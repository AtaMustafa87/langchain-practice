{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b0cb4a-b36d-437a-ac51-abf56cfae400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "    \n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"lsv2_pt_781bd944678a4df287c34b41c0c98251_44844eb3f6a\"#getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81ffdc3-34d6-4a6e-b0df-0c57e3529537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "files = [f'doc{i}.pdf' for i in range(2,5)]\n",
    "docs = [PyPDFLoader(f).load() for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1000ef2-70d4-4b86-9601-7608668c1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs[0] + docs[1] + docs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925825b5-01c9-4c2a-8ea2-895caf49f8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c29e5c-f583-40ec-aab5-fd350ac2e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791f18a8-d74c-4b40-8273-33962d5ae01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aead7941-596a-4ace-81dc-2c4213c4edfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-03-15T01:33:06+00:00', 'author': '', 'keywords': '', 'moddate': '2024-03-15T01:33:06+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'doc2.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'start_index': 0}, page_content='LARGE LANGUAGE MODELS CANNOT SELF -CORRECT\\nREASONING YET\\nJie Huang1,2∗ Xinyun Chen1∗ Swaroop Mishra1 Huaixiu Steven Zheng1 Adams Wei Yu1\\nXinying Song1 Denny Zhou1\\n1Google DeepMind 2University of Illinois at Urbana-Champaign\\njeffhj@illinois.edu, {xinyunchen, dennyzhou}@google.com\\nABSTRACT\\nLarge Language Models (LLMs) have emerged as a groundbreaking technology\\nwith their unparalleled text generation capabilities across various applications.\\nNevertheless, concerns persist regarding the accuracy and appropriateness of their\\ngenerated content. A contemporary methodology, self-correction, has been pro-\\nposed as a remedy to these issues. Building upon this premise, this paper critically\\nexamines the role and efficacy of self-correction within LLMs, shedding light on\\nits true potential and limitations. Central to our investigation is the notion of in-\\ntrinsic self-correction, whereby an LLM attempts to correct its initial responses')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b0c18b-8bf4-4cc1-b0d1-c82ee545fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5fe0c16-65ae-4cd5-adc8-5647c74855a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 768\n",
      "\n",
      "[0.034190398, 0.025235767, -0.1486969, -0.098875254, 0.032694545, -0.009843894, 0.040454157, 0.04934097, -0.026255531, 0.03786784]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417ee3d5-2cbb-46ee-b31c-d4e6eabc6bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e967aac6-16a3-4a7d-b88b-a2bc33255e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1b9060-6ee5-4125-b7a3-d62f0f48cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a7d9fc6-315d-4a0e-95c6-e25b0786b70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "047e0487-ae00-4782-b872-f82c9e3755af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Language models for code.Recent years have witnessed rapid progress in deep neural networks\n",
      "for code generation (Devlin et al., 2017; Chen et al., 2019; Yu et al., 2018; Roziere et al., 2020).\n",
      "While models designed and trained for specialized domains have achieved impressive performance\n",
      "in various applications such as text-to-code generation (Li et al., 2023a; Wang et al., 2020; Scholak\n",
      "et al., 2021; Dong & Lapata, 2016; Iyer et al., 2018) and code translation (Chen et al., 2018; Roziere\n",
      "et al., 2020; 2022), latest work on large language models demonstrate that a single pretrained model\n",
      "can achieve the state-of-the-art performance across a wide variety of coding tasks without specialized\n",
      "finetuning (Chen et al., 2021a; Chowdhery et al., 2022; Nijkamp et al., 2023; Zheng et al., 2023; Xu\n",
      "et al., 2022; Athiwaratkun et al., 2023; Orlanski et al., 2023).\n",
      "Despite showing the remarkable ability to follow natural language instructions, large language models' metadata={'author': '', 'creationdate': '2023-10-06T01:23:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-10-06T01:23:12+00:00', 'page': 11, 'page_label': '12', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'doc4.pdf', 'start_index': 1514, 'subject': '', 'title': '', 'total_pages': 78, 'trapped': '/False'}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"models have achieved impressive performance on code generation\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f59b8-801c-465e-b6cd-fbef62ece3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
