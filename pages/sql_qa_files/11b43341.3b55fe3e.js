"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2256],{15293:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"link","label":"Introduction","href":"/docs/introduction","docId":"introduction","unlisted":false},{"type":"category","label":"Tutorials","collapsible":false,"items":[{"type":"link","label":"Build a Question Answering application over a Graph Database","href":"/docs/tutorials/graph","className":"hidden","docId":"tutorials/graph","unlisted":false},{"type":"link","label":"Tutorials","href":"/docs/tutorials/","className":"hidden","docId":"tutorials/index","unlisted":false},{"type":"link","label":"Build a simple LLM application with chat models and prompt templates","href":"/docs/tutorials/llm_chain","className":"hidden","docId":"tutorials/llm_chain","unlisted":false},{"type":"link","label":"Build a Chatbot","href":"/docs/tutorials/chatbot","className":"hidden","docId":"tutorials/chatbot","unlisted":false},{"type":"link","label":"Build a Retrieval Augmented Generation (RAG) App: Part 2","href":"/docs/tutorials/qa_chat_history","className":"hidden","docId":"tutorials/qa_chat_history","unlisted":false},{"type":"link","label":"Build an Extraction Chain","href":"/docs/tutorials/extraction","className":"hidden","docId":"tutorials/extraction","unlisted":false},{"type":"link","label":"Build an Agent","href":"/docs/tutorials/agents","className":"hidden","docId":"tutorials/agents","unlisted":false},{"type":"link","label":"Tagging","href":"/docs/tutorials/classification","className":"hidden","docId":"tutorials/classification","unlisted":false},{"type":"link","label":"Build a Retrieval Augmented Generation (RAG) App: Part 1","href":"/docs/tutorials/rag","className":"hidden","docId":"tutorials/rag","unlisted":false},{"type":"link","label":"Build a semantic search engine","href":"/docs/tutorials/retrievers","className":"hidden","docId":"tutorials/retrievers","unlisted":false},{"type":"link","label":"Build a Question/Answering system over SQL data","href":"/docs/tutorials/sql_qa","className":"hidden","docId":"tutorials/sql_qa","unlisted":false},{"type":"link","label":"Summarize Text","href":"/docs/tutorials/summarization","className":"hidden","docId":"tutorials/summarization","unlisted":false}],"collapsed":false,"href":"/docs/tutorials/"},{"type":"category","label":"How-to guides","collapsible":false,"items":[{"type":"link","label":"How-to guides","href":"/docs/how_to/","className":"hidden","docId":"how_to/index","unlisted":false},{"type":"link","label":"How to use tools in a chain","href":"/docs/how_to/tools_chain","className":"hidden","docId":"how_to/tools_chain","unlisted":false},{"type":"link","label":"How to use a vectorstore as a retriever","href":"/docs/how_to/vectorstore_retriever","className":"hidden","docId":"how_to/vectorstore_retriever","unlisted":false},{"type":"link","label":"How to add memory to chatbots","href":"/docs/how_to/chatbots_memory","className":"hidden","docId":"how_to/chatbots_memory","unlisted":false},{"type":"link","label":"How to use example selectors","href":"/docs/how_to/example_selectors","className":"hidden","docId":"how_to/example_selectors","unlisted":false},{"type":"link","label":"How to add a semantic layer over graph database","href":"/docs/how_to/graph_semantic","className":"hidden","docId":"how_to/graph_semantic","unlisted":false},{"type":"link","label":"How to invoke runnables in parallel","href":"/docs/how_to/parallel","className":"hidden","docId":"how_to/parallel","unlisted":false},{"type":"link","label":"How to stream chat model responses","href":"/docs/how_to/chat_streaming","className":"hidden","docId":"how_to/chat_streaming","unlisted":false},{"type":"link","label":"How to add default invocation args to a Runnable","href":"/docs/how_to/binding","className":"hidden","docId":"how_to/binding","unlisted":false},{"type":"link","label":"How to add retrieval to chatbots","href":"/docs/how_to/chatbots_retrieval","className":"hidden","docId":"how_to/chatbots_retrieval","unlisted":false},{"type":"link","label":"How to use few shot examples in chat models","href":"/docs/how_to/few_shot_examples_chat","className":"hidden","docId":"how_to/few_shot_examples_chat","unlisted":false},{"type":"link","label":"How to do tool/function calling","href":"/docs/how_to/function_calling","className":"hidden","docId":"how_to/function_calling","unlisted":false},{"type":"link","label":"How to install LangChain packages","href":"/docs/how_to/installation","className":"hidden","docId":"how_to/installation","unlisted":false},{"type":"link","label":"How to add examples to the prompt for query analysis","href":"/docs/how_to/query_few_shot","className":"hidden","docId":"how_to/query_few_shot","unlisted":false},{"type":"link","label":"How to use few shot examples","href":"/docs/how_to/few_shot_examples","className":"hidden","docId":"how_to/few_shot_examples","unlisted":false},{"type":"link","label":"How to run custom functions","href":"/docs/how_to/functions","className":"hidden","docId":"how_to/functions","unlisted":false},{"type":"link","label":"How to use output parsers to parse an LLM response into structured format","href":"/docs/how_to/output_parser_structured","className":"hidden","docId":"how_to/output_parser_structured","unlisted":false},{"type":"link","label":"How to handle cases where no queries are generated","href":"/docs/how_to/query_no_queries","className":"hidden","docId":"how_to/query_no_queries","unlisted":false},{"type":"link","label":"How to route between sub-chains","href":"/docs/how_to/routing","className":"hidden","docId":"how_to/routing","unlisted":false},{"type":"link","label":"How to return structured data from a model","href":"/docs/how_to/structured_output","className":"hidden","docId":"how_to/structured_output","unlisted":false},{"type":"link","label":"How to summarize text through parallelization","href":"/docs/how_to/summarize_map_reduce","className":"hidden","docId":"how_to/summarize_map_reduce","unlisted":false},{"type":"link","label":"How to summarize text through iterative refinement","href":"/docs/how_to/summarize_refine","className":"hidden","docId":"how_to/summarize_refine","unlisted":false},{"type":"link","label":"How to summarize text in a single LLM call","href":"/docs/how_to/summarize_stuff","className":"hidden","docId":"how_to/summarize_stuff","unlisted":false},{"type":"link","label":"How to use toolkits","href":"/docs/how_to/toolkits","className":"hidden","docId":"how_to/toolkits","unlisted":false},{"type":"link","label":"How to add ad-hoc tool calling capability to LLMs and Chat Models","href":"/docs/how_to/tools_prompting","className":"hidden","docId":"how_to/tools_prompting","unlisted":false},{"type":"link","label":"Build an Agent with AgentExecutor (Legacy)","href":"/docs/how_to/agent_executor","className":"hidden","docId":"how_to/agent_executor","unlisted":false},{"type":"link","label":"How to construct knowledge graphs","href":"/docs/how_to/graph_constructing","className":"hidden","docId":"how_to/graph_constructing","unlisted":false},{"type":"link","label":"How to partially format prompt templates","href":"/docs/how_to/prompts_partial","className":"hidden","docId":"how_to/prompts_partial","unlisted":false},{"type":"link","label":"How to handle multiple queries when doing query analysis","href":"/docs/how_to/query_multiple_queries","className":"hidden","docId":"how_to/query_multiple_queries","unlisted":false},{"type":"link","label":"How to use built-in tools and toolkits","href":"/docs/how_to/tools_builtin","className":"hidden","docId":"how_to/tools_builtin","unlisted":false},{"type":"link","label":"How to pass through arguments from one step to the next","href":"/docs/how_to/passthrough","className":"hidden","docId":"how_to/passthrough","unlisted":false},{"type":"link","label":"How to compose prompts together","href":"/docs/how_to/prompts_composition","className":"hidden","docId":"how_to/prompts_composition","unlisted":false},{"type":"link","label":"How to handle multiple retrievers when doing query analysis","href":"/docs/how_to/query_multiple_retrievers","className":"hidden","docId":"how_to/query_multiple_retrievers","unlisted":false},{"type":"link","label":"How to add values to a chain\'s state","href":"/docs/how_to/assign","className":"hidden","docId":"how_to/assign","unlisted":false},{"type":"link","label":"How to construct filters for query analysis","href":"/docs/how_to/query_constructing_filters","className":"hidden","docId":"how_to/query_constructing_filters","unlisted":false},{"type":"link","label":"How to configure runtime chain internals","href":"/docs/how_to/configure","className":"hidden","docId":"how_to/configure","unlisted":false},{"type":"link","label":"How deal with high cardinality categoricals when doing query analysis","href":"/docs/how_to/query_high_cardinality","className":"hidden","docId":"how_to/query_high_cardinality","unlisted":false},{"type":"link","label":"Custom Document Loader","href":"/docs/how_to/document_loader_custom","className":"hidden","docId":"how_to/document_loader_custom","unlisted":false},{"type":"link","label":"How to use the MultiQueryRetriever","href":"/docs/how_to/MultiQueryRetriever","className":"hidden","docId":"how_to/MultiQueryRetriever","unlisted":false},{"type":"link","label":"How to add scores to retriever results","href":"/docs/how_to/add_scores_retriever","className":"hidden","docId":"how_to/add_scores_retriever","unlisted":false},{"type":"link","label":"Caching","href":"/docs/how_to/caching_embeddings","className":"hidden","docId":"how_to/caching_embeddings","unlisted":false},{"type":"link","label":"How to use callbacks in async environments","href":"/docs/how_to/callbacks_async","className":"hidden","docId":"how_to/callbacks_async","unlisted":false},{"type":"link","label":"How to attach callbacks to a runnable","href":"/docs/how_to/callbacks_attach","className":"hidden","docId":"how_to/callbacks_attach","unlisted":false},{"type":"link","label":"How to propagate callbacks  constructor","href":"/docs/how_to/callbacks_constructor","className":"hidden","docId":"how_to/callbacks_constructor","unlisted":false},{"type":"link","label":"How to dispatch custom callback events","href":"/docs/how_to/callbacks_custom_events","className":"hidden","docId":"how_to/callbacks_custom_events","unlisted":false},{"type":"link","label":"How to pass callbacks in at runtime","href":"/docs/how_to/callbacks_runtime","className":"hidden","docId":"how_to/callbacks_runtime","unlisted":false},{"type":"link","label":"How to split by character","href":"/docs/how_to/character_text_splitter","className":"hidden","docId":"how_to/character_text_splitter","unlisted":false},{"type":"link","label":"How to cache chat model responses","href":"/docs/how_to/chat_model_caching","className":"hidden","docId":"how_to/chat_model_caching","unlisted":false},{"type":"link","label":"How to handle rate limits","href":"/docs/how_to/chat_model_rate_limiting","className":"hidden","docId":"how_to/chat_model_rate_limiting","unlisted":false},{"type":"link","label":"How to init any model in one line","href":"/docs/how_to/chat_models_universal_init","className":"hidden","docId":"how_to/chat_models_universal_init","unlisted":false},{"type":"link","label":"How to track token usage in ChatModels","href":"/docs/how_to/chat_token_usage_tracking","className":"hidden","docId":"how_to/chat_token_usage_tracking","unlisted":false},{"type":"link","label":"How to add tools to chatbots","href":"/docs/how_to/chatbots_tools","className":"hidden","docId":"how_to/chatbots_tools","unlisted":false},{"type":"link","label":"How to split code","href":"/docs/how_to/code_splitter","className":"hidden","docId":"how_to/code_splitter","unlisted":false},{"type":"link","label":"How to do retrieval with contextual compression","href":"/docs/how_to/contextual_compression","className":"hidden","docId":"how_to/contextual_compression","unlisted":false},{"type":"link","label":"How to convert Runnables to Tools","href":"/docs/how_to/convert_runnable_to_tool","className":"hidden","docId":"how_to/convert_runnable_to_tool","unlisted":false},{"type":"link","label":"How to create custom callback handlers","href":"/docs/how_to/custom_callbacks","className":"hidden","docId":"how_to/custom_callbacks","unlisted":false},{"type":"link","label":"How to create a custom chat model class","href":"/docs/how_to/custom_chat_model","className":"hidden","docId":"how_to/custom_chat_model","unlisted":false},{"type":"link","label":"Custom Embeddings","href":"/docs/how_to/custom_embeddings","className":"hidden","docId":"how_to/custom_embeddings","unlisted":false},{"type":"link","label":"How to create a custom LLM class","href":"/docs/how_to/custom_llm","className":"hidden","docId":"how_to/custom_llm","unlisted":false},{"type":"link","label":"Custom Retriever","href":"/docs/how_to/custom_retriever","className":"hidden","docId":"how_to/custom_retriever","unlisted":false},{"type":"link","label":"How to create tools","href":"/docs/how_to/custom_tools","className":"hidden","docId":"how_to/custom_tools","unlisted":false},{"type":"link","label":"How to debug your LLM apps","href":"/docs/how_to/debugging","className":"hidden","docId":"how_to/debugging","unlisted":false},{"type":"link","label":"How to load CSVs","href":"/docs/how_to/document_loader_csv","className":"hidden","docId":"how_to/document_loader_csv","unlisted":false},{"type":"link","label":"How to load documents from a directory","href":"/docs/how_to/document_loader_directory","className":"hidden","docId":"how_to/document_loader_directory","unlisted":false},{"type":"link","label":"How to load HTML","href":"/docs/how_to/document_loader_html","className":"hidden","docId":"how_to/document_loader_html","unlisted":false},{"type":"link","label":"How to load JSON","href":"/docs/how_to/document_loader_json","className":"hidden","docId":"how_to/document_loader_json","unlisted":false},{"type":"link","label":"How to load Markdown","href":"/docs/how_to/document_loader_markdown","className":"hidden","docId":"how_to/document_loader_markdown","unlisted":false},{"type":"link","label":"How to load Microsoft Office files","href":"/docs/how_to/document_loader_office_file","className":"hidden","docId":"how_to/document_loader_office_file","unlisted":false},{"type":"link","label":"How to load PDFs","href":"/docs/how_to/document_loader_pdf","className":"hidden","docId":"how_to/document_loader_pdf","unlisted":false},{"type":"link","label":"How to load web pages","href":"/docs/how_to/document_loader_web","className":"hidden","docId":"how_to/document_loader_web","unlisted":false},{"type":"link","label":"How to create a dynamic (self-constructing) chain","href":"/docs/how_to/dynamic_chain","className":"hidden","docId":"how_to/dynamic_chain","unlisted":false},{"type":"link","label":"Text embedding models","href":"/docs/how_to/embed_text","className":"hidden","docId":"how_to/embed_text","unlisted":false},{"type":"link","label":"How to combine results from multiple retrievers","href":"/docs/how_to/ensemble_retriever","className":"hidden","docId":"how_to/ensemble_retriever","unlisted":false},{"type":"link","label":"How to select examples from a LangSmith dataset","href":"/docs/how_to/example_selectors_langsmith","className":"hidden","docId":"how_to/example_selectors_langsmith","unlisted":false},{"type":"link","label":"How to select examples by length","href":"/docs/how_to/example_selectors_length_based","className":"hidden","docId":"how_to/example_selectors_length_based","unlisted":false},{"type":"link","label":"How to select examples by maximal marginal relevance (MMR)","href":"/docs/how_to/example_selectors_mmr","className":"hidden","docId":"how_to/example_selectors_mmr","unlisted":false},{"type":"link","label":"How to select examples by n-gram overlap","href":"/docs/how_to/example_selectors_ngram","className":"hidden","docId":"how_to/example_selectors_ngram","unlisted":false},{"type":"link","label":"How to select examples by similarity","href":"/docs/how_to/example_selectors_similarity","className":"hidden","docId":"how_to/example_selectors_similarity","unlisted":false},{"type":"link","label":"How to use reference examples when doing extraction","href":"/docs/how_to/extraction_examples","className":"hidden","docId":"how_to/extraction_examples","unlisted":false},{"type":"link","label":"How to handle long text when doing extraction","href":"/docs/how_to/extraction_long_text","className":"hidden","docId":"how_to/extraction_long_text","unlisted":false},{"type":"link","label":"How to use prompting alone (no tool calling) to do extraction","href":"/docs/how_to/extraction_parse","className":"hidden","docId":"how_to/extraction_parse","unlisted":false},{"type":"link","label":"How to add fallbacks to a runnable","href":"/docs/how_to/fallbacks","className":"hidden","docId":"how_to/fallbacks","unlisted":false},{"type":"link","label":"How to filter messages","href":"/docs/how_to/filter_messages","className":"hidden","docId":"how_to/filter_messages","unlisted":false},{"type":"link","label":"Hybrid Search","href":"/docs/how_to/hybrid","className":"hidden","docId":"how_to/hybrid","unlisted":false},{"type":"link","label":"How to use the LangChain indexing API","href":"/docs/how_to/indexing","className":"hidden","docId":"how_to/indexing","unlisted":false},{"type":"link","label":"How to inspect runnables","href":"/docs/how_to/inspect","className":"hidden","docId":"how_to/inspect","unlisted":false},{"type":"link","label":"LangChain Expression Language Cheatsheet","href":"/docs/how_to/lcel_cheatsheet","className":"hidden","docId":"how_to/lcel_cheatsheet","unlisted":false},{"type":"link","label":"How to cache LLM responses","href":"/docs/how_to/llm_caching","className":"hidden","docId":"how_to/llm_caching","unlisted":false},{"type":"link","label":"How to track token usage for LLMs","href":"/docs/how_to/llm_token_usage_tracking","className":"hidden","docId":"how_to/llm_token_usage_tracking","unlisted":false},{"type":"link","label":"Run models locally","href":"/docs/how_to/local_llms","className":"hidden","docId":"how_to/local_llms","unlisted":false},{"type":"link","label":"How to get log probabilities","href":"/docs/how_to/logprobs","className":"hidden","docId":"how_to/logprobs","unlisted":false},{"type":"link","label":"How to reorder retrieved results to mitigate the \\"lost in the middle\\" effect","href":"/docs/how_to/long_context_reorder","className":"hidden","docId":"how_to/long_context_reorder","unlisted":false},{"type":"link","label":"How to split Markdown by Headers","href":"/docs/how_to/markdown_header_metadata_splitter","className":"hidden","docId":"how_to/markdown_header_metadata_splitter","unlisted":false},{"type":"link","label":"How to merge consecutive messages of the same type","href":"/docs/how_to/merge_message_runs","className":"hidden","docId":"how_to/merge_message_runs","unlisted":false},{"type":"link","label":"How to add message history","href":"/docs/how_to/message_history","className":"hidden","docId":"how_to/message_history","unlisted":false},{"type":"link","label":"How to migrate from legacy LangChain agents to LangGraph","href":"/docs/how_to/migrate_agent","className":"hidden","docId":"how_to/migrate_agent","unlisted":false},{"type":"link","label":"How to retrieve using multiple vectors per document","href":"/docs/how_to/multi_vector","className":"hidden","docId":"how_to/multi_vector","unlisted":false},{"type":"link","label":"How to pass multimodal data directly to models","href":"/docs/how_to/multimodal_inputs","className":"hidden","docId":"how_to/multimodal_inputs","unlisted":false},{"type":"link","label":"How to use multimodal prompts","href":"/docs/how_to/multimodal_prompts","className":"hidden","docId":"how_to/multimodal_prompts","unlisted":false},{"type":"link","label":"How to create a custom Output Parser","href":"/docs/how_to/output_parser_custom","className":"hidden","docId":"how_to/output_parser_custom","unlisted":false},{"type":"link","label":"How to use the output-fixing parser","href":"/docs/how_to/output_parser_fixing","className":"hidden","docId":"how_to/output_parser_fixing","unlisted":false},{"type":"link","label":"How to parse JSON output","href":"/docs/how_to/output_parser_json","className":"hidden","docId":"how_to/output_parser_json","unlisted":false},{"type":"link","label":"How to retry when a parsing error occurs","href":"/docs/how_to/output_parser_retry","className":"hidden","docId":"how_to/output_parser_retry","unlisted":false},{"type":"link","label":"How to parse text from message objects","href":"/docs/how_to/output_parser_string","className":"hidden","docId":"how_to/output_parser_string","unlisted":false},{"type":"link","label":"How to parse XML output","href":"/docs/how_to/output_parser_xml","className":"hidden","docId":"how_to/output_parser_xml","unlisted":false},{"type":"link","label":"How to parse YAML output","href":"/docs/how_to/output_parser_yaml","className":"hidden","docId":"how_to/output_parser_yaml","unlisted":false},{"type":"link","label":"How to use the Parent Document Retriever","href":"/docs/how_to/parent_document_retriever","className":"hidden","docId":"how_to/parent_document_retriever","unlisted":false},{"type":"link","label":"How to use LangChain with different Pydantic versions","href":"/docs/how_to/pydantic_compatibility","className":"hidden","docId":"how_to/pydantic_compatibility","unlisted":false},{"type":"link","label":"How to add chat history","href":"/docs/how_to/qa_chat_history_how_to","className":"hidden","docId":"how_to/qa_chat_history_how_to","unlisted":false},{"type":"link","label":"How to get a RAG application to add citations","href":"/docs/how_to/qa_citations","className":"hidden","docId":"how_to/qa_citations","unlisted":false},{"type":"link","label":"How to do per-user retrieval","href":"/docs/how_to/qa_per_user","className":"hidden","docId":"how_to/qa_per_user","unlisted":false},{"type":"link","label":"How to get your RAG application to return sources","href":"/docs/how_to/qa_sources","className":"hidden","docId":"how_to/qa_sources","unlisted":false},{"type":"link","label":"How to stream results from your RAG application","href":"/docs/how_to/qa_streaming","className":"hidden","docId":"how_to/qa_streaming","unlisted":false},{"type":"link","label":"How to split JSON data","href":"/docs/how_to/recursive_json_splitter","className":"hidden","docId":"how_to/recursive_json_splitter","unlisted":false},{"type":"link","label":"How to recursively split text by characters","href":"/docs/how_to/recursive_text_splitter","className":"hidden","docId":"how_to/recursive_text_splitter","unlisted":false},{"type":"link","label":"Response metadata","href":"/docs/how_to/response_metadata","className":"hidden","docId":"how_to/response_metadata","unlisted":false},{"type":"link","label":"How to pass runtime secrets to runnables","href":"/docs/how_to/runnable_runtime_secrets","className":"hidden","docId":"how_to/runnable_runtime_secrets","unlisted":false},{"type":"link","label":"How to do \\"self-querying\\" retrieval","href":"/docs/how_to/self_query","className":"hidden","docId":"how_to/self_query","unlisted":false},{"type":"link","label":"How to split text based on semantic similarity","href":"/docs/how_to/semantic-chunker","className":"hidden","docId":"how_to/semantic-chunker","unlisted":false},{"type":"link","label":"How to chain runnables","href":"/docs/how_to/sequence","className":"hidden","docId":"how_to/sequence","unlisted":false},{"type":"link","label":"How to save and load LangChain objects","href":"/docs/how_to/serialization","className":"hidden","docId":"how_to/serialization","unlisted":false},{"type":"link","label":"How to split text by tokens","href":"/docs/how_to/split_by_token","className":"hidden","docId":"how_to/split_by_token","unlisted":false},{"type":"link","label":"How to split HTML","href":"/docs/how_to/split_html","className":"hidden","docId":"how_to/split_html","unlisted":false},{"type":"link","label":"How to do question answering over CSVs","href":"/docs/how_to/sql_csv","className":"hidden","docId":"how_to/sql_csv","unlisted":false},{"type":"link","label":"How to deal with large databases when doing SQL question-answering","href":"/docs/how_to/sql_large_db","className":"hidden","docId":"how_to/sql_large_db","unlisted":false},{"type":"link","label":"How to better prompt when doing SQL question-answering","href":"/docs/how_to/sql_prompting","className":"hidden","docId":"how_to/sql_prompting","unlisted":false},{"type":"link","label":"How to do query validation as part of SQL question-answering","href":"/docs/how_to/sql_query_checking","className":"hidden","docId":"how_to/sql_query_checking","unlisted":false},{"type":"link","label":"How to stream runnables","href":"/docs/how_to/streaming","className":"hidden","docId":"how_to/streaming","unlisted":false},{"type":"link","label":"How to stream responses from an LLM","href":"/docs/how_to/streaming_llm","className":"hidden","docId":"how_to/streaming_llm","unlisted":false},{"type":"link","label":"How to use a time-weighted vector store retriever","href":"/docs/how_to/time_weighted_vectorstore","className":"hidden","docId":"how_to/time_weighted_vectorstore","unlisted":false},{"type":"link","label":"How to return artifacts from a tool","href":"/docs/how_to/tool_artifacts","className":"hidden","docId":"how_to/tool_artifacts","unlisted":false},{"type":"link","label":"How to use chat models to call tools","href":"/docs/how_to/tool_calling","className":"hidden","docId":"how_to/tool_calling","unlisted":false},{"type":"link","label":"How to disable parallel tool calling","href":"/docs/how_to/tool_calling_parallel","className":"hidden","docId":"how_to/tool_calling_parallel","unlisted":false},{"type":"link","label":"How to force models to call a tool","href":"/docs/how_to/tool_choice","className":"hidden","docId":"how_to/tool_choice","unlisted":false},{"type":"link","label":"How to access the RunnableConfig from a tool","href":"/docs/how_to/tool_configure","className":"hidden","docId":"how_to/tool_configure","unlisted":false},{"type":"link","label":"How to pass tool outputs to chat models","href":"/docs/how_to/tool_results_pass_to_model","className":"hidden","docId":"how_to/tool_results_pass_to_model","unlisted":false},{"type":"link","label":"How to pass run time values to tools","href":"/docs/how_to/tool_runtime","className":"hidden","docId":"how_to/tool_runtime","unlisted":false},{"type":"link","label":"How to stream events from a tool","href":"/docs/how_to/tool_stream_events","className":"hidden","docId":"how_to/tool_stream_events","unlisted":false},{"type":"link","label":"How to stream tool calls","href":"/docs/how_to/tool_streaming","className":"hidden","docId":"how_to/tool_streaming","unlisted":false},{"type":"link","label":"How to convert tools to OpenAI Functions","href":"/docs/how_to/tools_as_openai_functions","className":"hidden","docId":"how_to/tools_as_openai_functions","unlisted":false},{"type":"link","label":"How to handle tool errors","href":"/docs/how_to/tools_error","className":"hidden","docId":"how_to/tools_error","unlisted":false},{"type":"link","label":"How to use few-shot prompting with tool calling","href":"/docs/how_to/tools_few_shot","className":"hidden","docId":"how_to/tools_few_shot","unlisted":false},{"type":"link","label":"How to add a human-in-the-loop for tools","href":"/docs/how_to/tools_human","className":"hidden","docId":"how_to/tools_human","unlisted":false},{"type":"link","label":"How to bind model-specific tools","href":"/docs/how_to/tools_model_specific","className":"hidden","docId":"how_to/tools_model_specific","unlisted":false},{"type":"link","label":"How to trim messages","href":"/docs/how_to/trim_messages","className":"hidden","docId":"how_to/trim_messages","unlisted":false},{"type":"link","label":"How to create and query vector stores","href":"/docs/how_to/vectorstores","className":"hidden","docId":"how_to/vectorstores","unlisted":false}],"collapsed":false,"href":"/docs/how_to/"},{"type":"category","label":"Conceptual guide","collapsible":false,"items":[{"type":"link","label":"Agents","href":"/docs/concepts/agents","className":"hidden","docId":"concepts/agents","unlisted":false},{"type":"link","label":"Architecture","href":"/docs/concepts/architecture","className":"hidden","docId":"concepts/architecture","unlisted":false},{"type":"link","label":"Async programming with langchain","href":"/docs/concepts/async","className":"hidden","docId":"concepts/async","unlisted":false},{"type":"link","label":"Callbacks","href":"/docs/concepts/callbacks","className":"hidden","docId":"concepts/callbacks","unlisted":false},{"type":"link","label":"Chat history","href":"/docs/concepts/chat_history","className":"hidden","docId":"concepts/chat_history","unlisted":false},{"type":"link","label":"Chat models","href":"/docs/concepts/chat_models","className":"hidden","docId":"concepts/chat_models","unlisted":false},{"type":"link","label":"Document loaders","href":"/docs/concepts/document_loaders","className":"hidden","docId":"concepts/document_loaders","unlisted":false},{"type":"link","label":"Embedding models","href":"/docs/concepts/embedding_models","className":"hidden","docId":"concepts/embedding_models","unlisted":false},{"type":"link","label":"Evaluation","href":"/docs/concepts/evaluation","className":"hidden","docId":"concepts/evaluation","unlisted":false},{"type":"link","label":"Example selectors","href":"/docs/concepts/example_selectors","className":"hidden","docId":"concepts/example_selectors","unlisted":false},{"type":"link","label":"Few-shot prompting","href":"/docs/concepts/few_shot_prompting","className":"hidden","docId":"concepts/few_shot_prompting","unlisted":false},{"type":"link","label":"Conceptual guide","href":"/docs/concepts/","className":"hidden","docId":"concepts/index","unlisted":false},{"type":"link","label":"Key-value stores","href":"/docs/concepts/key_value_stores","className":"hidden","docId":"concepts/key_value_stores","unlisted":false},{"type":"link","label":"LangChain Expression Language (LCEL)","href":"/docs/concepts/lcel","className":"hidden","docId":"concepts/lcel","unlisted":false},{"type":"link","label":"Messages","href":"/docs/concepts/messages","className":"hidden","docId":"concepts/messages","unlisted":false},{"type":"link","label":"Multimodality","href":"/docs/concepts/multimodality","className":"hidden","docId":"concepts/multimodality","unlisted":false},{"type":"link","label":"Output parsers","href":"/docs/concepts/output_parsers","className":"hidden","docId":"concepts/output_parsers","unlisted":false},{"type":"link","label":"Prompt Templates","href":"/docs/concepts/prompt_templates","className":"hidden","docId":"concepts/prompt_templates","unlisted":false},{"type":"link","label":"Retrieval augmented generation (RAG)","href":"/docs/concepts/rag","className":"hidden","docId":"concepts/rag","unlisted":false},{"type":"link","label":"Retrieval","href":"/docs/concepts/retrieval","className":"hidden","docId":"concepts/retrieval","unlisted":false},{"type":"link","label":"Retrievers","href":"/docs/concepts/retrievers","className":"hidden","docId":"concepts/retrievers","unlisted":false},{"type":"link","label":"Runnable interface","href":"/docs/concepts/runnables","className":"hidden","docId":"concepts/runnables","unlisted":false},{"type":"link","label":"Streaming","href":"/docs/concepts/streaming","className":"hidden","docId":"concepts/streaming","unlisted":false},{"type":"link","label":"Structured outputs","href":"/docs/concepts/structured_outputs","className":"hidden","docId":"concepts/structured_outputs","unlisted":false},{"type":"link","label":"Testing","href":"/docs/concepts/testing","className":"hidden","docId":"concepts/testing","unlisted":false},{"type":"link","label":"String-in, string-out llms","href":"/docs/concepts/text_llms","className":"hidden","docId":"concepts/text_llms","unlisted":false},{"type":"link","label":"Text splitters","href":"/docs/concepts/text_splitters","className":"hidden","docId":"concepts/text_splitters","unlisted":false},{"type":"link","label":"Tokens","href":"/docs/concepts/tokens","className":"hidden","docId":"concepts/tokens","unlisted":false},{"type":"link","label":"Tool calling","href":"/docs/concepts/tool_calling","className":"hidden","docId":"concepts/tool_calling","unlisted":false},{"type":"link","label":"Tools","href":"/docs/concepts/tools","className":"hidden","docId":"concepts/tools","unlisted":false},{"type":"link","label":"Tracing","href":"/docs/concepts/tracing","className":"hidden","docId":"concepts/tracing","unlisted":false},{"type":"link","label":"Vector stores","href":"/docs/concepts/vectorstores","className":"hidden","docId":"concepts/vectorstores","unlisted":false},{"type":"link","label":"Why LangChain?","href":"/docs/concepts/why_langchain","className":"hidden","docId":"concepts/why_langchain","unlisted":false}],"collapsed":false,"href":"/docs/concepts/"},{"type":"category","label":"Ecosystem","collapsed":false,"collapsible":false,"items":[{"type":"link","href":"https://docs.smith.langchain.com/","label":"\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith"},{"type":"link","href":"https://langchain-ai.github.io/langgraph/","label":"\ud83e\udd9c\ud83d\udd78\ufe0f LangGraph"}]},{"type":"category","label":"Versions","collapsed":false,"collapsible":false,"items":[{"type":"link","label":"v0.3","href":"/docs/versions/v0_3/","docId":"versions/v0_3/index","unlisted":false},{"type":"category","label":"v0.2","items":[{"type":"link","label":"Overview","href":"/docs/versions/v0_2/overview","docId":"versions/v0_2/overview","unlisted":false},{"type":"link","label":"Migration","href":"/docs/versions/v0_2/","docId":"versions/v0_2/index","unlisted":false},{"type":"link","label":"astream_events v2","href":"/docs/versions/v0_2/migrating_astream_events","docId":"versions/v0_2/migrating_astream_events","unlisted":false},{"type":"link","label":"Changes","href":"/docs/versions/v0_2/deprecations","docId":"versions/v0_2/deprecations","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Pydantic compatibility","href":"/docs/how_to/pydantic_compatibility","docId":"how_to/pydantic_compatibility","unlisted":false},{"type":"category","label":"Migrating from v0.0 chains","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"How to migrate from v0.0 chains","href":"/docs/versions/migrating_chains/","className":"hidden","docId":"versions/migrating_chains/index","unlisted":false},{"type":"link","label":"Migrating from ConstitutionalChain","href":"/docs/versions/migrating_chains/constitutional_chain","className":"hidden","docId":"versions/migrating_chains/constitutional_chain","unlisted":false},{"type":"link","label":"Migrating from ConversationalChain","href":"/docs/versions/migrating_chains/conversation_chain","className":"hidden","docId":"versions/migrating_chains/conversation_chain","unlisted":false},{"type":"link","label":"Migrating from ConversationalRetrievalChain","href":"/docs/versions/migrating_chains/conversation_retrieval_chain","className":"hidden","docId":"versions/migrating_chains/conversation_retrieval_chain","unlisted":false},{"type":"link","label":"Migrating from LLMChain","href":"/docs/versions/migrating_chains/llm_chain","className":"hidden","docId":"versions/migrating_chains/llm_chain","unlisted":false},{"type":"link","label":"Migrating from LLMMathChain","href":"/docs/versions/migrating_chains/llm_math_chain","className":"hidden","docId":"versions/migrating_chains/llm_math_chain","unlisted":false},{"type":"link","label":"Migrating from LLMRouterChain","href":"/docs/versions/migrating_chains/llm_router_chain","className":"hidden","docId":"versions/migrating_chains/llm_router_chain","unlisted":false},{"type":"link","label":"Migrating from MapReduceDocumentsChain","href":"/docs/versions/migrating_chains/map_reduce_chain","className":"hidden","docId":"versions/migrating_chains/map_reduce_chain","unlisted":false},{"type":"link","label":"Migrating from MapRerankDocumentsChain","href":"/docs/versions/migrating_chains/map_rerank_docs_chain","className":"hidden","docId":"versions/migrating_chains/map_rerank_docs_chain","unlisted":false},{"type":"link","label":"Migrating from MultiPromptChain","href":"/docs/versions/migrating_chains/multi_prompt_chain","className":"hidden","docId":"versions/migrating_chains/multi_prompt_chain","unlisted":false},{"type":"link","label":"Migrating from RefineDocumentsChain","href":"/docs/versions/migrating_chains/refine_docs_chain","className":"hidden","docId":"versions/migrating_chains/refine_docs_chain","unlisted":false},{"type":"link","label":"Migrating from RetrievalQA","href":"/docs/versions/migrating_chains/retrieval_qa","className":"hidden","docId":"versions/migrating_chains/retrieval_qa","unlisted":false},{"type":"link","label":"Migrating from StuffDocumentsChain","href":"/docs/versions/migrating_chains/stuff_docs_chain","className":"hidden","docId":"versions/migrating_chains/stuff_docs_chain","unlisted":false}],"href":"/docs/versions/migrating_chains/"},{"type":"category","label":"Upgrading to LangGraph memory","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"How to migrate to LangGraph memory","href":"/docs/versions/migrating_memory/","className":"hidden","docId":"versions/migrating_memory/index","unlisted":false},{"type":"link","label":"How to use BaseChatMessageHistory with LangGraph","href":"/docs/versions/migrating_memory/chat_history","className":"hidden","docId":"versions/migrating_memory/chat_history","unlisted":false},{"type":"link","label":"Migrating off ConversationBufferMemory or ConversationStringBufferMemory","href":"/docs/versions/migrating_memory/conversation_buffer_memory","className":"hidden","docId":"versions/migrating_memory/conversation_buffer_memory","unlisted":false},{"type":"link","label":"Migrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory","href":"/docs/versions/migrating_memory/conversation_buffer_window_memory","className":"hidden","docId":"versions/migrating_memory/conversation_buffer_window_memory","unlisted":false},{"type":"link","label":"Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory","href":"/docs/versions/migrating_memory/conversation_summary_memory","className":"hidden","docId":"versions/migrating_memory/conversation_summary_memory","unlisted":false},{"type":"link","label":"A Long-Term Memory Agent","href":"/docs/versions/migrating_memory/long_term_memory_agent","className":"hidden","docId":"versions/migrating_memory/long_term_memory_agent","unlisted":false}],"href":"/docs/versions/migrating_memory/"},{"type":"link","label":"Release policy","href":"/docs/versions/release_policy","docId":"versions/release_policy","unlisted":false}]},{"type":"link","label":"Security Policy","href":"/docs/security","docId":"security","unlisted":false}],"integrations":[{"type":"category","label":"Providers","collapsible":false,"items":[{"type":"link","label":"Anthropic","href":"/docs/integrations/providers/anthropic","docId":"integrations/providers/anthropic","unlisted":false},{"type":"link","label":"AWS","href":"/docs/integrations/providers/aws","docId":"integrations/providers/aws","unlisted":false},{"type":"link","label":"Google","href":"/docs/integrations/providers/google","docId":"integrations/providers/google","unlisted":false},{"type":"link","label":"Hugging Face","href":"/docs/integrations/providers/huggingface","docId":"integrations/providers/huggingface","unlisted":false},{"type":"link","label":"Microsoft","href":"/docs/integrations/providers/microsoft","docId":"integrations/providers/microsoft","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/providers/openai","docId":"integrations/providers/openai","unlisted":false},{"type":"category","label":"More","collapsible":false,"items":[{"type":"link","label":"Providers","href":"/docs/integrations/providers/","className":"hidden","docId":"integrations/providers/index","unlisted":false},{"type":"link","label":"Abso","href":"/docs/integrations/providers/abso","className":"hidden","docId":"integrations/providers/abso","unlisted":false},{"type":"link","label":"Acreom","href":"/docs/integrations/providers/acreom","className":"hidden","docId":"integrations/providers/acreom","unlisted":false},{"type":"link","label":"Activeloop Deep Lake","href":"/docs/integrations/providers/activeloop_deeplake","className":"hidden","docId":"integrations/providers/activeloop_deeplake","unlisted":false},{"type":"link","label":"ADS4GPTs","href":"/docs/integrations/providers/ads4gpts","className":"hidden","docId":"integrations/providers/ads4gpts","unlisted":false},{"type":"link","label":"Aerospike","href":"/docs/integrations/providers/aerospike","className":"hidden","docId":"integrations/providers/aerospike","unlisted":false},{"type":"link","label":"AgentQL","href":"/docs/integrations/providers/agentql","className":"hidden","docId":"integrations/providers/agentql","unlisted":false},{"type":"link","label":"AI21 Labs","href":"/docs/integrations/providers/ai21","className":"hidden","docId":"integrations/providers/ai21","unlisted":false},{"type":"link","label":"Aim","href":"/docs/integrations/providers/aim_tracking","className":"hidden","docId":"integrations/providers/aim_tracking","unlisted":false},{"type":"link","label":"AINetwork","href":"/docs/integrations/providers/ainetwork","className":"hidden","docId":"integrations/providers/ainetwork","unlisted":false},{"type":"link","label":"Airbyte","href":"/docs/integrations/providers/airbyte","className":"hidden","docId":"integrations/providers/airbyte","unlisted":false},{"type":"link","label":"Airtable","href":"/docs/integrations/providers/airtable","className":"hidden","docId":"integrations/providers/airtable","unlisted":false},{"type":"link","label":"Alchemy","href":"/docs/integrations/providers/alchemy","className":"hidden","docId":"integrations/providers/alchemy","unlisted":false},{"type":"link","label":"Aleph Alpha","href":"/docs/integrations/providers/aleph_alpha","className":"hidden","docId":"integrations/providers/aleph_alpha","unlisted":false},{"type":"link","label":"Alibaba Cloud","href":"/docs/integrations/providers/alibaba_cloud","className":"hidden","docId":"integrations/providers/alibaba_cloud","unlisted":false},{"type":"link","label":"AnalyticDB","href":"/docs/integrations/providers/analyticdb","className":"hidden","docId":"integrations/providers/analyticdb","unlisted":false},{"type":"link","label":"Annoy","href":"/docs/integrations/providers/annoy","className":"hidden","docId":"integrations/providers/annoy","unlisted":false},{"type":"link","label":"Anthropic","href":"/docs/integrations/providers/anthropic","className":"hidden","docId":"integrations/providers/anthropic","unlisted":false},{"type":"link","label":"Anyscale","href":"/docs/integrations/providers/anyscale","className":"hidden","docId":"integrations/providers/anyscale","unlisted":false},{"type":"link","label":"Apache Software Foundation","href":"/docs/integrations/providers/apache","className":"hidden","docId":"integrations/providers/apache","unlisted":false},{"type":"link","label":"Apache Doris","href":"/docs/integrations/providers/apache_doris","className":"hidden","docId":"integrations/providers/apache_doris","unlisted":false},{"type":"link","label":"Apify","href":"/docs/integrations/providers/apify","className":"hidden","docId":"integrations/providers/apify","unlisted":false},{"type":"link","label":"Apple","href":"/docs/integrations/providers/apple","className":"hidden","docId":"integrations/providers/apple","unlisted":false},{"type":"link","label":"ArangoDB","href":"/docs/integrations/providers/arangodb","className":"hidden","docId":"integrations/providers/arangodb","unlisted":false},{"type":"link","label":"Arcee","href":"/docs/integrations/providers/arcee","className":"hidden","docId":"integrations/providers/arcee","unlisted":false},{"type":"link","label":"ArcGIS","href":"/docs/integrations/providers/arcgis","className":"hidden","docId":"integrations/providers/arcgis","unlisted":false},{"type":"link","label":"Argilla","href":"/docs/integrations/providers/argilla","className":"hidden","docId":"integrations/providers/argilla","unlisted":false},{"type":"link","label":"Arize","href":"/docs/integrations/providers/arize","className":"hidden","docId":"integrations/providers/arize","unlisted":false},{"type":"link","label":"Arthur","href":"/docs/integrations/providers/arthur_tracking","className":"hidden","docId":"integrations/providers/arthur_tracking","unlisted":false},{"type":"link","label":"Arxiv","href":"/docs/integrations/providers/arxiv","className":"hidden","docId":"integrations/providers/arxiv","unlisted":false},{"type":"link","label":"Ascend","href":"/docs/integrations/providers/ascend","className":"hidden","docId":"integrations/providers/ascend","unlisted":false},{"type":"link","label":"AskNews","href":"/docs/integrations/providers/asknews","className":"hidden","docId":"integrations/providers/asknews","unlisted":false},{"type":"link","label":"AssemblyAI","href":"/docs/integrations/providers/assemblyai","className":"hidden","docId":"integrations/providers/assemblyai","unlisted":false},{"type":"link","label":"Astra DB","href":"/docs/integrations/providers/astradb","className":"hidden","docId":"integrations/providers/astradb","unlisted":false},{"type":"link","label":"Atlas","href":"/docs/integrations/providers/atlas","className":"hidden","docId":"integrations/providers/atlas","unlisted":false},{"type":"link","label":"AwaDB","href":"/docs/integrations/providers/awadb","className":"hidden","docId":"integrations/providers/awadb","unlisted":false},{"type":"link","label":"AWS","href":"/docs/integrations/providers/aws","className":"hidden","docId":"integrations/providers/aws","unlisted":false},{"type":"link","label":"AZLyrics","href":"/docs/integrations/providers/azlyrics","className":"hidden","docId":"integrations/providers/azlyrics","unlisted":false},{"type":"link","label":"Azure AI","href":"/docs/integrations/providers/azure_ai","className":"hidden","docId":"integrations/providers/azure_ai","unlisted":false},{"type":"link","label":"BAAI","href":"/docs/integrations/providers/baai","className":"hidden","docId":"integrations/providers/baai","unlisted":false},{"type":"link","label":"Bagel","href":"/docs/integrations/providers/bagel","className":"hidden","docId":"integrations/providers/bagel","unlisted":false},{"type":"link","label":"BagelDB","href":"/docs/integrations/providers/bageldb","className":"hidden","docId":"integrations/providers/bageldb","unlisted":false},{"type":"link","label":"Baichuan","href":"/docs/integrations/providers/baichuan","className":"hidden","docId":"integrations/providers/baichuan","unlisted":false},{"type":"link","label":"Baidu","href":"/docs/integrations/providers/baidu","className":"hidden","docId":"integrations/providers/baidu","unlisted":false},{"type":"link","label":"Banana","href":"/docs/integrations/providers/bananadev","className":"hidden","docId":"integrations/providers/bananadev","unlisted":false},{"type":"link","label":"Baseten","href":"/docs/integrations/providers/baseten","className":"hidden","docId":"integrations/providers/baseten","unlisted":false},{"type":"link","label":"Beam","href":"/docs/integrations/providers/beam","className":"hidden","docId":"integrations/providers/beam","unlisted":false},{"type":"link","label":"Beautiful Soup","href":"/docs/integrations/providers/beautiful_soup","className":"hidden","docId":"integrations/providers/beautiful_soup","unlisted":false},{"type":"link","label":"BibTeX","href":"/docs/integrations/providers/bibtex","className":"hidden","docId":"integrations/providers/bibtex","unlisted":false},{"type":"link","label":"BiliBili","href":"/docs/integrations/providers/bilibili","className":"hidden","docId":"integrations/providers/bilibili","unlisted":false},{"type":"link","label":"Bittensor","href":"/docs/integrations/providers/bittensor","className":"hidden","docId":"integrations/providers/bittensor","unlisted":false},{"type":"link","label":"Blackboard","href":"/docs/integrations/providers/blackboard","className":"hidden","docId":"integrations/providers/blackboard","unlisted":false},{"type":"link","label":"bookend.ai","href":"/docs/integrations/providers/bookendai","className":"hidden","docId":"integrations/providers/bookendai","unlisted":false},{"type":"link","label":"Box","href":"/docs/integrations/providers/box","className":"hidden","docId":"integrations/providers/box","unlisted":false},{"type":"link","label":"Brave Search","href":"/docs/integrations/providers/brave_search","className":"hidden","docId":"integrations/providers/brave_search","unlisted":false},{"type":"link","label":"Breebs (Open Knowledge)","href":"/docs/integrations/providers/breebs","className":"hidden","docId":"integrations/providers/breebs","unlisted":false},{"type":"link","label":"Browserbase","href":"/docs/integrations/providers/browserbase","className":"hidden","docId":"integrations/providers/browserbase","unlisted":false},{"type":"link","label":"Browserless","href":"/docs/integrations/providers/browserless","className":"hidden","docId":"integrations/providers/browserless","unlisted":false},{"type":"link","label":"ByteDance","href":"/docs/integrations/providers/byte_dance","className":"hidden","docId":"integrations/providers/byte_dance","unlisted":false},{"type":"link","label":"Cassandra","href":"/docs/integrations/providers/cassandra","className":"hidden","docId":"integrations/providers/cassandra","unlisted":false},{"type":"link","label":"Cerebras","href":"/docs/integrations/providers/cerebras","className":"hidden","docId":"integrations/providers/cerebras","unlisted":false},{"type":"link","label":"CerebriumAI","href":"/docs/integrations/providers/cerebriumai","className":"hidden","docId":"integrations/providers/cerebriumai","unlisted":false},{"type":"link","label":"Chaindesk","href":"/docs/integrations/providers/chaindesk","className":"hidden","docId":"integrations/providers/chaindesk","unlisted":false},{"type":"link","label":"Chroma","href":"/docs/integrations/providers/chroma","className":"hidden","docId":"integrations/providers/chroma","unlisted":false},{"type":"link","label":"Clarifai","href":"/docs/integrations/providers/clarifai","className":"hidden","docId":"integrations/providers/clarifai","unlisted":false},{"type":"link","label":"ClearML","href":"/docs/integrations/providers/clearml_tracking","className":"hidden","docId":"integrations/providers/clearml_tracking","unlisted":false},{"type":"link","label":"ClickHouse","href":"/docs/integrations/providers/clickhouse","className":"hidden","docId":"integrations/providers/clickhouse","unlisted":false},{"type":"link","label":"ClickUp","href":"/docs/integrations/providers/clickup","className":"hidden","docId":"integrations/providers/clickup","unlisted":false},{"type":"link","label":"Cloudflare","href":"/docs/integrations/providers/cloudflare","className":"hidden","docId":"integrations/providers/cloudflare","unlisted":false},{"type":"link","label":"Clova","href":"/docs/integrations/providers/clova","className":"hidden","docId":"integrations/providers/clova","unlisted":false},{"type":"link","label":"CnosDB","href":"/docs/integrations/providers/cnosdb","className":"hidden","docId":"integrations/providers/cnosdb","unlisted":false},{"type":"link","label":"Cognee","href":"/docs/integrations/providers/cognee","className":"hidden","docId":"integrations/providers/cognee","unlisted":false},{"type":"link","label":"CogniSwitch","href":"/docs/integrations/providers/cogniswitch","className":"hidden","docId":"integrations/providers/cogniswitch","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/providers/cohere","className":"hidden","docId":"integrations/providers/cohere","unlisted":false},{"type":"link","label":"College Confidential","href":"/docs/integrations/providers/college_confidential","className":"hidden","docId":"integrations/providers/college_confidential","unlisted":false},{"type":"link","label":"Comet","href":"/docs/integrations/providers/comet_tracking","className":"hidden","docId":"integrations/providers/comet_tracking","unlisted":false},{"type":"link","label":"Confident AI","href":"/docs/integrations/providers/confident","className":"hidden","docId":"integrations/providers/confident","unlisted":false},{"type":"link","label":"Confluence","href":"/docs/integrations/providers/confluence","className":"hidden","docId":"integrations/providers/confluence","unlisted":false},{"type":"link","label":"Connery","href":"/docs/integrations/providers/connery","className":"hidden","docId":"integrations/providers/connery","unlisted":false},{"type":"link","label":"Context","href":"/docs/integrations/providers/context","className":"hidden","docId":"integrations/providers/context","unlisted":false},{"type":"link","label":"Contextual AI","href":"/docs/integrations/providers/contextual","className":"hidden","docId":"integrations/providers/contextual","unlisted":false},{"type":"link","label":"Couchbase","href":"/docs/integrations/providers/couchbase","className":"hidden","docId":"integrations/providers/couchbase","unlisted":false},{"type":"link","label":"Coze","href":"/docs/integrations/providers/coze","className":"hidden","docId":"integrations/providers/coze","unlisted":false},{"type":"link","label":"CrateDB","href":"/docs/integrations/providers/cratedb","className":"hidden","docId":"integrations/providers/cratedb","unlisted":false},{"type":"link","label":"C Transformers","href":"/docs/integrations/providers/ctransformers","className":"hidden","docId":"integrations/providers/ctransformers","unlisted":false},{"type":"link","label":"CTranslate2","href":"/docs/integrations/providers/ctranslate2","className":"hidden","docId":"integrations/providers/ctranslate2","unlisted":false},{"type":"link","label":"Cube","href":"/docs/integrations/providers/cube","className":"hidden","docId":"integrations/providers/cube","unlisted":false},{"type":"link","label":"Dappier","href":"/docs/integrations/providers/dappier","className":"hidden","docId":"integrations/providers/dappier","unlisted":false},{"type":"link","label":"DashVector","href":"/docs/integrations/providers/dashvector","className":"hidden","docId":"integrations/providers/dashvector","unlisted":false},{"type":"link","label":"Databricks","href":"/docs/integrations/providers/databricks","className":"hidden","docId":"integrations/providers/databricks","unlisted":false},{"type":"link","label":"Datadog Tracing","href":"/docs/integrations/providers/datadog","className":"hidden","docId":"integrations/providers/datadog","unlisted":false},{"type":"link","label":"Datadog Logs","href":"/docs/integrations/providers/datadog_logs","className":"hidden","docId":"integrations/providers/datadog_logs","unlisted":false},{"type":"link","label":"DataForSEO","href":"/docs/integrations/providers/dataforseo","className":"hidden","docId":"integrations/providers/dataforseo","unlisted":false},{"type":"link","label":"Dataherald","href":"/docs/integrations/providers/dataherald","className":"hidden","docId":"integrations/providers/dataherald","unlisted":false},{"type":"link","label":"Dedoc","href":"/docs/integrations/providers/dedoc","className":"hidden","docId":"integrations/providers/dedoc","unlisted":false},{"type":"link","label":"DeepInfra","href":"/docs/integrations/providers/deepinfra","className":"hidden","docId":"integrations/providers/deepinfra","unlisted":false},{"type":"link","label":"Deeplake","href":"/docs/integrations/providers/deeplake","className":"hidden","docId":"integrations/providers/deeplake","unlisted":false},{"type":"link","label":"DeepSeek","href":"/docs/integrations/providers/deepseek","className":"hidden","docId":"integrations/providers/deepseek","unlisted":false},{"type":"link","label":"DeepSparse","href":"/docs/integrations/providers/deepsparse","className":"hidden","docId":"integrations/providers/deepsparse","unlisted":false},{"type":"link","label":"Dell","href":"/docs/integrations/providers/dell","className":"hidden","docId":"integrations/providers/dell","unlisted":false},{"type":"link","label":"Diffbot","href":"/docs/integrations/providers/diffbot","className":"hidden","docId":"integrations/providers/diffbot","unlisted":false},{"type":"link","label":"DingoDB","href":"/docs/integrations/providers/dingo","className":"hidden","docId":"integrations/providers/dingo","unlisted":false},{"type":"link","label":"Discord","href":"/docs/integrations/providers/discord-shikenso","className":"hidden","docId":"integrations/providers/discord-shikenso","unlisted":false},{"type":"link","label":"Discord (community loader)","href":"/docs/integrations/providers/discord","className":"hidden","docId":"integrations/providers/discord","unlisted":false},{"type":"link","label":"DocArray","href":"/docs/integrations/providers/docarray","className":"hidden","docId":"integrations/providers/docarray","unlisted":false},{"type":"link","label":"Docling","href":"/docs/integrations/providers/docling","className":"hidden","docId":"integrations/providers/docling","unlisted":false},{"type":"link","label":"Doctran","href":"/docs/integrations/providers/doctran","className":"hidden","docId":"integrations/providers/doctran","unlisted":false},{"type":"link","label":"Docugami","href":"/docs/integrations/providers/docugami","className":"hidden","docId":"integrations/providers/docugami","unlisted":false},{"type":"link","label":"Docusaurus","href":"/docs/integrations/providers/docusaurus","className":"hidden","docId":"integrations/providers/docusaurus","unlisted":false},{"type":"link","label":"Dria","href":"/docs/integrations/providers/dria","className":"hidden","docId":"integrations/providers/dria","unlisted":false},{"type":"link","label":"Dropbox","href":"/docs/integrations/providers/dropbox","className":"hidden","docId":"integrations/providers/dropbox","unlisted":false},{"type":"link","label":"DSPy","href":"/docs/integrations/providers/dspy","className":"hidden","docId":"integrations/providers/dspy","unlisted":false},{"type":"link","label":"DuckDB","href":"/docs/integrations/providers/duckdb","className":"hidden","docId":"integrations/providers/duckdb","unlisted":false},{"type":"link","label":"DuckDuckGo Search","href":"/docs/integrations/providers/duckduckgo_search","className":"hidden","docId":"integrations/providers/duckduckgo_search","unlisted":false},{"type":"link","label":"E2B","href":"/docs/integrations/providers/e2b","className":"hidden","docId":"integrations/providers/e2b","unlisted":false},{"type":"link","label":"Eden AI","href":"/docs/integrations/providers/edenai","className":"hidden","docId":"integrations/providers/edenai","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/providers/elasticsearch","className":"hidden","docId":"integrations/providers/elasticsearch","unlisted":false},{"type":"link","label":"ElevenLabs","href":"/docs/integrations/providers/elevenlabs","className":"hidden","docId":"integrations/providers/elevenlabs","unlisted":false},{"type":"link","label":"Embedchain","href":"/docs/integrations/providers/embedchain","className":"hidden","docId":"integrations/providers/embedchain","unlisted":false},{"type":"link","label":"Epsilla","href":"/docs/integrations/providers/epsilla","className":"hidden","docId":"integrations/providers/epsilla","unlisted":false},{"type":"link","label":"Etherscan","href":"/docs/integrations/providers/etherscan","className":"hidden","docId":"integrations/providers/etherscan","unlisted":false},{"type":"link","label":"Everly AI","href":"/docs/integrations/providers/everlyai","className":"hidden","docId":"integrations/providers/everlyai","unlisted":false},{"type":"link","label":"EverNote","href":"/docs/integrations/providers/evernote","className":"hidden","docId":"integrations/providers/evernote","unlisted":false},{"type":"link","label":"Exa","href":"/docs/integrations/providers/exa_search","className":"hidden","docId":"integrations/providers/exa_search","unlisted":false},{"type":"link","label":"Facebook - Meta","href":"/docs/integrations/providers/facebook","className":"hidden","docId":"integrations/providers/facebook","unlisted":false},{"type":"link","label":"FalkorDB","href":"/docs/integrations/providers/falkordb","className":"hidden","docId":"integrations/providers/falkordb","unlisted":false},{"type":"link","label":"Fauna","href":"/docs/integrations/providers/fauna","className":"hidden","docId":"integrations/providers/fauna","unlisted":false},{"type":"link","label":"Fiddler","href":"/docs/integrations/providers/fiddler","className":"hidden","docId":"integrations/providers/fiddler","unlisted":false},{"type":"link","label":"Figma","href":"/docs/integrations/providers/figma","className":"hidden","docId":"integrations/providers/figma","unlisted":false},{"type":"link","label":"FireCrawl","href":"/docs/integrations/providers/firecrawl","className":"hidden","docId":"integrations/providers/firecrawl","unlisted":false},{"type":"link","label":"Fireworks AI","href":"/docs/integrations/providers/fireworks","className":"hidden","docId":"integrations/providers/fireworks","unlisted":false},{"type":"link","label":"Flyte","href":"/docs/integrations/providers/flyte","className":"hidden","docId":"integrations/providers/flyte","unlisted":false},{"type":"link","label":"FMP Data (Financial Data Prep)","href":"/docs/integrations/providers/fmp-data","className":"hidden","docId":"integrations/providers/fmp-data","unlisted":false},{"type":"link","label":"Forefront AI","href":"/docs/integrations/providers/forefrontai","className":"hidden","docId":"integrations/providers/forefrontai","unlisted":false},{"type":"link","label":"Friendli AI","href":"/docs/integrations/providers/friendli","className":"hidden","docId":"integrations/providers/friendli","unlisted":false},{"type":"link","label":"Geopandas","href":"/docs/integrations/providers/geopandas","className":"hidden","docId":"integrations/providers/geopandas","unlisted":false},{"type":"link","label":"Git","href":"/docs/integrations/providers/git","className":"hidden","docId":"integrations/providers/git","unlisted":false},{"type":"link","label":"GitBook","href":"/docs/integrations/providers/gitbook","className":"hidden","docId":"integrations/providers/gitbook","unlisted":false},{"type":"link","label":"GitHub","href":"/docs/integrations/providers/github","className":"hidden","docId":"integrations/providers/github","unlisted":false},{"type":"link","label":"GitLab","href":"/docs/integrations/providers/gitlab","className":"hidden","docId":"integrations/providers/gitlab","unlisted":false},{"type":"link","label":"Golden","href":"/docs/integrations/providers/golden","className":"hidden","docId":"integrations/providers/golden","unlisted":false},{"type":"link","label":"Goodfire","href":"/docs/integrations/providers/goodfire","className":"hidden","docId":"integrations/providers/goodfire","unlisted":false},{"type":"link","label":"Google","href":"/docs/integrations/providers/google","className":"hidden","docId":"integrations/providers/google","unlisted":false},{"type":"link","label":"Serper - Google Search API","href":"/docs/integrations/providers/google_serper","className":"hidden","docId":"integrations/providers/google_serper","unlisted":false},{"type":"link","label":"GooseAI","href":"/docs/integrations/providers/gooseai","className":"hidden","docId":"integrations/providers/gooseai","unlisted":false},{"type":"link","label":"GPT4All","href":"/docs/integrations/providers/gpt4all","className":"hidden","docId":"integrations/providers/gpt4all","unlisted":false},{"type":"link","label":"Gradient","href":"/docs/integrations/providers/gradient","className":"hidden","docId":"integrations/providers/gradient","unlisted":false},{"type":"link","label":"Graph RAG","href":"/docs/integrations/providers/graph_rag","className":"hidden","docId":"integrations/providers/graph_rag","unlisted":false},{"type":"link","label":"Graphsignal","href":"/docs/integrations/providers/graphsignal","className":"hidden","docId":"integrations/providers/graphsignal","unlisted":false},{"type":"link","label":"Grobid","href":"/docs/integrations/providers/grobid","className":"hidden","docId":"integrations/providers/grobid","unlisted":false},{"type":"link","label":"Groq","href":"/docs/integrations/providers/groq","className":"hidden","docId":"integrations/providers/groq","unlisted":false},{"type":"link","label":"Gutenberg","href":"/docs/integrations/providers/gutenberg","className":"hidden","docId":"integrations/providers/gutenberg","unlisted":false},{"type":"link","label":"Hacker News","href":"/docs/integrations/providers/hacker_news","className":"hidden","docId":"integrations/providers/hacker_news","unlisted":false},{"type":"link","label":"Hazy Research","href":"/docs/integrations/providers/hazy_research","className":"hidden","docId":"integrations/providers/hazy_research","unlisted":false},{"type":"link","label":"Helicone","href":"/docs/integrations/providers/helicone","className":"hidden","docId":"integrations/providers/helicone","unlisted":false},{"type":"link","label":"Hologres","href":"/docs/integrations/providers/hologres","className":"hidden","docId":"integrations/providers/hologres","unlisted":false},{"type":"link","label":"HTML to text","href":"/docs/integrations/providers/html2text","className":"hidden","docId":"integrations/providers/html2text","unlisted":false},{"type":"link","label":"Huawei","href":"/docs/integrations/providers/huawei","className":"hidden","docId":"integrations/providers/huawei","unlisted":false},{"type":"link","label":"Hugging Face","href":"/docs/integrations/providers/huggingface","className":"hidden","docId":"integrations/providers/huggingface","unlisted":false},{"type":"link","label":"Hyperbrowser","href":"/docs/integrations/providers/hyperbrowser","className":"hidden","docId":"integrations/providers/hyperbrowser","unlisted":false},{"type":"link","label":"IBM","href":"/docs/integrations/providers/ibm","className":"hidden","docId":"integrations/providers/ibm","unlisted":false},{"type":"link","label":"IEIT Systems","href":"/docs/integrations/providers/ieit_systems","className":"hidden","docId":"integrations/providers/ieit_systems","unlisted":false},{"type":"link","label":"iFixit","href":"/docs/integrations/providers/ifixit","className":"hidden","docId":"integrations/providers/ifixit","unlisted":false},{"type":"link","label":"iFlytek","href":"/docs/integrations/providers/iflytek","className":"hidden","docId":"integrations/providers/iflytek","unlisted":false},{"type":"link","label":"IMSDb","href":"/docs/integrations/providers/imsdb","className":"hidden","docId":"integrations/providers/imsdb","unlisted":false},{"type":"link","label":"Infinispan VS","href":"/docs/integrations/providers/infinispanvs","className":"hidden","docId":"integrations/providers/infinispanvs","unlisted":false},{"type":"link","label":"Infinity","href":"/docs/integrations/providers/infinity","className":"hidden","docId":"integrations/providers/infinity","unlisted":false},{"type":"link","label":"Infino","href":"/docs/integrations/providers/infino","className":"hidden","docId":"integrations/providers/infino","unlisted":false},{"type":"link","label":"Intel","href":"/docs/integrations/providers/intel","className":"hidden","docId":"integrations/providers/intel","unlisted":false},{"type":"link","label":"Iugu","href":"/docs/integrations/providers/iugu","className":"hidden","docId":"integrations/providers/iugu","unlisted":false},{"type":"link","label":"Jaguar","href":"/docs/integrations/providers/jaguar","className":"hidden","docId":"integrations/providers/jaguar","unlisted":false},{"type":"link","label":"Javelin AI Gateway","href":"/docs/integrations/providers/javelin_ai_gateway","className":"hidden","docId":"integrations/providers/javelin_ai_gateway","unlisted":false},{"type":"link","label":"Jenkins","href":"/docs/integrations/providers/jenkins","className":"hidden","docId":"integrations/providers/jenkins","unlisted":false},{"type":"link","label":"Jina AI","href":"/docs/integrations/providers/jina","className":"hidden","docId":"integrations/providers/jina","unlisted":false},{"type":"link","label":"Johnsnowlabs","href":"/docs/integrations/providers/johnsnowlabs","className":"hidden","docId":"integrations/providers/johnsnowlabs","unlisted":false},{"type":"link","label":"Joplin","href":"/docs/integrations/providers/joplin","className":"hidden","docId":"integrations/providers/joplin","unlisted":false},{"type":"link","label":"KDB.AI","href":"/docs/integrations/providers/kdbai","className":"hidden","docId":"integrations/providers/kdbai","unlisted":false},{"type":"link","label":"Kinetica","href":"/docs/integrations/providers/kinetica","className":"hidden","docId":"integrations/providers/kinetica","unlisted":false},{"type":"link","label":"KoboldAI","href":"/docs/integrations/providers/koboldai","className":"hidden","docId":"integrations/providers/koboldai","unlisted":false},{"type":"link","label":"Konko","href":"/docs/integrations/providers/konko","className":"hidden","docId":"integrations/providers/konko","unlisted":false},{"type":"link","label":"KoNLPY","href":"/docs/integrations/providers/konlpy","className":"hidden","docId":"integrations/providers/konlpy","unlisted":false},{"type":"link","label":"K\xf9zu","href":"/docs/integrations/providers/kuzu","className":"hidden","docId":"integrations/providers/kuzu","unlisted":false},{"type":"link","label":"Label Studio","href":"/docs/integrations/providers/labelstudio","className":"hidden","docId":"integrations/providers/labelstudio","unlisted":false},{"type":"link","label":"lakeFS","href":"/docs/integrations/providers/lakefs","className":"hidden","docId":"integrations/providers/lakefs","unlisted":false},{"type":"link","label":"LanceDB","href":"/docs/integrations/providers/lancedb","className":"hidden","docId":"integrations/providers/lancedb","unlisted":false},{"type":"link","label":"LangChain Decorators \u2728","href":"/docs/integrations/providers/langchain_decorators","className":"hidden","docId":"integrations/providers/langchain_decorators","unlisted":false},{"type":"link","label":"LangFair: Use-Case Level LLM Bias and Fairness Assessments","href":"/docs/integrations/providers/langfair","className":"hidden","docId":"integrations/providers/langfair","unlisted":false},{"type":"link","label":"Lantern","href":"/docs/integrations/providers/lantern","className":"hidden","docId":"integrations/providers/lantern","unlisted":false},{"type":"link","label":"Lindorm","href":"/docs/integrations/providers/lindorm","className":"hidden","docId":"integrations/providers/lindorm","unlisted":false},{"type":"link","label":"Linkup","href":"/docs/integrations/providers/linkup","className":"hidden","docId":"integrations/providers/linkup","unlisted":false},{"type":"link","label":"LiteLLM","href":"/docs/integrations/providers/littlellm","className":"hidden","docId":"integrations/providers/littlellm","unlisted":false},{"type":"link","label":"LlamaIndex","href":"/docs/integrations/providers/llama_index","className":"hidden","docId":"integrations/providers/llama_index","unlisted":false},{"type":"link","label":"Llama.cpp","href":"/docs/integrations/providers/llamacpp","className":"hidden","docId":"integrations/providers/llamacpp","unlisted":false},{"type":"link","label":"LlamaEdge","href":"/docs/integrations/providers/llamaedge","className":"hidden","docId":"integrations/providers/llamaedge","unlisted":false},{"type":"link","label":"llamafile","href":"/docs/integrations/providers/llamafile","className":"hidden","docId":"integrations/providers/llamafile","unlisted":false},{"type":"link","label":"LLMonitor","href":"/docs/integrations/providers/llmonitor","className":"hidden","docId":"integrations/providers/llmonitor","unlisted":false},{"type":"link","label":"LocalAI","href":"/docs/integrations/providers/localai","className":"hidden","docId":"integrations/providers/localai","unlisted":false},{"type":"link","label":"Log10","href":"/docs/integrations/providers/log10","className":"hidden","docId":"integrations/providers/log10","unlisted":false},{"type":"link","label":"MariTalk","href":"/docs/integrations/providers/maritalk","className":"hidden","docId":"integrations/providers/maritalk","unlisted":false},{"type":"link","label":"Marqo","href":"/docs/integrations/providers/marqo","className":"hidden","docId":"integrations/providers/marqo","unlisted":false},{"type":"link","label":"MediaWikiDump","href":"/docs/integrations/providers/mediawikidump","className":"hidden","docId":"integrations/providers/mediawikidump","unlisted":false},{"type":"link","label":"Meilisearch","href":"/docs/integrations/providers/meilisearch","className":"hidden","docId":"integrations/providers/meilisearch","unlisted":false},{"type":"link","label":"Memcached","href":"/docs/integrations/providers/memcached","className":"hidden","docId":"integrations/providers/memcached","unlisted":false},{"type":"link","label":"Metal","href":"/docs/integrations/providers/metal","className":"hidden","docId":"integrations/providers/metal","unlisted":false},{"type":"link","label":"Microsoft","href":"/docs/integrations/providers/microsoft","className":"hidden","docId":"integrations/providers/microsoft","unlisted":false},{"type":"link","label":"Milvus","href":"/docs/integrations/providers/milvus","className":"hidden","docId":"integrations/providers/milvus","unlisted":false},{"type":"link","label":"MindsDB","href":"/docs/integrations/providers/mindsdb","className":"hidden","docId":"integrations/providers/mindsdb","unlisted":false},{"type":"link","label":"Minimax","href":"/docs/integrations/providers/minimax","className":"hidden","docId":"integrations/providers/minimax","unlisted":false},{"type":"link","label":"MistralAI","href":"/docs/integrations/providers/mistralai","className":"hidden","docId":"integrations/providers/mistralai","unlisted":false},{"type":"link","label":"MLflow AI Gateway for LLMs","href":"/docs/integrations/providers/mlflow","className":"hidden","docId":"integrations/providers/mlflow","unlisted":false},{"type":"link","label":"MLflow","href":"/docs/integrations/providers/mlflow_tracking","className":"hidden","docId":"integrations/providers/mlflow_tracking","unlisted":false},{"type":"link","label":"MLX","href":"/docs/integrations/providers/mlx","className":"hidden","docId":"integrations/providers/mlx","unlisted":false},{"type":"link","label":"Modal","href":"/docs/integrations/providers/modal","className":"hidden","docId":"integrations/providers/modal","unlisted":false},{"type":"link","label":"ModelScope","href":"/docs/integrations/providers/modelscope","className":"hidden","docId":"integrations/providers/modelscope","unlisted":false},{"type":"link","label":"Modern Treasury","href":"/docs/integrations/providers/modern_treasury","className":"hidden","docId":"integrations/providers/modern_treasury","unlisted":false},{"type":"link","label":"Momento","href":"/docs/integrations/providers/momento","className":"hidden","docId":"integrations/providers/momento","unlisted":false},{"type":"link","label":"MongoDB","href":"/docs/integrations/providers/mongodb","className":"hidden","docId":"integrations/providers/mongodb","unlisted":false},{"type":"link","label":"MongoDB Atlas","href":"/docs/integrations/providers/mongodb_atlas","className":"hidden","docId":"integrations/providers/mongodb_atlas","unlisted":false},{"type":"link","label":"Motherduck","href":"/docs/integrations/providers/motherduck","className":"hidden","docId":"integrations/providers/motherduck","unlisted":false},{"type":"link","label":"Mot\xf6rhead","href":"/docs/integrations/providers/motorhead","className":"hidden","docId":"integrations/providers/motorhead","unlisted":false},{"type":"link","label":"MyScale","href":"/docs/integrations/providers/myscale","className":"hidden","docId":"integrations/providers/myscale","unlisted":false},{"type":"link","label":"NAVER","href":"/docs/integrations/providers/naver","className":"hidden","docId":"integrations/providers/naver","unlisted":false},{"type":"link","label":"Neo4j","href":"/docs/integrations/providers/neo4j","className":"hidden","docId":"integrations/providers/neo4j","unlisted":false},{"type":"link","label":"Nimble","href":"/docs/integrations/providers/nimble","className":"hidden","docId":"integrations/providers/nimble","unlisted":false},{"type":"link","label":"NLPCloud","href":"/docs/integrations/providers/nlpcloud","className":"hidden","docId":"integrations/providers/nlpcloud","unlisted":false},{"type":"link","label":"Nomic","href":"/docs/integrations/providers/nomic","className":"hidden","docId":"integrations/providers/nomic","unlisted":false},{"type":"link","label":"Notion DB","href":"/docs/integrations/providers/notion","className":"hidden","docId":"integrations/providers/notion","unlisted":false},{"type":"link","label":"Nuclia","href":"/docs/integrations/providers/nuclia","className":"hidden","docId":"integrations/providers/nuclia","unlisted":false},{"type":"link","label":"NVIDIA","href":"/docs/integrations/providers/nvidia","className":"hidden","docId":"integrations/providers/nvidia","unlisted":false},{"type":"link","label":"Obsidian","href":"/docs/integrations/providers/obsidian","className":"hidden","docId":"integrations/providers/obsidian","unlisted":false},{"type":"link","label":"OceanBase","href":"/docs/integrations/providers/oceanbase","className":"hidden","docId":"integrations/providers/oceanbase","unlisted":false},{"type":"link","label":"Oracle Cloud Infrastructure (OCI)","href":"/docs/integrations/providers/oci","className":"hidden","docId":"integrations/providers/oci","unlisted":false},{"type":"link","label":"OctoAI","href":"/docs/integrations/providers/octoai","className":"hidden","docId":"integrations/providers/octoai","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/providers/ollama","className":"hidden","docId":"integrations/providers/ollama","unlisted":false},{"type":"link","label":"Ontotext GraphDB","href":"/docs/integrations/providers/ontotext_graphdb","className":"hidden","docId":"integrations/providers/ontotext_graphdb","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/providers/openai","className":"hidden","docId":"integrations/providers/openai","unlisted":false},{"type":"link","label":"OpenGradient","href":"/docs/integrations/providers/opengradient","className":"hidden","docId":"integrations/providers/opengradient","unlisted":false},{"type":"link","label":"OpenLLM","href":"/docs/integrations/providers/openllm","className":"hidden","docId":"integrations/providers/openllm","unlisted":false},{"type":"link","label":"OpenSearch","href":"/docs/integrations/providers/opensearch","className":"hidden","docId":"integrations/providers/opensearch","unlisted":false},{"type":"link","label":"OpenWeatherMap","href":"/docs/integrations/providers/openweathermap","className":"hidden","docId":"integrations/providers/openweathermap","unlisted":false},{"type":"link","label":"OracleAI Vector Search","href":"/docs/integrations/providers/oracleai","className":"hidden","docId":"integrations/providers/oracleai","unlisted":false},{"type":"link","label":"Outline","href":"/docs/integrations/providers/outline","className":"hidden","docId":"integrations/providers/outline","unlisted":false},{"type":"link","label":"Outlines","href":"/docs/integrations/providers/outlines","className":"hidden","docId":"integrations/providers/outlines","unlisted":false},{"type":"link","label":"Pandas","href":"/docs/integrations/providers/pandas","className":"hidden","docId":"integrations/providers/pandas","unlisted":false},{"type":"link","label":"PaymanAI","href":"/docs/integrations/providers/payman-tool","className":"hidden","docId":"integrations/providers/payman-tool","unlisted":false},{"type":"category","label":"Pebblo","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Identity-enabled RAG using PebbloRetrievalQA","href":"/docs/integrations/providers/pebblo/pebblo_retrieval_qa","docId":"integrations/providers/pebblo/pebblo_retrieval_qa","unlisted":false}],"className":"hidden","href":"/docs/integrations/providers/pebblo/"},{"type":"link","label":"Permit","href":"/docs/integrations/providers/permit","className":"hidden","docId":"integrations/providers/permit","unlisted":false},{"type":"link","label":"Perplexity","href":"/docs/integrations/providers/perplexity","className":"hidden","docId":"integrations/providers/perplexity","unlisted":false},{"type":"link","label":"Petals","href":"/docs/integrations/providers/petals","className":"hidden","docId":"integrations/providers/petals","unlisted":false},{"type":"link","label":"Postgres Embedding","href":"/docs/integrations/providers/pg_embedding","className":"hidden","docId":"integrations/providers/pg_embedding","unlisted":false},{"type":"link","label":"PGVector","href":"/docs/integrations/providers/pgvector","className":"hidden","docId":"integrations/providers/pgvector","unlisted":false},{"type":"link","label":"Pinecone","href":"/docs/integrations/providers/pinecone","className":"hidden","docId":"integrations/providers/pinecone","unlisted":false},{"type":"link","label":"PipelineAI","href":"/docs/integrations/providers/pipelineai","className":"hidden","docId":"integrations/providers/pipelineai","unlisted":false},{"type":"link","label":"Pipeshift","href":"/docs/integrations/providers/pipeshift","className":"hidden","docId":"integrations/providers/pipeshift","unlisted":false},{"type":"category","label":"Portkey","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Log, Trace, and Monitor","href":"/docs/integrations/providers/portkey/logging_tracing_portkey","docId":"integrations/providers/portkey/logging_tracing_portkey","unlisted":false}],"className":"hidden","href":"/docs/integrations/providers/portkey/"},{"type":"link","label":"Predibase","href":"/docs/integrations/providers/predibase","className":"hidden","docId":"integrations/providers/predibase","unlisted":false},{"type":"link","label":"Prediction Guard","href":"/docs/integrations/providers/predictionguard","className":"hidden","docId":"integrations/providers/predictionguard","unlisted":false},{"type":"link","label":"PremAI","href":"/docs/integrations/providers/premai","className":"hidden","docId":"integrations/providers/premai","unlisted":false},{"type":"link","label":"SWI-Prolog","href":"/docs/integrations/providers/prolog","className":"hidden","docId":"integrations/providers/prolog","unlisted":false},{"type":"link","label":"PromptLayer","href":"/docs/integrations/providers/promptlayer","className":"hidden","docId":"integrations/providers/promptlayer","unlisted":false},{"type":"link","label":"Psychic","href":"/docs/integrations/providers/psychic","className":"hidden","docId":"integrations/providers/psychic","unlisted":false},{"type":"link","label":"PubMed","href":"/docs/integrations/providers/pubmed","className":"hidden","docId":"integrations/providers/pubmed","unlisted":false},{"type":"link","label":"PullMd Loader","href":"/docs/integrations/providers/pull-md","className":"hidden","docId":"integrations/providers/pull-md","unlisted":false},{"type":"link","label":"PygmalionAI","href":"/docs/integrations/providers/pygmalionai","className":"hidden","docId":"integrations/providers/pygmalionai","unlisted":false},{"type":"link","label":"PyMuPDF4LLM","href":"/docs/integrations/providers/pymupdf4llm","className":"hidden","docId":"integrations/providers/pymupdf4llm","unlisted":false},{"type":"link","label":"Qdrant","href":"/docs/integrations/providers/qdrant","className":"hidden","docId":"integrations/providers/qdrant","unlisted":false},{"type":"link","label":"RAGatouille","href":"/docs/integrations/providers/ragatouille","className":"hidden","docId":"integrations/providers/ragatouille","unlisted":false},{"type":"link","label":"rank_bm25","href":"/docs/integrations/providers/rank_bm25","className":"hidden","docId":"integrations/providers/rank_bm25","unlisted":false},{"type":"link","label":"Ray Serve","href":"/docs/integrations/providers/ray_serve","className":"hidden","docId":"integrations/providers/ray_serve","unlisted":false},{"type":"link","label":"Rebuff","href":"/docs/integrations/providers/rebuff","className":"hidden","docId":"integrations/providers/rebuff","unlisted":false},{"type":"link","label":"Reddit","href":"/docs/integrations/providers/reddit","className":"hidden","docId":"integrations/providers/reddit","unlisted":false},{"type":"link","label":"Redis","href":"/docs/integrations/providers/redis","className":"hidden","docId":"integrations/providers/redis","unlisted":false},{"type":"link","label":"Remembrall","href":"/docs/integrations/providers/remembrall","className":"hidden","docId":"integrations/providers/remembrall","unlisted":false},{"type":"link","label":"Replicate","href":"/docs/integrations/providers/replicate","className":"hidden","docId":"integrations/providers/replicate","unlisted":false},{"type":"link","label":"Roam","href":"/docs/integrations/providers/roam","className":"hidden","docId":"integrations/providers/roam","unlisted":false},{"type":"link","label":"Sema4 (fka Robocorp)","href":"/docs/integrations/providers/robocorp","className":"hidden","docId":"integrations/providers/robocorp","unlisted":false},{"type":"link","label":"Rockset","href":"/docs/integrations/providers/rockset","className":"hidden","docId":"integrations/providers/rockset","unlisted":false},{"type":"link","label":"Runhouse","href":"/docs/integrations/providers/runhouse","className":"hidden","docId":"integrations/providers/runhouse","unlisted":false},{"type":"link","label":"RWKV-4","href":"/docs/integrations/providers/rwkv","className":"hidden","docId":"integrations/providers/rwkv","unlisted":false},{"type":"link","label":"Salesforce","href":"/docs/integrations/providers/salesforce","className":"hidden","docId":"integrations/providers/salesforce","unlisted":false},{"type":"link","label":"Salute Devices","href":"/docs/integrations/providers/salute_devices","className":"hidden","docId":"integrations/providers/salute_devices","unlisted":false},{"type":"link","label":"SambaNova","href":"/docs/integrations/providers/sambanova","className":"hidden","docId":"integrations/providers/sambanova","unlisted":false},{"type":"link","label":"SAP","href":"/docs/integrations/providers/sap","className":"hidden","docId":"integrations/providers/sap","unlisted":false},{"type":"link","label":"ScrapeGraph AI","href":"/docs/integrations/providers/scrapegraph","className":"hidden","docId":"integrations/providers/scrapegraph","unlisted":false},{"type":"link","label":"SearchApi","href":"/docs/integrations/providers/searchapi","className":"hidden","docId":"integrations/providers/searchapi","unlisted":false},{"type":"link","label":"SearxNG Search API","href":"/docs/integrations/providers/searx","className":"hidden","docId":"integrations/providers/searx","unlisted":false},{"type":"link","label":"SemaDB","href":"/docs/integrations/providers/semadb","className":"hidden","docId":"integrations/providers/semadb","unlisted":false},{"type":"link","label":"SerpAPI","href":"/docs/integrations/providers/serpapi","className":"hidden","docId":"integrations/providers/serpapi","unlisted":false},{"type":"link","label":"Shale Protocol","href":"/docs/integrations/providers/shaleprotocol","className":"hidden","docId":"integrations/providers/shaleprotocol","unlisted":false},{"type":"link","label":"SingleStoreDB","href":"/docs/integrations/providers/singlestoredb","className":"hidden","docId":"integrations/providers/singlestoredb","unlisted":false},{"type":"link","label":"scikit-learn","href":"/docs/integrations/providers/sklearn","className":"hidden","docId":"integrations/providers/sklearn","unlisted":false},{"type":"link","label":"Slack","href":"/docs/integrations/providers/slack","className":"hidden","docId":"integrations/providers/slack","unlisted":false},{"type":"link","label":"Snowflake","href":"/docs/integrations/providers/snowflake","className":"hidden","docId":"integrations/providers/snowflake","unlisted":false},{"type":"link","label":"spaCy","href":"/docs/integrations/providers/spacy","className":"hidden","docId":"integrations/providers/spacy","unlisted":false},{"type":"link","label":"Spark","href":"/docs/integrations/providers/spark","className":"hidden","docId":"integrations/providers/spark","unlisted":false},{"type":"link","label":"SparkLLM","href":"/docs/integrations/providers/sparkllm","className":"hidden","docId":"integrations/providers/sparkllm","unlisted":false},{"type":"link","label":"Spreedly","href":"/docs/integrations/providers/spreedly","className":"hidden","docId":"integrations/providers/spreedly","unlisted":false},{"type":"link","label":"SQLite","href":"/docs/integrations/providers/sqlite","className":"hidden","docId":"integrations/providers/sqlite","unlisted":false},{"type":"link","label":"Stack Exchange","href":"/docs/integrations/providers/stackexchange","className":"hidden","docId":"integrations/providers/stackexchange","unlisted":false},{"type":"link","label":"StarRocks","href":"/docs/integrations/providers/starrocks","className":"hidden","docId":"integrations/providers/starrocks","unlisted":false},{"type":"link","label":"StochasticAI","href":"/docs/integrations/providers/stochasticai","className":"hidden","docId":"integrations/providers/stochasticai","unlisted":false},{"type":"link","label":"Streamlit","href":"/docs/integrations/providers/streamlit","className":"hidden","docId":"integrations/providers/streamlit","unlisted":false},{"type":"link","label":"Stripe","href":"/docs/integrations/providers/stripe","className":"hidden","docId":"integrations/providers/stripe","unlisted":false},{"type":"link","label":"Supabase (Postgres)","href":"/docs/integrations/providers/supabase","className":"hidden","docId":"integrations/providers/supabase","unlisted":false},{"type":"link","label":"Nebula","href":"/docs/integrations/providers/symblai_nebula","className":"hidden","docId":"integrations/providers/symblai_nebula","unlisted":false},{"type":"link","label":"Tableau","href":"/docs/integrations/providers/tableau","className":"hidden","docId":"integrations/providers/tableau","unlisted":false},{"type":"link","label":"Taiga","href":"/docs/integrations/providers/taiga","className":"hidden","docId":"integrations/providers/taiga","unlisted":false},{"type":"link","label":"Tair","href":"/docs/integrations/providers/tair","className":"hidden","docId":"integrations/providers/tair","unlisted":false},{"type":"link","label":"Tavily","href":"/docs/integrations/providers/tavily","className":"hidden","docId":"integrations/providers/tavily","unlisted":false},{"type":"link","label":"Telegram","href":"/docs/integrations/providers/telegram","className":"hidden","docId":"integrations/providers/telegram","unlisted":false},{"type":"link","label":"Tencent","href":"/docs/integrations/providers/tencent","className":"hidden","docId":"integrations/providers/tencent","unlisted":false},{"type":"link","label":"TensorFlow Datasets","href":"/docs/integrations/providers/tensorflow_datasets","className":"hidden","docId":"integrations/providers/tensorflow_datasets","unlisted":false},{"type":"link","label":"TiDB","href":"/docs/integrations/providers/tidb","className":"hidden","docId":"integrations/providers/tidb","unlisted":false},{"type":"link","label":"TigerGraph","href":"/docs/integrations/providers/tigergraph","className":"hidden","docId":"integrations/providers/tigergraph","unlisted":false},{"type":"link","label":"Tigris","href":"/docs/integrations/providers/tigris","className":"hidden","docId":"integrations/providers/tigris","unlisted":false},{"type":"link","label":"Tilores","href":"/docs/integrations/providers/tilores","className":"hidden","docId":"integrations/providers/tilores","unlisted":false},{"type":"link","label":"Together AI","href":"/docs/integrations/providers/together","className":"hidden","docId":"integrations/providers/together","unlisted":false},{"type":"link","label":"2Markdown","href":"/docs/integrations/providers/tomarkdown","className":"hidden","docId":"integrations/providers/tomarkdown","unlisted":false},{"type":"link","label":"Transwarp","href":"/docs/integrations/providers/transwarp","className":"hidden","docId":"integrations/providers/transwarp","unlisted":false},{"type":"link","label":"Trello","href":"/docs/integrations/providers/trello","className":"hidden","docId":"integrations/providers/trello","unlisted":false},{"type":"link","label":"Trubrics","href":"/docs/integrations/providers/trubrics","className":"hidden","docId":"integrations/providers/trubrics","unlisted":false},{"type":"link","label":"TruLens","href":"/docs/integrations/providers/trulens","className":"hidden","docId":"integrations/providers/trulens","unlisted":false},{"type":"link","label":"Twitter","href":"/docs/integrations/providers/twitter","className":"hidden","docId":"integrations/providers/twitter","unlisted":false},{"type":"link","label":"Typesense","href":"/docs/integrations/providers/typesense","className":"hidden","docId":"integrations/providers/typesense","unlisted":false},{"type":"link","label":"Unstructured","href":"/docs/integrations/providers/unstructured","className":"hidden","docId":"integrations/providers/unstructured","unlisted":false},{"type":"link","label":"Upstage","href":"/docs/integrations/providers/upstage","className":"hidden","docId":"integrations/providers/upstage","unlisted":false},{"type":"link","label":"upstash","href":"/docs/integrations/providers/upstash","className":"hidden","docId":"integrations/providers/upstash","unlisted":false},{"type":"link","label":"UpTrain","href":"/docs/integrations/providers/uptrain","className":"hidden","docId":"integrations/providers/uptrain","unlisted":false},{"type":"link","label":"USearch","href":"/docs/integrations/providers/usearch","className":"hidden","docId":"integrations/providers/usearch","unlisted":false},{"type":"link","label":"Valthera","href":"/docs/integrations/providers/valthera","className":"hidden","docId":"integrations/providers/valthera","unlisted":false},{"type":"link","label":"VDMS","href":"/docs/integrations/providers/vdms","className":"hidden","docId":"integrations/providers/vdms","unlisted":false},{"type":"link","label":"Vearch","href":"/docs/integrations/providers/vearch","className":"hidden","docId":"integrations/providers/vearch","unlisted":false},{"type":"category","label":"Vectara","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Vectara Chat","href":"/docs/integrations/providers/vectara/vectara_chat","docId":"integrations/providers/vectara/vectara_chat","unlisted":false}],"className":"hidden","href":"/docs/integrations/providers/vectara/"},{"type":"link","label":"Vespa","href":"/docs/integrations/providers/vespa","className":"hidden","docId":"integrations/providers/vespa","unlisted":false},{"type":"link","label":"vlite","href":"/docs/integrations/providers/vlite","className":"hidden","docId":"integrations/providers/vlite","unlisted":false},{"type":"link","label":"VoyageAI","href":"/docs/integrations/providers/voyageai","className":"hidden","docId":"integrations/providers/voyageai","unlisted":false},{"type":"link","label":"Weights & Biases","href":"/docs/integrations/providers/wandb","className":"hidden","docId":"integrations/providers/wandb","unlisted":false},{"type":"link","label":"Weights & Biases tracing","href":"/docs/integrations/providers/wandb_tracing","className":"hidden","docId":"integrations/providers/wandb_tracing","unlisted":false},{"type":"link","label":"Weights & Biases tracking","href":"/docs/integrations/providers/wandb_tracking","className":"hidden","docId":"integrations/providers/wandb_tracking","unlisted":false},{"type":"link","label":"Weather","href":"/docs/integrations/providers/weather","className":"hidden","docId":"integrations/providers/weather","unlisted":false},{"type":"link","label":"Weaviate","href":"/docs/integrations/providers/weaviate","className":"hidden","docId":"integrations/providers/weaviate","unlisted":false},{"type":"link","label":"WhatsApp","href":"/docs/integrations/providers/whatsapp","className":"hidden","docId":"integrations/providers/whatsapp","unlisted":false},{"type":"link","label":"WhyLabs","href":"/docs/integrations/providers/whylabs_profiling","className":"hidden","docId":"integrations/providers/whylabs_profiling","unlisted":false},{"type":"link","label":"Wikipedia","href":"/docs/integrations/providers/wikipedia","className":"hidden","docId":"integrations/providers/wikipedia","unlisted":false},{"type":"link","label":"Wolfram Alpha","href":"/docs/integrations/providers/wolfram_alpha","className":"hidden","docId":"integrations/providers/wolfram_alpha","unlisted":false},{"type":"link","label":"Writer, Inc.","href":"/docs/integrations/providers/writer","className":"hidden","docId":"integrations/providers/writer","unlisted":false},{"type":"link","label":"xAI","href":"/docs/integrations/providers/xai","className":"hidden","docId":"integrations/providers/xai","unlisted":false},{"type":"link","label":"Xata","href":"/docs/integrations/providers/xata","className":"hidden","docId":"integrations/providers/xata","unlisted":false},{"type":"link","label":"Xorbits Inference (Xinference)","href":"/docs/integrations/providers/xinference","className":"hidden","docId":"integrations/providers/xinference","unlisted":false},{"type":"link","label":"Yahoo","href":"/docs/integrations/providers/yahoo","className":"hidden","docId":"integrations/providers/yahoo","unlisted":false},{"type":"link","label":"Yandex","href":"/docs/integrations/providers/yandex","className":"hidden","docId":"integrations/providers/yandex","unlisted":false},{"type":"link","label":"Yeager.ai","href":"/docs/integrations/providers/yeagerai","className":"hidden","docId":"integrations/providers/yeagerai","unlisted":false},{"type":"link","label":"Yellowbrick","href":"/docs/integrations/providers/yellowbrick","className":"hidden","docId":"integrations/providers/yellowbrick","unlisted":false},{"type":"link","label":"01.AI","href":"/docs/integrations/providers/yi","className":"hidden","docId":"integrations/providers/yi","unlisted":false},{"type":"link","label":"You","href":"/docs/integrations/providers/you","className":"hidden","docId":"integrations/providers/you","unlisted":false},{"type":"link","label":"YouTube","href":"/docs/integrations/providers/youtube","className":"hidden","docId":"integrations/providers/youtube","unlisted":false},{"type":"link","label":"Zep","href":"/docs/integrations/providers/zep","className":"hidden","docId":"integrations/providers/zep","unlisted":false},{"type":"link","label":"Zhipu AI","href":"/docs/integrations/providers/zhipuai","className":"hidden","docId":"integrations/providers/zhipuai","unlisted":false},{"type":"link","label":"Zilliz","href":"/docs/integrations/providers/zilliz","className":"hidden","docId":"integrations/providers/zilliz","unlisted":false},{"type":"link","label":"Zotero","href":"/docs/integrations/providers/zotero","className":"hidden","docId":"integrations/providers/zotero","unlisted":false}],"collapsed":false,"href":"/docs/integrations/providers/all"}],"collapsed":false,"href":"/docs/integrations/providers/"},{"type":"category","label":"Components","collapsible":false,"items":[{"type":"category","label":"Chat models","collapsible":false,"items":[{"type":"link","label":"Chat models","href":"/docs/integrations/chat/","className":"hidden","docId":"integrations/chat/index","unlisted":false},{"type":"link","label":"Abso","href":"/docs/integrations/chat/abso","className":"hidden","docId":"integrations/chat/abso","unlisted":false},{"type":"link","label":"AI21 Labs","href":"/docs/integrations/chat/ai21","className":"hidden","docId":"integrations/chat/ai21","unlisted":false},{"type":"link","label":"Alibaba Cloud PAI EAS","href":"/docs/integrations/chat/alibaba_cloud_pai_eas","className":"hidden","docId":"integrations/chat/alibaba_cloud_pai_eas","unlisted":false},{"type":"link","label":"Anthropic","href":"/docs/integrations/chat/anthropic","className":"hidden","docId":"integrations/chat/anthropic","unlisted":false},{"type":"link","label":"[Deprecated] Experimental Anthropic Tools Wrapper","href":"/docs/integrations/chat/anthropic_functions","className":"hidden","docId":"integrations/chat/anthropic_functions","unlisted":false},{"type":"link","label":"Anyscale","href":"/docs/integrations/chat/anyscale","className":"hidden","docId":"integrations/chat/anyscale","unlisted":false},{"type":"link","label":"AzureAIChatCompletionsModel","href":"/docs/integrations/chat/azure_ai","className":"hidden","docId":"integrations/chat/azure_ai","unlisted":false},{"type":"link","label":"Azure OpenAI","href":"/docs/integrations/chat/azure_chat_openai","className":"hidden","docId":"integrations/chat/azure_chat_openai","unlisted":false},{"type":"link","label":"Azure ML Endpoint","href":"/docs/integrations/chat/azureml_chat_endpoint","className":"hidden","docId":"integrations/chat/azureml_chat_endpoint","unlisted":false},{"type":"link","label":"Baichuan Chat","href":"/docs/integrations/chat/baichuan","className":"hidden","docId":"integrations/chat/baichuan","unlisted":false},{"type":"link","label":"Baidu Qianfan","href":"/docs/integrations/chat/baidu_qianfan_endpoint","className":"hidden","docId":"integrations/chat/baidu_qianfan_endpoint","unlisted":false},{"type":"link","label":"AWS Bedrock","href":"/docs/integrations/chat/bedrock","className":"hidden","docId":"integrations/chat/bedrock","unlisted":false},{"type":"link","label":"Cerebras","href":"/docs/integrations/chat/cerebras","className":"hidden","docId":"integrations/chat/cerebras","unlisted":false},{"type":"link","label":"Cloudflare Workers AI","href":"/docs/integrations/chat/cloudflare_workersai","className":"hidden","docId":"integrations/chat/cloudflare_workersai","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/chat/cohere","className":"hidden","docId":"integrations/chat/cohere","unlisted":false},{"type":"link","label":"ContextualAI","href":"/docs/integrations/chat/contextual","className":"hidden","docId":"integrations/chat/contextual","unlisted":false},{"type":"link","label":"Coze Chat","href":"/docs/integrations/chat/coze","className":"hidden","docId":"integrations/chat/coze","unlisted":false},{"type":"link","label":"Dappier AI","href":"/docs/integrations/chat/dappier","className":"hidden","docId":"integrations/chat/dappier","unlisted":false},{"type":"link","label":"Databricks","href":"/docs/integrations/chat/databricks","className":"hidden","docId":"integrations/chat/databricks","unlisted":false},{"type":"link","label":"DeepInfra","href":"/docs/integrations/chat/deepinfra","className":"hidden","docId":"integrations/chat/deepinfra","unlisted":false},{"type":"link","label":"DeepSeek","href":"/docs/integrations/chat/deepseek","className":"hidden","docId":"integrations/chat/deepseek","unlisted":false},{"type":"link","label":"Eden AI","href":"/docs/integrations/chat/edenai","className":"hidden","docId":"integrations/chat/edenai","unlisted":false},{"type":"link","label":"Ernie Bot Chat","href":"/docs/integrations/chat/ernie","className":"hidden","docId":"integrations/chat/ernie","unlisted":false},{"type":"link","label":"EverlyAI","href":"/docs/integrations/chat/everlyai","className":"hidden","docId":"integrations/chat/everlyai","unlisted":false},{"type":"link","label":"Fireworks","href":"/docs/integrations/chat/fireworks","className":"hidden","docId":"integrations/chat/fireworks","unlisted":false},{"type":"link","label":"ChatFriendli","href":"/docs/integrations/chat/friendli","className":"hidden","docId":"integrations/chat/friendli","unlisted":false},{"type":"link","label":"GigaChat","href":"/docs/integrations/chat/gigachat","className":"hidden","docId":"integrations/chat/gigachat","unlisted":false},{"type":"link","label":"Goodfire","href":"/docs/integrations/chat/goodfire","className":"hidden","docId":"integrations/chat/goodfire","unlisted":false},{"type":"link","label":"Google AI","href":"/docs/integrations/chat/google_generative_ai","className":"hidden","docId":"integrations/chat/google_generative_ai","unlisted":false},{"type":"link","label":"Google Cloud Vertex AI","href":"/docs/integrations/chat/google_vertex_ai_palm","className":"hidden","docId":"integrations/chat/google_vertex_ai_palm","unlisted":false},{"type":"link","label":"GPTRouter","href":"/docs/integrations/chat/gpt_router","className":"hidden","docId":"integrations/chat/gpt_router","unlisted":false},{"type":"link","label":"Groq","href":"/docs/integrations/chat/groq","className":"hidden","docId":"integrations/chat/groq","unlisted":false},{"type":"link","label":"ChatHuggingFace","href":"/docs/integrations/chat/huggingface","className":"hidden","docId":"integrations/chat/huggingface","unlisted":false},{"type":"link","label":"IBM watsonx.ai","href":"/docs/integrations/chat/ibm_watsonx","className":"hidden","docId":"integrations/chat/ibm_watsonx","unlisted":false},{"type":"link","label":"JinaChat","href":"/docs/integrations/chat/jinachat","className":"hidden","docId":"integrations/chat/jinachat","unlisted":false},{"type":"link","label":"Kinetica","href":"/docs/integrations/chat/kinetica","className":"hidden","docId":"integrations/chat/kinetica","unlisted":false},{"type":"link","label":"Konko","href":"/docs/integrations/chat/konko","className":"hidden","docId":"integrations/chat/konko","unlisted":false},{"type":"link","label":"LiteLLM","href":"/docs/integrations/chat/litellm","className":"hidden","docId":"integrations/chat/litellm","unlisted":false},{"type":"link","label":"LiteLLM Router","href":"/docs/integrations/chat/litellm_router","className":"hidden","docId":"integrations/chat/litellm_router","unlisted":false},{"type":"link","label":"Llama 2 Chat","href":"/docs/integrations/chat/llama2_chat","className":"hidden","docId":"integrations/chat/llama2_chat","unlisted":false},{"type":"link","label":"Llama API","href":"/docs/integrations/chat/llama_api","className":"hidden","docId":"integrations/chat/llama_api","unlisted":false},{"type":"link","label":"LlamaEdge","href":"/docs/integrations/chat/llama_edge","className":"hidden","docId":"integrations/chat/llama_edge","unlisted":false},{"type":"link","label":"Llama.cpp","href":"/docs/integrations/chat/llamacpp","className":"hidden","docId":"integrations/chat/llamacpp","unlisted":false},{"type":"link","label":"maritalk","href":"/docs/integrations/chat/maritalk","className":"hidden","docId":"integrations/chat/maritalk","unlisted":false},{"type":"link","label":"MiniMax","href":"/docs/integrations/chat/minimax","className":"hidden","docId":"integrations/chat/minimax","unlisted":false},{"type":"link","label":"MistralAI","href":"/docs/integrations/chat/mistralai","className":"hidden","docId":"integrations/chat/mistralai","unlisted":false},{"type":"link","label":"MLX","href":"/docs/integrations/chat/mlx","className":"hidden","docId":"integrations/chat/mlx","unlisted":false},{"type":"link","label":"ModelScope","href":"/docs/integrations/chat/modelscope_chat_endpoint","className":"hidden","docId":"integrations/chat/modelscope_chat_endpoint","unlisted":false},{"type":"link","label":"Moonshot","href":"/docs/integrations/chat/moonshot","className":"hidden","docId":"integrations/chat/moonshot","unlisted":false},{"type":"link","label":"Naver","href":"/docs/integrations/chat/naver","className":"hidden","docId":"integrations/chat/naver","unlisted":false},{"type":"link","label":"NVIDIA AI Endpoints","href":"/docs/integrations/chat/nvidia_ai_endpoints","className":"hidden","docId":"integrations/chat/nvidia_ai_endpoints","unlisted":false},{"type":"link","label":"ChatOCIModelDeployment","href":"/docs/integrations/chat/oci_data_science","className":"hidden","docId":"integrations/chat/oci_data_science","unlisted":false},{"type":"link","label":"OCIGenAI","href":"/docs/integrations/chat/oci_generative_ai","className":"hidden","docId":"integrations/chat/oci_generative_ai","unlisted":false},{"type":"link","label":"ChatOctoAI","href":"/docs/integrations/chat/octoai","className":"hidden","docId":"integrations/chat/octoai","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/chat/ollama","className":"hidden","docId":"integrations/chat/ollama","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/chat/openai","className":"hidden","docId":"integrations/chat/openai","unlisted":false},{"type":"link","label":"Outlines","href":"/docs/integrations/chat/outlines","className":"hidden","docId":"integrations/chat/outlines","unlisted":false},{"type":"link","label":"Perplexity","href":"/docs/integrations/chat/perplexity","className":"hidden","docId":"integrations/chat/perplexity","unlisted":false},{"type":"link","label":"Pipeshift","href":"/docs/integrations/chat/pipeshift","className":"hidden","docId":"integrations/chat/pipeshift","unlisted":false},{"type":"link","label":"ChatPredictionGuard","href":"/docs/integrations/chat/predictionguard","className":"hidden","docId":"integrations/chat/predictionguard","unlisted":false},{"type":"link","label":"PremAI","href":"/docs/integrations/chat/premai","className":"hidden","docId":"integrations/chat/premai","unlisted":false},{"type":"link","label":"PromptLayer ChatOpenAI","href":"/docs/integrations/chat/promptlayer_chatopenai","className":"hidden","docId":"integrations/chat/promptlayer_chatopenai","unlisted":false},{"type":"link","label":"Reka","href":"/docs/integrations/chat/reka","className":"hidden","docId":"integrations/chat/reka","unlisted":false},{"type":"link","label":"SambaNovaCloud","href":"/docs/integrations/chat/sambanova","className":"hidden","docId":"integrations/chat/sambanova","unlisted":false},{"type":"link","label":"SambaStudio","href":"/docs/integrations/chat/sambastudio","className":"hidden","docId":"integrations/chat/sambastudio","unlisted":false},{"type":"link","label":"Snowflake Cortex","href":"/docs/integrations/chat/snowflake","className":"hidden","docId":"integrations/chat/snowflake","unlisted":false},{"type":"link","label":"solar","href":"/docs/integrations/chat/solar","className":"hidden","docId":"integrations/chat/solar","unlisted":false},{"type":"link","label":"SparkLLM Chat","href":"/docs/integrations/chat/sparkllm","className":"hidden","docId":"integrations/chat/sparkllm","unlisted":false},{"type":"link","label":"Nebula (Symbl.ai)","href":"/docs/integrations/chat/symblai_nebula","className":"hidden","docId":"integrations/chat/symblai_nebula","unlisted":false},{"type":"link","label":"Tencent Hunyuan","href":"/docs/integrations/chat/tencent_hunyuan","className":"hidden","docId":"integrations/chat/tencent_hunyuan","unlisted":false},{"type":"link","label":"Together","href":"/docs/integrations/chat/together","className":"hidden","docId":"integrations/chat/together","unlisted":false},{"type":"link","label":"Tongyi Qwen","href":"/docs/integrations/chat/tongyi","className":"hidden","docId":"integrations/chat/tongyi","unlisted":false},{"type":"link","label":"Upstage","href":"/docs/integrations/chat/upstage","className":"hidden","docId":"integrations/chat/upstage","unlisted":false},{"type":"link","label":"vLLM Chat","href":"/docs/integrations/chat/vllm","className":"hidden","docId":"integrations/chat/vllm","unlisted":false},{"type":"link","label":"Volc Enging Maas","href":"/docs/integrations/chat/volcengine_maas","className":"hidden","docId":"integrations/chat/volcengine_maas","unlisted":false},{"type":"link","label":"Chat Writer","href":"/docs/integrations/chat/writer","className":"hidden","docId":"integrations/chat/writer","unlisted":false},{"type":"link","label":"xAI","href":"/docs/integrations/chat/xai","className":"hidden","docId":"integrations/chat/xai","unlisted":false},{"type":"link","label":"Xinference","href":"/docs/integrations/chat/xinference","className":"hidden","docId":"integrations/chat/xinference","unlisted":false},{"type":"link","label":"YandexGPT","href":"/docs/integrations/chat/yandex","className":"hidden","docId":"integrations/chat/yandex","unlisted":false},{"type":"link","label":"ChatYI","href":"/docs/integrations/chat/yi","className":"hidden","docId":"integrations/chat/yi","unlisted":false},{"type":"link","label":"Yuan2.0","href":"/docs/integrations/chat/yuan2","className":"hidden","docId":"integrations/chat/yuan2","unlisted":false},{"type":"link","label":"ZHIPU AI","href":"/docs/integrations/chat/zhipuai","className":"hidden","docId":"integrations/chat/zhipuai","unlisted":false}],"collapsed":false,"href":"/docs/integrations/chat/"},{"type":"category","label":"Retrievers","collapsible":false,"items":[{"type":"link","label":"Retrievers","href":"/docs/integrations/retrievers/","className":"hidden","docId":"integrations/retrievers/index","unlisted":false},{"type":"link","label":"Activeloop Deep Memory","href":"/docs/integrations/retrievers/activeloop","className":"hidden","docId":"integrations/retrievers/activeloop","unlisted":false},{"type":"link","label":"Amazon Kendra","href":"/docs/integrations/retrievers/amazon_kendra_retriever","className":"hidden","docId":"integrations/retrievers/amazon_kendra_retriever","unlisted":false},{"type":"link","label":"Arcee","href":"/docs/integrations/retrievers/arcee","className":"hidden","docId":"integrations/retrievers/arcee","unlisted":false},{"type":"link","label":"Arxiv","href":"/docs/integrations/retrievers/arxiv","className":"hidden","docId":"integrations/retrievers/arxiv","unlisted":false},{"type":"link","label":"AskNews","href":"/docs/integrations/retrievers/asknews","className":"hidden","docId":"integrations/retrievers/asknews","unlisted":false},{"type":"link","label":"Azure AI Search","href":"/docs/integrations/retrievers/azure_ai_search","className":"hidden","docId":"integrations/retrievers/azure_ai_search","unlisted":false},{"type":"link","label":"Bedrock (Knowledge Bases)","href":"/docs/integrations/retrievers/bedrock","className":"hidden","docId":"integrations/retrievers/bedrock","unlisted":false},{"type":"link","label":"BM25","href":"/docs/integrations/retrievers/bm25","className":"hidden","docId":"integrations/retrievers/bm25","unlisted":false},{"type":"link","label":"Box","href":"/docs/integrations/retrievers/box","className":"hidden","docId":"integrations/retrievers/box","unlisted":false},{"type":"link","label":"BREEBS (Open Knowledge)","href":"/docs/integrations/retrievers/breebs","className":"hidden","docId":"integrations/retrievers/breebs","unlisted":false},{"type":"link","label":"Chaindesk","href":"/docs/integrations/retrievers/chaindesk","className":"hidden","docId":"integrations/retrievers/chaindesk","unlisted":false},{"type":"link","label":"ChatGPT plugin","href":"/docs/integrations/retrievers/chatgpt-plugin","className":"hidden","docId":"integrations/retrievers/chatgpt-plugin","unlisted":false},{"type":"link","label":"Cognee","href":"/docs/integrations/retrievers/cognee","className":"hidden","docId":"integrations/retrievers/cognee","unlisted":false},{"type":"link","label":"Cohere reranker","href":"/docs/integrations/retrievers/cohere-reranker","className":"hidden","docId":"integrations/retrievers/cohere-reranker","unlisted":false},{"type":"link","label":"Cohere RAG","href":"/docs/integrations/retrievers/cohere","className":"hidden","docId":"integrations/retrievers/cohere","unlisted":false},{"type":"link","label":"Contextual AI Reranker","href":"/docs/integrations/retrievers/contextual","className":"hidden","docId":"integrations/retrievers/contextual","unlisted":false},{"type":"link","label":"Dappier","href":"/docs/integrations/retrievers/dappier","className":"hidden","docId":"integrations/retrievers/dappier","unlisted":false},{"type":"link","label":"DocArray","href":"/docs/integrations/retrievers/docarray_retriever","className":"hidden","docId":"integrations/retrievers/docarray_retriever","unlisted":false},{"type":"link","label":"Dria","href":"/docs/integrations/retrievers/dria_index","className":"hidden","docId":"integrations/retrievers/dria_index","unlisted":false},{"type":"link","label":"ElasticSearch BM25","href":"/docs/integrations/retrievers/elastic_search_bm25","className":"hidden","docId":"integrations/retrievers/elastic_search_bm25","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/retrievers/elasticsearch_retriever","className":"hidden","docId":"integrations/retrievers/elasticsearch_retriever","unlisted":false},{"type":"link","label":"Embedchain","href":"/docs/integrations/retrievers/embedchain","className":"hidden","docId":"integrations/retrievers/embedchain","unlisted":false},{"type":"link","label":"FlashRank reranker","href":"/docs/integrations/retrievers/flashrank-reranker","className":"hidden","docId":"integrations/retrievers/flashrank-reranker","unlisted":false},{"type":"link","label":"Fleet AI Context","href":"/docs/integrations/retrievers/fleet_context","className":"hidden","docId":"integrations/retrievers/fleet_context","unlisted":false},{"type":"link","label":"Google Drive","href":"/docs/integrations/retrievers/google_drive","className":"hidden","docId":"integrations/retrievers/google_drive","unlisted":false},{"type":"link","label":"Google Vertex AI Search","href":"/docs/integrations/retrievers/google_vertex_ai_search","className":"hidden","docId":"integrations/retrievers/google_vertex_ai_search","unlisted":false},{"type":"link","label":"Graph RAG","href":"/docs/integrations/retrievers/graph_rag","className":"hidden","docId":"integrations/retrievers/graph_rag","unlisted":false},{"type":"link","label":"IBM watsonx.ai","href":"/docs/integrations/retrievers/ibm_watsonx_ranker","className":"hidden","docId":"integrations/retrievers/ibm_watsonx_ranker","unlisted":false},{"type":"link","label":"JaguarDB Vector Database","href":"/docs/integrations/retrievers/jaguar","className":"hidden","docId":"integrations/retrievers/jaguar","unlisted":false},{"type":"link","label":"Kay.ai","href":"/docs/integrations/retrievers/kay","className":"hidden","docId":"integrations/retrievers/kay","unlisted":false},{"type":"link","label":"Kinetica Vectorstore based Retriever","href":"/docs/integrations/retrievers/kinetica","className":"hidden","docId":"integrations/retrievers/kinetica","unlisted":false},{"type":"link","label":"kNN","href":"/docs/integrations/retrievers/knn","className":"hidden","docId":"integrations/retrievers/knn","unlisted":false},{"type":"link","label":"LinkupSearchRetriever","href":"/docs/integrations/retrievers/linkup_search","className":"hidden","docId":"integrations/retrievers/linkup_search","unlisted":false},{"type":"link","label":"LLMLingua Document Compressor","href":"/docs/integrations/retrievers/llmlingua","className":"hidden","docId":"integrations/retrievers/llmlingua","unlisted":false},{"type":"link","label":"LOTR (Merger Retriever)","href":"/docs/integrations/retrievers/merger_retriever","className":"hidden","docId":"integrations/retrievers/merger_retriever","unlisted":false},{"type":"link","label":"Metal","href":"/docs/integrations/retrievers/metal","className":"hidden","docId":"integrations/retrievers/metal","unlisted":false},{"type":"link","label":"Milvus Hybrid Search","href":"/docs/integrations/retrievers/milvus_hybrid_search","className":"hidden","docId":"integrations/retrievers/milvus_hybrid_search","unlisted":false},{"type":"link","label":"NanoPQ (Product Quantization)","href":"/docs/integrations/retrievers/nanopq","className":"hidden","docId":"integrations/retrievers/nanopq","unlisted":false},{"type":"link","label":"needle","href":"/docs/integrations/retrievers/needle","className":"hidden","docId":"integrations/retrievers/needle","unlisted":false},{"type":"link","label":"Nimble","href":"/docs/integrations/retrievers/nimble","className":"hidden","docId":"integrations/retrievers/nimble","unlisted":false},{"type":"link","label":"Outline","href":"/docs/integrations/retrievers/outline","className":"hidden","docId":"integrations/retrievers/outline","unlisted":false},{"type":"link","label":"Permit","href":"/docs/integrations/retrievers/permit","className":"hidden","docId":"integrations/retrievers/permit","unlisted":false},{"type":"link","label":"Pinecone Hybrid Search","href":"/docs/integrations/retrievers/pinecone_hybrid_search","className":"hidden","docId":"integrations/retrievers/pinecone_hybrid_search","unlisted":false},{"type":"link","label":"PubMed","href":"/docs/integrations/retrievers/pubmed","className":"hidden","docId":"integrations/retrievers/pubmed","unlisted":false},{"type":"link","label":"Qdrant Sparse Vector","href":"/docs/integrations/retrievers/qdrant-sparse","className":"hidden","docId":"integrations/retrievers/qdrant-sparse","unlisted":false},{"type":"link","label":"RAGatouille","href":"/docs/integrations/retrievers/ragatouille","className":"hidden","docId":"integrations/retrievers/ragatouille","unlisted":false},{"type":"link","label":"RePhraseQuery","href":"/docs/integrations/retrievers/re_phrase","className":"hidden","docId":"integrations/retrievers/re_phrase","unlisted":false},{"type":"link","label":"Rememberizer","href":"/docs/integrations/retrievers/rememberizer","className":"hidden","docId":"integrations/retrievers/rememberizer","unlisted":false},{"type":"link","label":"SEC filing","href":"/docs/integrations/retrievers/sec_filings","className":"hidden","docId":"integrations/retrievers/sec_filings","unlisted":false},{"type":"category","label":"Self-querying retrievers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Deep Lake","href":"/docs/integrations/retrievers/self_query/activeloop_deeplake_self_query","docId":"integrations/retrievers/self_query/activeloop_deeplake_self_query","unlisted":false},{"type":"link","label":"Astra DB (Cassandra)","href":"/docs/integrations/retrievers/self_query/astradb","docId":"integrations/retrievers/self_query/astradb","unlisted":false},{"type":"link","label":"Chroma","href":"/docs/integrations/retrievers/self_query/chroma_self_query","docId":"integrations/retrievers/self_query/chroma_self_query","unlisted":false},{"type":"link","label":"DashVector","href":"/docs/integrations/retrievers/self_query/dashvector","docId":"integrations/retrievers/self_query/dashvector","unlisted":false},{"type":"link","label":"Databricks Vector Search","href":"/docs/integrations/retrievers/self_query/databricks_vector_search","docId":"integrations/retrievers/self_query/databricks_vector_search","unlisted":false},{"type":"link","label":"DingoDB","href":"/docs/integrations/retrievers/self_query/dingo","docId":"integrations/retrievers/self_query/dingo","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/retrievers/self_query/elasticsearch_self_query","docId":"integrations/retrievers/self_query/elasticsearch_self_query","unlisted":false},{"type":"link","label":"SAP HANA Cloud Vector Engine","href":"/docs/integrations/retrievers/self_query/hanavector_self_query","docId":"integrations/retrievers/self_query/hanavector_self_query","unlisted":false},{"type":"link","label":"Milvus","href":"/docs/integrations/retrievers/self_query/milvus_self_query","docId":"integrations/retrievers/self_query/milvus_self_query","unlisted":false},{"type":"link","label":"MongoDB Atlas","href":"/docs/integrations/retrievers/self_query/mongodb_atlas","docId":"integrations/retrievers/self_query/mongodb_atlas","unlisted":false},{"type":"link","label":"MyScale","href":"/docs/integrations/retrievers/self_query/myscale_self_query","docId":"integrations/retrievers/self_query/myscale_self_query","unlisted":false},{"type":"link","label":"Neo4j","href":"/docs/integrations/retrievers/self_query/neo4j_self_query","docId":"integrations/retrievers/self_query/neo4j_self_query","unlisted":false},{"type":"link","label":"OpenSearch","href":"/docs/integrations/retrievers/self_query/opensearch_self_query","docId":"integrations/retrievers/self_query/opensearch_self_query","unlisted":false},{"type":"link","label":"PGVector (Postgres)","href":"/docs/integrations/retrievers/self_query/pgvector_self_query","docId":"integrations/retrievers/self_query/pgvector_self_query","unlisted":false},{"type":"link","label":"Pinecone","href":"/docs/integrations/retrievers/self_query/pinecone","docId":"integrations/retrievers/self_query/pinecone","unlisted":false},{"type":"link","label":"Qdrant","href":"/docs/integrations/retrievers/self_query/qdrant_self_query","docId":"integrations/retrievers/self_query/qdrant_self_query","unlisted":false},{"type":"link","label":"Redis","href":"/docs/integrations/retrievers/self_query/redis_self_query","docId":"integrations/retrievers/self_query/redis_self_query","unlisted":false},{"type":"link","label":"Supabase (Postgres)","href":"/docs/integrations/retrievers/self_query/supabase_self_query","docId":"integrations/retrievers/self_query/supabase_self_query","unlisted":false},{"type":"link","label":"Tencent Cloud VectorDB","href":"/docs/integrations/retrievers/self_query/tencentvectordb","docId":"integrations/retrievers/self_query/tencentvectordb","unlisted":false},{"type":"link","label":"Timescale Vector (Postgres)","href":"/docs/integrations/retrievers/self_query/timescalevector_self_query","docId":"integrations/retrievers/self_query/timescalevector_self_query","unlisted":false},{"type":"link","label":"Vectara self-querying","href":"/docs/integrations/retrievers/self_query/vectara_self_query","docId":"integrations/retrievers/self_query/vectara_self_query","unlisted":false},{"type":"link","label":"Weaviate","href":"/docs/integrations/retrievers/self_query/weaviate_self_query","docId":"integrations/retrievers/self_query/weaviate_self_query","unlisted":false}],"className":"hidden","href":"/docs/integrations/retrievers/self_query/"},{"type":"link","label":"SingleStoreDB","href":"/docs/integrations/retrievers/singlestoredb","className":"hidden","docId":"integrations/retrievers/singlestoredb","unlisted":false},{"type":"link","label":"SVM","href":"/docs/integrations/retrievers/svm","className":"hidden","docId":"integrations/retrievers/svm","unlisted":false},{"type":"link","label":"TavilySearchAPI","href":"/docs/integrations/retrievers/tavily","className":"hidden","docId":"integrations/retrievers/tavily","unlisted":false},{"type":"link","label":"TF-IDF","href":"/docs/integrations/retrievers/tf_idf","className":"hidden","docId":"integrations/retrievers/tf_idf","unlisted":false},{"type":"link","label":"**NeuralDB**","href":"/docs/integrations/retrievers/thirdai_neuraldb","className":"hidden","docId":"integrations/retrievers/thirdai_neuraldb","unlisted":false},{"type":"link","label":"Vespa","href":"/docs/integrations/retrievers/vespa","className":"hidden","docId":"integrations/retrievers/vespa","unlisted":false},{"type":"link","label":"Wikipedia","href":"/docs/integrations/retrievers/wikipedia","className":"hidden","docId":"integrations/retrievers/wikipedia","unlisted":false},{"type":"link","label":"You.com","href":"/docs/integrations/retrievers/you-retriever","className":"hidden","docId":"integrations/retrievers/you-retriever","unlisted":false},{"type":"link","label":"Zep Cloud","href":"/docs/integrations/retrievers/zep_cloud_memorystore","className":"hidden","docId":"integrations/retrievers/zep_cloud_memorystore","unlisted":false},{"type":"link","label":"Zep Open Source","href":"/docs/integrations/retrievers/zep_memorystore","className":"hidden","docId":"integrations/retrievers/zep_memorystore","unlisted":false},{"type":"link","label":"Zilliz Cloud Pipeline","href":"/docs/integrations/retrievers/zilliz_cloud_pipeline","className":"hidden","docId":"integrations/retrievers/zilliz_cloud_pipeline","unlisted":false},{"type":"link","label":"Zotero","href":"/docs/integrations/retrievers/zotero","className":"hidden","docId":"integrations/retrievers/zotero","unlisted":false}],"collapsed":false,"href":"/docs/integrations/retrievers/"},{"type":"category","label":"Tools/Toolkits","collapsible":false,"items":[{"type":"link","label":"Tools","href":"/docs/integrations/tools/","className":"hidden","docId":"integrations/tools/index","unlisted":false},{"type":"link","label":"ADS4GPTs","href":"/docs/integrations/tools/ads4gpts","className":"hidden","docId":"integrations/tools/ads4gpts","unlisted":false},{"type":"link","label":"AgentQL","href":"/docs/integrations/tools/agentql","className":"hidden","docId":"integrations/tools/agentql","unlisted":false},{"type":"link","label":"AINetwork Toolkit","href":"/docs/integrations/tools/ainetwork","className":"hidden","docId":"integrations/tools/ainetwork","unlisted":false},{"type":"link","label":"Alpha Vantage","href":"/docs/integrations/tools/alpha_vantage","className":"hidden","docId":"integrations/tools/alpha_vantage","unlisted":false},{"type":"link","label":"Amadeus Toolkit","href":"/docs/integrations/tools/amadeus","className":"hidden","docId":"integrations/tools/amadeus","unlisted":false},{"type":"link","label":"Apify Actor","href":"/docs/integrations/tools/apify_actors","className":"hidden","docId":"integrations/tools/apify_actors","unlisted":false},{"type":"link","label":"ArXiv","href":"/docs/integrations/tools/arxiv","className":"hidden","docId":"integrations/tools/arxiv","unlisted":false},{"type":"link","label":"AskNews","href":"/docs/integrations/tools/asknews","className":"hidden","docId":"integrations/tools/asknews","unlisted":false},{"type":"link","label":"AWS Lambda","href":"/docs/integrations/tools/awslambda","className":"hidden","docId":"integrations/tools/awslambda","unlisted":false},{"type":"link","label":"Azure AI Services Toolkit","href":"/docs/integrations/tools/azure_ai_services","className":"hidden","docId":"integrations/tools/azure_ai_services","unlisted":false},{"type":"link","label":"Azure Cognitive Services Toolkit","href":"/docs/integrations/tools/azure_cognitive_services","className":"hidden","docId":"integrations/tools/azure_cognitive_services","unlisted":false},{"type":"link","label":"Azure Container Apps dynamic sessions","href":"/docs/integrations/tools/azure_dynamic_sessions","className":"hidden","docId":"integrations/tools/azure_dynamic_sessions","unlisted":false},{"type":"link","label":"Shell (bash)","href":"/docs/integrations/tools/bash","className":"hidden","docId":"integrations/tools/bash","unlisted":false},{"type":"link","label":"Bearly Code Interpreter","href":"/docs/integrations/tools/bearly","className":"hidden","docId":"integrations/tools/bearly","unlisted":false},{"type":"link","label":"Bing Search","href":"/docs/integrations/tools/bing_search","className":"hidden","docId":"integrations/tools/bing_search","unlisted":false},{"type":"link","label":"Brave Search","href":"/docs/integrations/tools/brave_search","className":"hidden","docId":"integrations/tools/brave_search","unlisted":false},{"type":"link","label":"Cassandra Database Toolkit","href":"/docs/integrations/tools/cassandra_database","className":"hidden","docId":"integrations/tools/cassandra_database","unlisted":false},{"type":"link","label":"CDP","href":"/docs/integrations/tools/cdp_agentkit","className":"hidden","docId":"integrations/tools/cdp_agentkit","unlisted":false},{"type":"link","label":"ChatGPT Plugins","href":"/docs/integrations/tools/chatgpt_plugins","className":"hidden","docId":"integrations/tools/chatgpt_plugins","unlisted":false},{"type":"link","label":"ClickUp Toolkit","href":"/docs/integrations/tools/clickup","className":"hidden","docId":"integrations/tools/clickup","unlisted":false},{"type":"link","label":"Cogniswitch Toolkit","href":"/docs/integrations/tools/cogniswitch","className":"hidden","docId":"integrations/tools/cogniswitch","unlisted":false},{"type":"link","label":"Connery Toolkit and Tools","href":"/docs/integrations/tools/connery","className":"hidden","docId":"integrations/tools/connery","unlisted":false},{"type":"link","label":"Dall-E Image Generator","href":"/docs/integrations/tools/dalle_image_generator","className":"hidden","docId":"integrations/tools/dalle_image_generator","unlisted":false},{"type":"link","label":"Dappier","href":"/docs/integrations/tools/dappier","className":"hidden","docId":"integrations/tools/dappier","unlisted":false},{"type":"link","label":"Databricks Unity Catalog (UC)","href":"/docs/integrations/tools/databricks","className":"hidden","docId":"integrations/tools/databricks","unlisted":false},{"type":"link","label":"DataForSEO","href":"/docs/integrations/tools/dataforseo","className":"hidden","docId":"integrations/tools/dataforseo","unlisted":false},{"type":"link","label":"Dataherald","href":"/docs/integrations/tools/dataherald","className":"hidden","docId":"integrations/tools/dataherald","unlisted":false},{"type":"link","label":"DuckDuckGo Search","href":"/docs/integrations/tools/ddg","className":"hidden","docId":"integrations/tools/ddg","unlisted":false},{"type":"link","label":"Discord","href":"/docs/integrations/tools/discord","className":"hidden","docId":"integrations/tools/discord","unlisted":false},{"type":"link","label":"E2B Data Analysis","href":"/docs/integrations/tools/e2b_data_analysis","className":"hidden","docId":"integrations/tools/e2b_data_analysis","unlisted":false},{"type":"link","label":"Eden AI","href":"/docs/integrations/tools/edenai_tools","className":"hidden","docId":"integrations/tools/edenai_tools","unlisted":false},{"type":"link","label":"ElevenLabs Text2Speech","href":"/docs/integrations/tools/eleven_labs_tts","className":"hidden","docId":"integrations/tools/eleven_labs_tts","unlisted":false},{"type":"link","label":"Exa Search","href":"/docs/integrations/tools/exa_search","className":"hidden","docId":"integrations/tools/exa_search","unlisted":false},{"type":"link","label":"File System","href":"/docs/integrations/tools/filesystem","className":"hidden","docId":"integrations/tools/filesystem","unlisted":false},{"type":"link","label":"FinancialDatasets Toolkit","href":"/docs/integrations/tools/financial_datasets","className":"hidden","docId":"integrations/tools/financial_datasets","unlisted":false},{"type":"link","label":"FMP Data","href":"/docs/integrations/tools/fmp-data","className":"hidden","docId":"integrations/tools/fmp-data","unlisted":false},{"type":"link","label":"Github Toolkit","href":"/docs/integrations/tools/github","className":"hidden","docId":"integrations/tools/github","unlisted":false},{"type":"link","label":"Gitlab Toolkit","href":"/docs/integrations/tools/gitlab","className":"hidden","docId":"integrations/tools/gitlab","unlisted":false},{"type":"link","label":"Gmail Toolkit","href":"/docs/integrations/tools/gmail","className":"hidden","docId":"integrations/tools/gmail","unlisted":false},{"type":"link","label":"Golden Query","href":"/docs/integrations/tools/golden_query","className":"hidden","docId":"integrations/tools/golden_query","unlisted":false},{"type":"link","label":"Google Books","href":"/docs/integrations/tools/google_books","className":"hidden","docId":"integrations/tools/google_books","unlisted":false},{"type":"link","label":"Google Cloud Text-to-Speech","href":"/docs/integrations/tools/google_cloud_texttospeech","className":"hidden","docId":"integrations/tools/google_cloud_texttospeech","unlisted":false},{"type":"link","label":"Google Drive","href":"/docs/integrations/tools/google_drive","className":"hidden","docId":"integrations/tools/google_drive","unlisted":false},{"type":"link","label":"Google Finance","href":"/docs/integrations/tools/google_finance","className":"hidden","docId":"integrations/tools/google_finance","unlisted":false},{"type":"link","label":"Google Imagen","href":"/docs/integrations/tools/google_imagen","className":"hidden","docId":"integrations/tools/google_imagen","unlisted":false},{"type":"link","label":"Google Jobs","href":"/docs/integrations/tools/google_jobs","className":"hidden","docId":"integrations/tools/google_jobs","unlisted":false},{"type":"link","label":"Google Lens","href":"/docs/integrations/tools/google_lens","className":"hidden","docId":"integrations/tools/google_lens","unlisted":false},{"type":"link","label":"Google Places","href":"/docs/integrations/tools/google_places","className":"hidden","docId":"integrations/tools/google_places","unlisted":false},{"type":"link","label":"Google Scholar","href":"/docs/integrations/tools/google_scholar","className":"hidden","docId":"integrations/tools/google_scholar","unlisted":false},{"type":"link","label":"Google Search","href":"/docs/integrations/tools/google_search","className":"hidden","docId":"integrations/tools/google_search","unlisted":false},{"type":"link","label":"Google Serper","href":"/docs/integrations/tools/google_serper","className":"hidden","docId":"integrations/tools/google_serper","unlisted":false},{"type":"link","label":"Google Trends","href":"/docs/integrations/tools/google_trends","className":"hidden","docId":"integrations/tools/google_trends","unlisted":false},{"type":"link","label":"Gradio","href":"/docs/integrations/tools/gradio_tools","className":"hidden","docId":"integrations/tools/gradio_tools","unlisted":false},{"type":"link","label":"GraphQL","href":"/docs/integrations/tools/graphql","className":"hidden","docId":"integrations/tools/graphql","unlisted":false},{"type":"link","label":"HuggingFace Hub Tools","href":"/docs/integrations/tools/huggingface_tools","className":"hidden","docId":"integrations/tools/huggingface_tools","unlisted":false},{"type":"link","label":"Human as a tool","href":"/docs/integrations/tools/human_tools","className":"hidden","docId":"integrations/tools/human_tools","unlisted":false},{"type":"link","label":"IFTTT WebHooks","href":"/docs/integrations/tools/ifttt","className":"hidden","docId":"integrations/tools/ifttt","unlisted":false},{"type":"link","label":"Infobip","href":"/docs/integrations/tools/infobip","className":"hidden","docId":"integrations/tools/infobip","unlisted":false},{"type":"link","label":"Ionic Shopping Tool","href":"/docs/integrations/tools/ionic_shopping","className":"hidden","docId":"integrations/tools/ionic_shopping","unlisted":false},{"type":"link","label":"Jenkins","href":"/docs/integrations/tools/jenkins","className":"hidden","docId":"integrations/tools/jenkins","unlisted":false},{"type":"link","label":"Jina Search","href":"/docs/integrations/tools/jina_search","className":"hidden","docId":"integrations/tools/jina_search","unlisted":false},{"type":"link","label":"Jira Toolkit","href":"/docs/integrations/tools/jira","className":"hidden","docId":"integrations/tools/jira","unlisted":false},{"type":"link","label":"JSON Toolkit","href":"/docs/integrations/tools/json","className":"hidden","docId":"integrations/tools/json","unlisted":false},{"type":"link","label":"Lemon Agent","href":"/docs/integrations/tools/lemonai","className":"hidden","docId":"integrations/tools/lemonai","unlisted":false},{"type":"link","label":"LinkupSearchTool","href":"/docs/integrations/tools/linkup_search","className":"hidden","docId":"integrations/tools/linkup_search","unlisted":false},{"type":"link","label":"Memorize","href":"/docs/integrations/tools/memorize","className":"hidden","docId":"integrations/tools/memorize","unlisted":false},{"type":"link","label":"Mojeek Search","href":"/docs/integrations/tools/mojeek_search","className":"hidden","docId":"integrations/tools/mojeek_search","unlisted":false},{"type":"link","label":"MultiOn Toolkit","href":"/docs/integrations/tools/multion","className":"hidden","docId":"integrations/tools/multion","unlisted":false},{"type":"link","label":"NASA Toolkit","href":"/docs/integrations/tools/nasa","className":"hidden","docId":"integrations/tools/nasa","unlisted":false},{"type":"link","label":"Naver Search","href":"/docs/integrations/tools/naver_search","className":"hidden","docId":"integrations/tools/naver_search","unlisted":false},{"type":"link","label":"Nuclia Understanding","href":"/docs/integrations/tools/nuclia","className":"hidden","docId":"integrations/tools/nuclia","unlisted":false},{"type":"link","label":"NVIDIA Riva: ASR and TTS","href":"/docs/integrations/tools/nvidia_riva","className":"hidden","docId":"integrations/tools/nvidia_riva","unlisted":false},{"type":"link","label":"Office365 Toolkit","href":"/docs/integrations/tools/office365","className":"hidden","docId":"integrations/tools/office365","unlisted":false},{"type":"link","label":"OpenAPI Toolkit","href":"/docs/integrations/tools/openapi","className":"hidden","docId":"integrations/tools/openapi","unlisted":false},{"type":"link","label":"Natural Language API Toolkits","href":"/docs/integrations/tools/openapi_nla","className":"hidden","docId":"integrations/tools/openapi_nla","unlisted":false},{"type":"link","label":"OpenGradient","href":"/docs/integrations/tools/opengradient_toolkit","className":"hidden","docId":"integrations/tools/opengradient_toolkit","unlisted":false},{"type":"link","label":"OpenWeatherMap","href":"/docs/integrations/tools/openweathermap","className":"hidden","docId":"integrations/tools/openweathermap","unlisted":false},{"type":"link","label":"Oracle AI Vector Search: Generate Summary","href":"/docs/integrations/tools/oracleai","className":"hidden","docId":"integrations/tools/oracleai","unlisted":false},{"type":"link","label":"Pandas Dataframe","href":"/docs/integrations/tools/pandas","className":"hidden","docId":"integrations/tools/pandas","unlisted":false},{"type":"link","label":"Passio NutritionAI","href":"/docs/integrations/tools/passio_nutrition_ai","className":"hidden","docId":"integrations/tools/passio_nutrition_ai","unlisted":false},{"type":"link","label":"PaymanAI","href":"/docs/integrations/tools/payman-tool","className":"hidden","docId":"integrations/tools/payman-tool","unlisted":false},{"type":"link","label":"Permit","href":"/docs/integrations/tools/permit","className":"hidden","docId":"integrations/tools/permit","unlisted":false},{"type":"link","label":"PlayWright Browser Toolkit","href":"/docs/integrations/tools/playwright","className":"hidden","docId":"integrations/tools/playwright","unlisted":false},{"type":"link","label":"Polygon IO Toolkit and Tools","href":"/docs/integrations/tools/polygon","className":"hidden","docId":"integrations/tools/polygon","unlisted":false},{"type":"link","label":"PowerBI Toolkit","href":"/docs/integrations/tools/powerbi","className":"hidden","docId":"integrations/tools/powerbi","unlisted":false},{"type":"link","label":"Prolog","href":"/docs/integrations/tools/prolog_tool","className":"hidden","docId":"integrations/tools/prolog_tool","unlisted":false},{"type":"link","label":"PubMed","href":"/docs/integrations/tools/pubmed","className":"hidden","docId":"integrations/tools/pubmed","unlisted":false},{"type":"link","label":"Python REPL","href":"/docs/integrations/tools/python","className":"hidden","docId":"integrations/tools/python","unlisted":false},{"type":"link","label":"Reddit Search","href":"/docs/integrations/tools/reddit_search","className":"hidden","docId":"integrations/tools/reddit_search","unlisted":false},{"type":"link","label":"Requests Toolkit","href":"/docs/integrations/tools/requests","className":"hidden","docId":"integrations/tools/requests","unlisted":false},{"type":"link","label":"Riza Code Interpreter","href":"/docs/integrations/tools/riza","className":"hidden","docId":"integrations/tools/riza","unlisted":false},{"type":"link","label":"Robocorp Toolkit","href":"/docs/integrations/tools/robocorp","className":"hidden","docId":"integrations/tools/robocorp","unlisted":false},{"type":"link","label":"Salesforce","href":"/docs/integrations/tools/salesforce","className":"hidden","docId":"integrations/tools/salesforce","unlisted":false},{"type":"link","label":"SceneXplain","href":"/docs/integrations/tools/sceneXplain","className":"hidden","docId":"integrations/tools/sceneXplain","unlisted":false},{"type":"link","label":"ScrapeGraph","href":"/docs/integrations/tools/scrapegraph","className":"hidden","docId":"integrations/tools/scrapegraph","unlisted":false},{"type":"link","label":"SearchApi","href":"/docs/integrations/tools/searchapi","className":"hidden","docId":"integrations/tools/searchapi","unlisted":false},{"type":"link","label":"SearxNG Search","href":"/docs/integrations/tools/searx_search","className":"hidden","docId":"integrations/tools/searx_search","unlisted":false},{"type":"link","label":"Semantic Scholar API Tool","href":"/docs/integrations/tools/semanticscholar","className":"hidden","docId":"integrations/tools/semanticscholar","unlisted":false},{"type":"link","label":"SerpAPI","href":"/docs/integrations/tools/serpapi","className":"hidden","docId":"integrations/tools/serpapi","unlisted":false},{"type":"link","label":"Slack Toolkit","href":"/docs/integrations/tools/slack","className":"hidden","docId":"integrations/tools/slack","unlisted":false},{"type":"link","label":"Spark SQL Toolkit","href":"/docs/integrations/tools/spark_sql","className":"hidden","docId":"integrations/tools/spark_sql","unlisted":false},{"type":"link","label":"SQLDatabase Toolkit","href":"/docs/integrations/tools/sql_database","className":"hidden","docId":"integrations/tools/sql_database","unlisted":false},{"type":"link","label":"StackExchange","href":"/docs/integrations/tools/stackexchange","className":"hidden","docId":"integrations/tools/stackexchange","unlisted":false},{"type":"link","label":"Steam Toolkit","href":"/docs/integrations/tools/steam","className":"hidden","docId":"integrations/tools/steam","unlisted":false},{"type":"link","label":"Stripe","href":"/docs/integrations/tools/stripe","className":"hidden","docId":"integrations/tools/stripe","unlisted":false},{"type":"link","label":"Tableau","href":"/docs/integrations/tools/tableau","className":"hidden","docId":"integrations/tools/tableau","unlisted":false},{"type":"link","label":"Taiga","href":"/docs/integrations/tools/taiga","className":"hidden","docId":"integrations/tools/taiga","unlisted":false},{"type":"link","label":"Tavily Extract","href":"/docs/integrations/tools/tavily_extract","className":"hidden","docId":"integrations/tools/tavily_extract","unlisted":false},{"type":"link","label":"Tavily Search","href":"/docs/integrations/tools/tavily_search","className":"hidden","docId":"integrations/tools/tavily_search","unlisted":false},{"type":"link","label":"Tilores","href":"/docs/integrations/tools/tilores","className":"hidden","docId":"integrations/tools/tilores","unlisted":false},{"type":"link","label":"Twilio","href":"/docs/integrations/tools/twilio","className":"hidden","docId":"integrations/tools/twilio","unlisted":false},{"type":"link","label":"Upstage","href":"/docs/integrations/tools/upstage_groundedness_check","className":"hidden","docId":"integrations/tools/upstage_groundedness_check","unlisted":false},{"type":"link","label":"Valthera","href":"/docs/integrations/tools/valthera","className":"hidden","docId":"integrations/tools/valthera","unlisted":false},{"type":"link","label":"Wikidata","href":"/docs/integrations/tools/wikidata","className":"hidden","docId":"integrations/tools/wikidata","unlisted":false},{"type":"link","label":"Wikipedia","href":"/docs/integrations/tools/wikipedia","className":"hidden","docId":"integrations/tools/wikipedia","unlisted":false},{"type":"link","label":"Wolfram Alpha","href":"/docs/integrations/tools/wolfram_alpha","className":"hidden","docId":"integrations/tools/wolfram_alpha","unlisted":false},{"type":"link","label":"Writer Tools","href":"/docs/integrations/tools/writer","className":"hidden","docId":"integrations/tools/writer","unlisted":false},{"type":"link","label":"Yahoo Finance News","href":"/docs/integrations/tools/yahoo_finance_news","className":"hidden","docId":"integrations/tools/yahoo_finance_news","unlisted":false},{"type":"link","label":"You.com Search","href":"/docs/integrations/tools/you","className":"hidden","docId":"integrations/tools/you","unlisted":false},{"type":"link","label":"YouTube","href":"/docs/integrations/tools/youtube","className":"hidden","docId":"integrations/tools/youtube","unlisted":false},{"type":"link","label":"Zapier Natural Language Actions","href":"/docs/integrations/tools/zapier","className":"hidden","docId":"integrations/tools/zapier","unlisted":false},{"type":"link","label":"ZenGuard AI","href":"/docs/integrations/tools/zenguard","className":"hidden","docId":"integrations/tools/zenguard","unlisted":false}],"collapsed":false,"href":"/docs/integrations/tools/"},{"type":"category","label":"Document loaders","collapsible":false,"items":[{"type":"link","label":"Document loaders","href":"/docs/integrations/document_loaders/","className":"hidden","docId":"integrations/document_loaders/index","unlisted":false},{"type":"link","label":"acreom","href":"/docs/integrations/document_loaders/acreom","className":"hidden","docId":"integrations/document_loaders/acreom","unlisted":false},{"type":"link","label":"AgentQLLoader","href":"/docs/integrations/document_loaders/agentql","className":"hidden","docId":"integrations/document_loaders/agentql","unlisted":false},{"type":"link","label":"AirbyteLoader","href":"/docs/integrations/document_loaders/airbyte","className":"hidden","docId":"integrations/document_loaders/airbyte","unlisted":false},{"type":"link","label":"Airbyte CDK (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_cdk","className":"hidden","docId":"integrations/document_loaders/airbyte_cdk","unlisted":false},{"type":"link","label":"Airbyte Gong (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_gong","className":"hidden","docId":"integrations/document_loaders/airbyte_gong","unlisted":false},{"type":"link","label":"Airbyte Hubspot (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_hubspot","className":"hidden","docId":"integrations/document_loaders/airbyte_hubspot","unlisted":false},{"type":"link","label":"Airbyte JSON (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_json","className":"hidden","docId":"integrations/document_loaders/airbyte_json","unlisted":false},{"type":"link","label":"Airbyte Salesforce (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_salesforce","className":"hidden","docId":"integrations/document_loaders/airbyte_salesforce","unlisted":false},{"type":"link","label":"Airbyte Shopify (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_shopify","className":"hidden","docId":"integrations/document_loaders/airbyte_shopify","unlisted":false},{"type":"link","label":"Airbyte Stripe (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_stripe","className":"hidden","docId":"integrations/document_loaders/airbyte_stripe","unlisted":false},{"type":"link","label":"Airbyte Typeform (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_typeform","className":"hidden","docId":"integrations/document_loaders/airbyte_typeform","unlisted":false},{"type":"link","label":"Airbyte Zendesk Support (Deprecated)","href":"/docs/integrations/document_loaders/airbyte_zendesk_support","className":"hidden","docId":"integrations/document_loaders/airbyte_zendesk_support","unlisted":false},{"type":"link","label":"Airtable","href":"/docs/integrations/document_loaders/airtable","className":"hidden","docId":"integrations/document_loaders/airtable","unlisted":false},{"type":"link","label":"Alibaba Cloud MaxCompute","href":"/docs/integrations/document_loaders/alibaba_cloud_maxcompute","className":"hidden","docId":"integrations/document_loaders/alibaba_cloud_maxcompute","unlisted":false},{"type":"link","label":"Amazon Textract","href":"/docs/integrations/document_loaders/amazon_textract","className":"hidden","docId":"integrations/document_loaders/amazon_textract","unlisted":false},{"type":"link","label":"Apify Dataset","href":"/docs/integrations/document_loaders/apify_dataset","className":"hidden","docId":"integrations/document_loaders/apify_dataset","unlisted":false},{"type":"link","label":"ArcGIS","href":"/docs/integrations/document_loaders/arcgis","className":"hidden","docId":"integrations/document_loaders/arcgis","unlisted":false},{"type":"link","label":"ArxivLoader","href":"/docs/integrations/document_loaders/arxiv","className":"hidden","docId":"integrations/document_loaders/arxiv","unlisted":false},{"type":"link","label":"AssemblyAI Audio Transcripts","href":"/docs/integrations/document_loaders/assemblyai","className":"hidden","docId":"integrations/document_loaders/assemblyai","unlisted":false},{"type":"link","label":"AstraDB","href":"/docs/integrations/document_loaders/astradb","className":"hidden","docId":"integrations/document_loaders/astradb","unlisted":false},{"type":"link","label":"Async Chromium","href":"/docs/integrations/document_loaders/async_chromium","className":"hidden","docId":"integrations/document_loaders/async_chromium","unlisted":false},{"type":"link","label":"AsyncHtml","href":"/docs/integrations/document_loaders/async_html","className":"hidden","docId":"integrations/document_loaders/async_html","unlisted":false},{"type":"link","label":"Athena","href":"/docs/integrations/document_loaders/athena","className":"hidden","docId":"integrations/document_loaders/athena","unlisted":false},{"type":"link","label":"AWS S3 Directory","href":"/docs/integrations/document_loaders/aws_s3_directory","className":"hidden","docId":"integrations/document_loaders/aws_s3_directory","unlisted":false},{"type":"link","label":"AWS S3 File","href":"/docs/integrations/document_loaders/aws_s3_file","className":"hidden","docId":"integrations/document_loaders/aws_s3_file","unlisted":false},{"type":"link","label":"AZLyrics","href":"/docs/integrations/document_loaders/azlyrics","className":"hidden","docId":"integrations/document_loaders/azlyrics","unlisted":false},{"type":"link","label":"Azure AI Data","href":"/docs/integrations/document_loaders/azure_ai_data","className":"hidden","docId":"integrations/document_loaders/azure_ai_data","unlisted":false},{"type":"link","label":"Azure Blob Storage Container","href":"/docs/integrations/document_loaders/azure_blob_storage_container","className":"hidden","docId":"integrations/document_loaders/azure_blob_storage_container","unlisted":false},{"type":"link","label":"Azure Blob Storage File","href":"/docs/integrations/document_loaders/azure_blob_storage_file","className":"hidden","docId":"integrations/document_loaders/azure_blob_storage_file","unlisted":false},{"type":"link","label":"Azure AI Document Intelligence","href":"/docs/integrations/document_loaders/azure_document_intelligence","className":"hidden","docId":"integrations/document_loaders/azure_document_intelligence","unlisted":false},{"type":"link","label":"BibTeX","href":"/docs/integrations/document_loaders/bibtex","className":"hidden","docId":"integrations/document_loaders/bibtex","unlisted":false},{"type":"link","label":"BiliBili","href":"/docs/integrations/document_loaders/bilibili","className":"hidden","docId":"integrations/document_loaders/bilibili","unlisted":false},{"type":"link","label":"Blackboard","href":"/docs/integrations/document_loaders/blackboard","className":"hidden","docId":"integrations/document_loaders/blackboard","unlisted":false},{"type":"link","label":"Blockchain","href":"/docs/integrations/document_loaders/blockchain","className":"hidden","docId":"integrations/document_loaders/blockchain","unlisted":false},{"type":"link","label":"Box","href":"/docs/integrations/document_loaders/box","className":"hidden","docId":"integrations/document_loaders/box","unlisted":false},{"type":"link","label":"Brave Search","href":"/docs/integrations/document_loaders/brave_search","className":"hidden","docId":"integrations/document_loaders/brave_search","unlisted":false},{"type":"link","label":"Browserbase","href":"/docs/integrations/document_loaders/browserbase","className":"hidden","docId":"integrations/document_loaders/browserbase","unlisted":false},{"type":"link","label":"Browserless","href":"/docs/integrations/document_loaders/browserless","className":"hidden","docId":"integrations/document_loaders/browserless","unlisted":false},{"type":"link","label":"BSHTMLLoader","href":"/docs/integrations/document_loaders/bshtml","className":"hidden","docId":"integrations/document_loaders/bshtml","unlisted":false},{"type":"link","label":"Cassandra","href":"/docs/integrations/document_loaders/cassandra","className":"hidden","docId":"integrations/document_loaders/cassandra","unlisted":false},{"type":"link","label":"ChatGPT Data","href":"/docs/integrations/document_loaders/chatgpt_loader","className":"hidden","docId":"integrations/document_loaders/chatgpt_loader","unlisted":false},{"type":"link","label":"College Confidential","href":"/docs/integrations/document_loaders/college_confidential","className":"hidden","docId":"integrations/document_loaders/college_confidential","unlisted":false},{"type":"link","label":"Concurrent Loader","href":"/docs/integrations/document_loaders/concurrent","className":"hidden","docId":"integrations/document_loaders/concurrent","unlisted":false},{"type":"link","label":"Confluence","href":"/docs/integrations/document_loaders/confluence","className":"hidden","docId":"integrations/document_loaders/confluence","unlisted":false},{"type":"link","label":"CoNLL-U","href":"/docs/integrations/document_loaders/conll-u","className":"hidden","docId":"integrations/document_loaders/conll-u","unlisted":false},{"type":"link","label":"Copy Paste","href":"/docs/integrations/document_loaders/copypaste","className":"hidden","docId":"integrations/document_loaders/copypaste","unlisted":false},{"type":"link","label":"Couchbase","href":"/docs/integrations/document_loaders/couchbase","className":"hidden","docId":"integrations/document_loaders/couchbase","unlisted":false},{"type":"link","label":"CSV","href":"/docs/integrations/document_loaders/csv","className":"hidden","docId":"integrations/document_loaders/csv","unlisted":false},{"type":"link","label":"Cube Semantic Layer","href":"/docs/integrations/document_loaders/cube_semantic","className":"hidden","docId":"integrations/document_loaders/cube_semantic","unlisted":false},{"type":"link","label":"Datadog Logs","href":"/docs/integrations/document_loaders/datadog_logs","className":"hidden","docId":"integrations/document_loaders/datadog_logs","unlisted":false},{"type":"link","label":"Dedoc","href":"/docs/integrations/document_loaders/dedoc","className":"hidden","docId":"integrations/document_loaders/dedoc","unlisted":false},{"type":"link","label":"Diffbot","href":"/docs/integrations/document_loaders/diffbot","className":"hidden","docId":"integrations/document_loaders/diffbot","unlisted":false},{"type":"link","label":"Discord","href":"/docs/integrations/document_loaders/discord","className":"hidden","docId":"integrations/document_loaders/discord","unlisted":false},{"type":"link","label":"Docling","href":"/docs/integrations/document_loaders/docling","className":"hidden","docId":"integrations/document_loaders/docling","unlisted":false},{"type":"link","label":"Docugami","href":"/docs/integrations/document_loaders/docugami","className":"hidden","docId":"integrations/document_loaders/docugami","unlisted":false},{"type":"link","label":"Docusaurus","href":"/docs/integrations/document_loaders/docusaurus","className":"hidden","docId":"integrations/document_loaders/docusaurus","unlisted":false},{"type":"link","label":"Dropbox","href":"/docs/integrations/document_loaders/dropbox","className":"hidden","docId":"integrations/document_loaders/dropbox","unlisted":false},{"type":"link","label":"DuckDB","href":"/docs/integrations/document_loaders/duckdb","className":"hidden","docId":"integrations/document_loaders/duckdb","unlisted":false},{"type":"link","label":"Email","href":"/docs/integrations/document_loaders/email","className":"hidden","docId":"integrations/document_loaders/email","unlisted":false},{"type":"link","label":"EPub","href":"/docs/integrations/document_loaders/epub","className":"hidden","docId":"integrations/document_loaders/epub","unlisted":false},{"type":"link","label":"Etherscan","href":"/docs/integrations/document_loaders/etherscan","className":"hidden","docId":"integrations/document_loaders/etherscan","unlisted":false},{"type":"link","label":"EverNote","href":"/docs/integrations/document_loaders/evernote","className":"hidden","docId":"integrations/document_loaders/evernote","unlisted":false},{"type":"category","label":"example_data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Sample Markdown Document","href":"/docs/integrations/document_loaders/example_data/example","docId":"integrations/document_loaders/example_data/example","unlisted":false}],"className":"hidden"},{"type":"link","label":"Facebook Chat","href":"/docs/integrations/document_loaders/facebook_chat","className":"hidden","docId":"integrations/document_loaders/facebook_chat","unlisted":false},{"type":"link","label":"Fauna","href":"/docs/integrations/document_loaders/fauna","className":"hidden","docId":"integrations/document_loaders/fauna","unlisted":false},{"type":"link","label":"Figma","href":"/docs/integrations/document_loaders/figma","className":"hidden","docId":"integrations/document_loaders/figma","unlisted":false},{"type":"link","label":"FireCrawl","href":"/docs/integrations/document_loaders/firecrawl","className":"hidden","docId":"integrations/document_loaders/firecrawl","unlisted":false},{"type":"link","label":"Geopandas","href":"/docs/integrations/document_loaders/geopandas","className":"hidden","docId":"integrations/document_loaders/geopandas","unlisted":false},{"type":"link","label":"Git","href":"/docs/integrations/document_loaders/git","className":"hidden","docId":"integrations/document_loaders/git","unlisted":false},{"type":"link","label":"GitBook","href":"/docs/integrations/document_loaders/gitbook","className":"hidden","docId":"integrations/document_loaders/gitbook","unlisted":false},{"type":"link","label":"GitHub","href":"/docs/integrations/document_loaders/github","className":"hidden","docId":"integrations/document_loaders/github","unlisted":false},{"type":"link","label":"Glue Catalog","href":"/docs/integrations/document_loaders/glue_catalog","className":"hidden","docId":"integrations/document_loaders/glue_catalog","unlisted":false},{"type":"link","label":"Google AlloyDB for PostgreSQL","href":"/docs/integrations/document_loaders/google_alloydb","className":"hidden","docId":"integrations/document_loaders/google_alloydb","unlisted":false},{"type":"link","label":"Google BigQuery","href":"/docs/integrations/document_loaders/google_bigquery","className":"hidden","docId":"integrations/document_loaders/google_bigquery","unlisted":false},{"type":"link","label":"Google Bigtable","href":"/docs/integrations/document_loaders/google_bigtable","className":"hidden","docId":"integrations/document_loaders/google_bigtable","unlisted":false},{"type":"link","label":"Google Cloud SQL for SQL server","href":"/docs/integrations/document_loaders/google_cloud_sql_mssql","className":"hidden","docId":"integrations/document_loaders/google_cloud_sql_mssql","unlisted":false},{"type":"link","label":"Google Cloud SQL for MySQL","href":"/docs/integrations/document_loaders/google_cloud_sql_mysql","className":"hidden","docId":"integrations/document_loaders/google_cloud_sql_mysql","unlisted":false},{"type":"link","label":"Google Cloud SQL for PostgreSQL","href":"/docs/integrations/document_loaders/google_cloud_sql_pg","className":"hidden","docId":"integrations/document_loaders/google_cloud_sql_pg","unlisted":false},{"type":"link","label":"Google Cloud Storage Directory","href":"/docs/integrations/document_loaders/google_cloud_storage_directory","className":"hidden","docId":"integrations/document_loaders/google_cloud_storage_directory","unlisted":false},{"type":"link","label":"Google Cloud Storage File","href":"/docs/integrations/document_loaders/google_cloud_storage_file","className":"hidden","docId":"integrations/document_loaders/google_cloud_storage_file","unlisted":false},{"type":"link","label":"Google Firestore in Datastore Mode","href":"/docs/integrations/document_loaders/google_datastore","className":"hidden","docId":"integrations/document_loaders/google_datastore","unlisted":false},{"type":"link","label":"Google Drive","href":"/docs/integrations/document_loaders/google_drive","className":"hidden","docId":"integrations/document_loaders/google_drive","unlisted":false},{"type":"link","label":"Google El Carro for Oracle Workloads","href":"/docs/integrations/document_loaders/google_el_carro","className":"hidden","docId":"integrations/document_loaders/google_el_carro","unlisted":false},{"type":"link","label":"Google Firestore (Native Mode)","href":"/docs/integrations/document_loaders/google_firestore","className":"hidden","docId":"integrations/document_loaders/google_firestore","unlisted":false},{"type":"link","label":"Google Memorystore for Redis","href":"/docs/integrations/document_loaders/google_memorystore_redis","className":"hidden","docId":"integrations/document_loaders/google_memorystore_redis","unlisted":false},{"type":"link","label":"Google Spanner","href":"/docs/integrations/document_loaders/google_spanner","className":"hidden","docId":"integrations/document_loaders/google_spanner","unlisted":false},{"type":"link","label":"Google Speech-to-Text Audio Transcripts","href":"/docs/integrations/document_loaders/google_speech_to_text","className":"hidden","docId":"integrations/document_loaders/google_speech_to_text","unlisted":false},{"type":"link","label":"Grobid","href":"/docs/integrations/document_loaders/grobid","className":"hidden","docId":"integrations/document_loaders/grobid","unlisted":false},{"type":"link","label":"Gutenberg","href":"/docs/integrations/document_loaders/gutenberg","className":"hidden","docId":"integrations/document_loaders/gutenberg","unlisted":false},{"type":"link","label":"Hacker News","href":"/docs/integrations/document_loaders/hacker_news","className":"hidden","docId":"integrations/document_loaders/hacker_news","unlisted":false},{"type":"link","label":"Huawei OBS Directory","href":"/docs/integrations/document_loaders/huawei_obs_directory","className":"hidden","docId":"integrations/document_loaders/huawei_obs_directory","unlisted":false},{"type":"link","label":"Huawei OBS File","href":"/docs/integrations/document_loaders/huawei_obs_file","className":"hidden","docId":"integrations/document_loaders/huawei_obs_file","unlisted":false},{"type":"link","label":"HuggingFace dataset","href":"/docs/integrations/document_loaders/hugging_face_dataset","className":"hidden","docId":"integrations/document_loaders/hugging_face_dataset","unlisted":false},{"type":"link","label":"HyperbrowserLoader","href":"/docs/integrations/document_loaders/hyperbrowser","className":"hidden","docId":"integrations/document_loaders/hyperbrowser","unlisted":false},{"type":"link","label":"iFixit","href":"/docs/integrations/document_loaders/ifixit","className":"hidden","docId":"integrations/document_loaders/ifixit","unlisted":false},{"type":"link","label":"Images","href":"/docs/integrations/document_loaders/image","className":"hidden","docId":"integrations/document_loaders/image","unlisted":false},{"type":"link","label":"Image captions","href":"/docs/integrations/document_loaders/image_captions","className":"hidden","docId":"integrations/document_loaders/image_captions","unlisted":false},{"type":"link","label":"IMSDb","href":"/docs/integrations/document_loaders/imsdb","className":"hidden","docId":"integrations/document_loaders/imsdb","unlisted":false},{"type":"link","label":"Iugu","href":"/docs/integrations/document_loaders/iugu","className":"hidden","docId":"integrations/document_loaders/iugu","unlisted":false},{"type":"link","label":"Joplin","href":"/docs/integrations/document_loaders/joplin","className":"hidden","docId":"integrations/document_loaders/joplin","unlisted":false},{"type":"link","label":"JSONLoader","href":"/docs/integrations/document_loaders/json","className":"hidden","docId":"integrations/document_loaders/json","unlisted":false},{"type":"link","label":"Jupyter Notebook","href":"/docs/integrations/document_loaders/jupyter_notebook","className":"hidden","docId":"integrations/document_loaders/jupyter_notebook","unlisted":false},{"type":"link","label":"Kinetica","href":"/docs/integrations/document_loaders/kinetica","className":"hidden","docId":"integrations/document_loaders/kinetica","unlisted":false},{"type":"link","label":"lakeFS","href":"/docs/integrations/document_loaders/lakefs","className":"hidden","docId":"integrations/document_loaders/lakefs","unlisted":false},{"type":"link","label":"LangSmith","href":"/docs/integrations/document_loaders/langsmith","className":"hidden","docId":"integrations/document_loaders/langsmith","unlisted":false},{"type":"link","label":"LarkSuite (FeiShu)","href":"/docs/integrations/document_loaders/larksuite","className":"hidden","docId":"integrations/document_loaders/larksuite","unlisted":false},{"type":"link","label":"LLM Sherpa","href":"/docs/integrations/document_loaders/llmsherpa","className":"hidden","docId":"integrations/document_loaders/llmsherpa","unlisted":false},{"type":"link","label":"Mastodon","href":"/docs/integrations/document_loaders/mastodon","className":"hidden","docId":"integrations/document_loaders/mastodon","unlisted":false},{"type":"link","label":"MathPixPDFLoader","href":"/docs/integrations/document_loaders/mathpix","className":"hidden","docId":"integrations/document_loaders/mathpix","unlisted":false},{"type":"link","label":"MediaWiki Dump","href":"/docs/integrations/document_loaders/mediawikidump","className":"hidden","docId":"integrations/document_loaders/mediawikidump","unlisted":false},{"type":"link","label":"Merge Documents Loader","href":"/docs/integrations/document_loaders/merge_doc","className":"hidden","docId":"integrations/document_loaders/merge_doc","unlisted":false},{"type":"link","label":"mhtml","href":"/docs/integrations/document_loaders/mhtml","className":"hidden","docId":"integrations/document_loaders/mhtml","unlisted":false},{"type":"link","label":"Microsoft Excel","href":"/docs/integrations/document_loaders/microsoft_excel","className":"hidden","docId":"integrations/document_loaders/microsoft_excel","unlisted":false},{"type":"link","label":"Microsoft OneDrive","href":"/docs/integrations/document_loaders/microsoft_onedrive","className":"hidden","docId":"integrations/document_loaders/microsoft_onedrive","unlisted":false},{"type":"link","label":"Microsoft OneNote","href":"/docs/integrations/document_loaders/microsoft_onenote","className":"hidden","docId":"integrations/document_loaders/microsoft_onenote","unlisted":false},{"type":"link","label":"Microsoft PowerPoint","href":"/docs/integrations/document_loaders/microsoft_powerpoint","className":"hidden","docId":"integrations/document_loaders/microsoft_powerpoint","unlisted":false},{"type":"link","label":"Microsoft SharePoint","href":"/docs/integrations/document_loaders/microsoft_sharepoint","className":"hidden","docId":"integrations/document_loaders/microsoft_sharepoint","unlisted":false},{"type":"link","label":"Microsoft Word","href":"/docs/integrations/document_loaders/microsoft_word","className":"hidden","docId":"integrations/document_loaders/microsoft_word","unlisted":false},{"type":"link","label":"Near Blockchain","href":"/docs/integrations/document_loaders/mintbase","className":"hidden","docId":"integrations/document_loaders/mintbase","unlisted":false},{"type":"link","label":"Modern Treasury","href":"/docs/integrations/document_loaders/modern_treasury","className":"hidden","docId":"integrations/document_loaders/modern_treasury","unlisted":false},{"type":"link","label":"MongoDB","href":"/docs/integrations/document_loaders/mongodb","className":"hidden","docId":"integrations/document_loaders/mongodb","unlisted":false},{"type":"link","label":"Needle Document Loader","href":"/docs/integrations/document_loaders/needle","className":"hidden","docId":"integrations/document_loaders/needle","unlisted":false},{"type":"link","label":"News URL","href":"/docs/integrations/document_loaders/news","className":"hidden","docId":"integrations/document_loaders/news","unlisted":false},{"type":"link","label":"Notion DB 2/2","href":"/docs/integrations/document_loaders/notion","className":"hidden","docId":"integrations/document_loaders/notion","unlisted":false},{"type":"link","label":"Nuclia","href":"/docs/integrations/document_loaders/nuclia","className":"hidden","docId":"integrations/document_loaders/nuclia","unlisted":false},{"type":"link","label":"Obsidian","href":"/docs/integrations/document_loaders/obsidian","className":"hidden","docId":"integrations/document_loaders/obsidian","unlisted":false},{"type":"link","label":"Open Document Format (ODT)","href":"/docs/integrations/document_loaders/odt","className":"hidden","docId":"integrations/document_loaders/odt","unlisted":false},{"type":"link","label":"Open City Data","href":"/docs/integrations/document_loaders/open_city_data","className":"hidden","docId":"integrations/document_loaders/open_city_data","unlisted":false},{"type":"link","label":"Oracle Autonomous Database","href":"/docs/integrations/document_loaders/oracleadb_loader","className":"hidden","docId":"integrations/document_loaders/oracleadb_loader","unlisted":false},{"type":"link","label":"Oracle AI Vector Search: Document Processing","href":"/docs/integrations/document_loaders/oracleai","className":"hidden","docId":"integrations/document_loaders/oracleai","unlisted":false},{"type":"link","label":"Org-mode","href":"/docs/integrations/document_loaders/org_mode","className":"hidden","docId":"integrations/document_loaders/org_mode","unlisted":false},{"type":"link","label":"Pandas DataFrame","href":"/docs/integrations/document_loaders/pandas_dataframe","className":"hidden","docId":"integrations/document_loaders/pandas_dataframe","unlisted":false},{"type":"category","label":"parsers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Azure OpenAI Whisper Parser","href":"/docs/integrations/document_loaders/parsers/azure_openai_whisper_parser","docId":"integrations/document_loaders/parsers/azure_openai_whisper_parser","unlisted":false},{"type":"link","label":"Writer PDF Parser","href":"/docs/integrations/document_loaders/parsers/writer_pdf_parser","docId":"integrations/document_loaders/parsers/writer_pdf_parser","unlisted":false}],"className":"hidden"},{"type":"link","label":"PDFMinerLoader","href":"/docs/integrations/document_loaders/pdfminer","className":"hidden","docId":"integrations/document_loaders/pdfminer","unlisted":false},{"type":"link","label":"PDFPlumber","href":"/docs/integrations/document_loaders/pdfplumber","className":"hidden","docId":"integrations/document_loaders/pdfplumber","unlisted":false},{"type":"link","label":"Pebblo Safe DocumentLoader","href":"/docs/integrations/document_loaders/pebblo","className":"hidden","docId":"integrations/document_loaders/pebblo","unlisted":false},{"type":"link","label":"Polars DataFrame","href":"/docs/integrations/document_loaders/polars_dataframe","className":"hidden","docId":"integrations/document_loaders/polars_dataframe","unlisted":false},{"type":"link","label":"Dell PowerScale Document Loader","href":"/docs/integrations/document_loaders/powerscale","className":"hidden","docId":"integrations/document_loaders/powerscale","unlisted":false},{"type":"link","label":"Psychic","href":"/docs/integrations/document_loaders/psychic","className":"hidden","docId":"integrations/document_loaders/psychic","unlisted":false},{"type":"link","label":"PubMed","href":"/docs/integrations/document_loaders/pubmed","className":"hidden","docId":"integrations/document_loaders/pubmed","unlisted":false},{"type":"link","label":"PullMdLoader","href":"/docs/integrations/document_loaders/pull_md","className":"hidden","docId":"integrations/document_loaders/pull_md","unlisted":false},{"type":"link","label":"PyMuPDFLoader","href":"/docs/integrations/document_loaders/pymupdf","className":"hidden","docId":"integrations/document_loaders/pymupdf","unlisted":false},{"type":"link","label":"PyMuPDF4LLM","href":"/docs/integrations/document_loaders/pymupdf4llm","className":"hidden","docId":"integrations/document_loaders/pymupdf4llm","unlisted":false},{"type":"link","label":"PyPDFDirectoryLoader","href":"/docs/integrations/document_loaders/pypdfdirectory","className":"hidden","docId":"integrations/document_loaders/pypdfdirectory","unlisted":false},{"type":"link","label":"PyPDFium2Loader","href":"/docs/integrations/document_loaders/pypdfium2","className":"hidden","docId":"integrations/document_loaders/pypdfium2","unlisted":false},{"type":"link","label":"PyPDFLoader","href":"/docs/integrations/document_loaders/pypdfloader","className":"hidden","docId":"integrations/document_loaders/pypdfloader","unlisted":false},{"type":"link","label":"PySpark","href":"/docs/integrations/document_loaders/pyspark_dataframe","className":"hidden","docId":"integrations/document_loaders/pyspark_dataframe","unlisted":false},{"type":"link","label":"Quip","href":"/docs/integrations/document_loaders/quip","className":"hidden","docId":"integrations/document_loaders/quip","unlisted":false},{"type":"link","label":"ReadTheDocs Documentation","href":"/docs/integrations/document_loaders/readthedocs_documentation","className":"hidden","docId":"integrations/document_loaders/readthedocs_documentation","unlisted":false},{"type":"link","label":"Recursive URL","href":"/docs/integrations/document_loaders/recursive_url","className":"hidden","docId":"integrations/document_loaders/recursive_url","unlisted":false},{"type":"link","label":"Reddit","href":"/docs/integrations/document_loaders/reddit","className":"hidden","docId":"integrations/document_loaders/reddit","unlisted":false},{"type":"link","label":"Roam","href":"/docs/integrations/document_loaders/roam","className":"hidden","docId":"integrations/document_loaders/roam","unlisted":false},{"type":"link","label":"Rockset","href":"/docs/integrations/document_loaders/rockset","className":"hidden","docId":"integrations/document_loaders/rockset","unlisted":false},{"type":"link","label":"rspace","href":"/docs/integrations/document_loaders/rspace","className":"hidden","docId":"integrations/document_loaders/rspace","unlisted":false},{"type":"link","label":"RSS Feeds","href":"/docs/integrations/document_loaders/rss","className":"hidden","docId":"integrations/document_loaders/rss","unlisted":false},{"type":"link","label":"RST","href":"/docs/integrations/document_loaders/rst","className":"hidden","docId":"integrations/document_loaders/rst","unlisted":false},{"type":"link","label":"scrapfly","href":"/docs/integrations/document_loaders/scrapfly","className":"hidden","docId":"integrations/document_loaders/scrapfly","unlisted":false},{"type":"link","label":"ScrapingAnt","href":"/docs/integrations/document_loaders/scrapingant","className":"hidden","docId":"integrations/document_loaders/scrapingant","unlisted":false},{"type":"link","label":"Sitemap","href":"/docs/integrations/document_loaders/sitemap","className":"hidden","docId":"integrations/document_loaders/sitemap","unlisted":false},{"type":"link","label":"Slack","href":"/docs/integrations/document_loaders/slack","className":"hidden","docId":"integrations/document_loaders/slack","unlisted":false},{"type":"link","label":"Snowflake","href":"/docs/integrations/document_loaders/snowflake","className":"hidden","docId":"integrations/document_loaders/snowflake","unlisted":false},{"type":"link","label":"Source Code","href":"/docs/integrations/document_loaders/source_code","className":"hidden","docId":"integrations/document_loaders/source_code","unlisted":false},{"type":"link","label":"Spider","href":"/docs/integrations/document_loaders/spider","className":"hidden","docId":"integrations/document_loaders/spider","unlisted":false},{"type":"link","label":"Spreedly","href":"/docs/integrations/document_loaders/spreedly","className":"hidden","docId":"integrations/document_loaders/spreedly","unlisted":false},{"type":"link","label":"Stripe","href":"/docs/integrations/document_loaders/stripe","className":"hidden","docId":"integrations/document_loaders/stripe","unlisted":false},{"type":"link","label":"Subtitle","href":"/docs/integrations/document_loaders/subtitle","className":"hidden","docId":"integrations/document_loaders/subtitle","unlisted":false},{"type":"link","label":"SurrealDB","href":"/docs/integrations/document_loaders/surrealdb","className":"hidden","docId":"integrations/document_loaders/surrealdb","unlisted":false},{"type":"link","label":"Telegram","href":"/docs/integrations/document_loaders/telegram","className":"hidden","docId":"integrations/document_loaders/telegram","unlisted":false},{"type":"link","label":"Tencent COS Directory","href":"/docs/integrations/document_loaders/tencent_cos_directory","className":"hidden","docId":"integrations/document_loaders/tencent_cos_directory","unlisted":false},{"type":"link","label":"Tencent COS File","href":"/docs/integrations/document_loaders/tencent_cos_file","className":"hidden","docId":"integrations/document_loaders/tencent_cos_file","unlisted":false},{"type":"link","label":"TensorFlow Datasets","href":"/docs/integrations/document_loaders/tensorflow_datasets","className":"hidden","docId":"integrations/document_loaders/tensorflow_datasets","unlisted":false},{"type":"link","label":"TiDB","href":"/docs/integrations/document_loaders/tidb","className":"hidden","docId":"integrations/document_loaders/tidb","unlisted":false},{"type":"link","label":"2Markdown","href":"/docs/integrations/document_loaders/tomarkdown","className":"hidden","docId":"integrations/document_loaders/tomarkdown","unlisted":false},{"type":"link","label":"TOML","href":"/docs/integrations/document_loaders/toml","className":"hidden","docId":"integrations/document_loaders/toml","unlisted":false},{"type":"link","label":"Trello","href":"/docs/integrations/document_loaders/trello","className":"hidden","docId":"integrations/document_loaders/trello","unlisted":false},{"type":"link","label":"TSV","href":"/docs/integrations/document_loaders/tsv","className":"hidden","docId":"integrations/document_loaders/tsv","unlisted":false},{"type":"link","label":"Twitter","href":"/docs/integrations/document_loaders/twitter","className":"hidden","docId":"integrations/document_loaders/twitter","unlisted":false},{"type":"link","label":"Unstructured","href":"/docs/integrations/document_loaders/unstructured_file","className":"hidden","docId":"integrations/document_loaders/unstructured_file","unlisted":false},{"type":"link","label":"UnstructuredMarkdownLoader","href":"/docs/integrations/document_loaders/unstructured_markdown","className":"hidden","docId":"integrations/document_loaders/unstructured_markdown","unlisted":false},{"type":"link","label":"UnstructuredPDFLoader","href":"/docs/integrations/document_loaders/unstructured_pdfloader","className":"hidden","docId":"integrations/document_loaders/unstructured_pdfloader","unlisted":false},{"type":"link","label":"Upstage","href":"/docs/integrations/document_loaders/upstage","className":"hidden","docId":"integrations/document_loaders/upstage","unlisted":false},{"type":"link","label":"URL","href":"/docs/integrations/document_loaders/url","className":"hidden","docId":"integrations/document_loaders/url","unlisted":false},{"type":"link","label":"Vsdx","href":"/docs/integrations/document_loaders/vsdx","className":"hidden","docId":"integrations/document_loaders/vsdx","unlisted":false},{"type":"link","label":"Weather","href":"/docs/integrations/document_loaders/weather","className":"hidden","docId":"integrations/document_loaders/weather","unlisted":false},{"type":"link","label":"WebBaseLoader","href":"/docs/integrations/document_loaders/web_base","className":"hidden","docId":"integrations/document_loaders/web_base","unlisted":false},{"type":"link","label":"WhatsApp Chat","href":"/docs/integrations/document_loaders/whatsapp_chat","className":"hidden","docId":"integrations/document_loaders/whatsapp_chat","unlisted":false},{"type":"link","label":"Wikipedia","href":"/docs/integrations/document_loaders/wikipedia","className":"hidden","docId":"integrations/document_loaders/wikipedia","unlisted":false},{"type":"link","label":"UnstructuredXMLLoader","href":"/docs/integrations/document_loaders/xml","className":"hidden","docId":"integrations/document_loaders/xml","unlisted":false},{"type":"link","label":"Xorbits Pandas DataFrame","href":"/docs/integrations/document_loaders/xorbits","className":"hidden","docId":"integrations/document_loaders/xorbits","unlisted":false},{"type":"link","label":"YouTube audio","href":"/docs/integrations/document_loaders/youtube_audio","className":"hidden","docId":"integrations/document_loaders/youtube_audio","unlisted":false},{"type":"link","label":"YouTube transcripts","href":"/docs/integrations/document_loaders/youtube_transcript","className":"hidden","docId":"integrations/document_loaders/youtube_transcript","unlisted":false},{"type":"link","label":"YoutubeLoaderDL","href":"/docs/integrations/document_loaders/yt_dlp","className":"hidden","docId":"integrations/document_loaders/yt_dlp","unlisted":false},{"type":"link","label":"Yuque","href":"/docs/integrations/document_loaders/yuque","className":"hidden","docId":"integrations/document_loaders/yuque","unlisted":false},{"type":"link","label":"ZeroxPDFLoader","href":"/docs/integrations/document_loaders/zeroxpdfloader","className":"hidden","docId":"integrations/document_loaders/zeroxpdfloader","unlisted":false}],"collapsed":false,"href":"/docs/integrations/document_loaders/"},{"type":"category","label":"Vector stores","collapsible":false,"items":[{"type":"link","label":"Vector stores","href":"/docs/integrations/vectorstores/","className":"hidden","docId":"integrations/vectorstores/index","unlisted":false},{"type":"link","label":"Activeloop Deep Lake","href":"/docs/integrations/vectorstores/activeloop_deeplake","className":"hidden","docId":"integrations/vectorstores/activeloop_deeplake","unlisted":false},{"type":"link","label":"Aerospike","href":"/docs/integrations/vectorstores/aerospike","className":"hidden","docId":"integrations/vectorstores/aerospike","unlisted":false},{"type":"link","label":"Alibaba Cloud OpenSearch","href":"/docs/integrations/vectorstores/alibabacloud_opensearch","className":"hidden","docId":"integrations/vectorstores/alibabacloud_opensearch","unlisted":false},{"type":"link","label":"AnalyticDB","href":"/docs/integrations/vectorstores/analyticdb","className":"hidden","docId":"integrations/vectorstores/analyticdb","unlisted":false},{"type":"link","label":"Annoy","href":"/docs/integrations/vectorstores/annoy","className":"hidden","docId":"integrations/vectorstores/annoy","unlisted":false},{"type":"link","label":"Apache Doris","href":"/docs/integrations/vectorstores/apache_doris","className":"hidden","docId":"integrations/vectorstores/apache_doris","unlisted":false},{"type":"link","label":"ApertureDB","href":"/docs/integrations/vectorstores/aperturedb","className":"hidden","docId":"integrations/vectorstores/aperturedb","unlisted":false},{"type":"link","label":"Astra DB Vector Store","href":"/docs/integrations/vectorstores/astradb","className":"hidden","docId":"integrations/vectorstores/astradb","unlisted":false},{"type":"link","label":"Atlas","href":"/docs/integrations/vectorstores/atlas","className":"hidden","docId":"integrations/vectorstores/atlas","unlisted":false},{"type":"link","label":"AwaDB","href":"/docs/integrations/vectorstores/awadb","className":"hidden","docId":"integrations/vectorstores/awadb","unlisted":false},{"type":"link","label":"Azure Cosmos DB Mongo vCore","href":"/docs/integrations/vectorstores/azure_cosmos_db","className":"hidden","docId":"integrations/vectorstores/azure_cosmos_db","unlisted":false},{"type":"link","label":"Azure Cosmos DB No SQL","href":"/docs/integrations/vectorstores/azure_cosmos_db_no_sql","className":"hidden","docId":"integrations/vectorstores/azure_cosmos_db_no_sql","unlisted":false},{"type":"link","label":"Azure AI Search","href":"/docs/integrations/vectorstores/azuresearch","className":"hidden","docId":"integrations/vectorstores/azuresearch","unlisted":false},{"type":"link","label":"Bagel","href":"/docs/integrations/vectorstores/bagel","className":"hidden","docId":"integrations/vectorstores/bagel","unlisted":false},{"type":"link","label":"BagelDB","href":"/docs/integrations/vectorstores/bageldb","className":"hidden","docId":"integrations/vectorstores/bageldb","unlisted":false},{"type":"link","label":"Baidu Cloud ElasticSearch VectorSearch","href":"/docs/integrations/vectorstores/baiducloud_vector_search","className":"hidden","docId":"integrations/vectorstores/baiducloud_vector_search","unlisted":false},{"type":"link","label":"Baidu VectorDB","href":"/docs/integrations/vectorstores/baiduvectordb","className":"hidden","docId":"integrations/vectorstores/baiduvectordb","unlisted":false},{"type":"link","label":"Apache Cassandra","href":"/docs/integrations/vectorstores/cassandra","className":"hidden","docId":"integrations/vectorstores/cassandra","unlisted":false},{"type":"link","label":"Chroma","href":"/docs/integrations/vectorstores/chroma","className":"hidden","docId":"integrations/vectorstores/chroma","unlisted":false},{"type":"link","label":"Clarifai","href":"/docs/integrations/vectorstores/clarifai","className":"hidden","docId":"integrations/vectorstores/clarifai","unlisted":false},{"type":"link","label":"ClickHouse","href":"/docs/integrations/vectorstores/clickhouse","className":"hidden","docId":"integrations/vectorstores/clickhouse","unlisted":false},{"type":"link","label":"Couchbase","href":"/docs/integrations/vectorstores/couchbase","className":"hidden","docId":"integrations/vectorstores/couchbase","unlisted":false},{"type":"link","label":"DashVector","href":"/docs/integrations/vectorstores/dashvector","className":"hidden","docId":"integrations/vectorstores/dashvector","unlisted":false},{"type":"link","label":"Databricks","href":"/docs/integrations/vectorstores/databricks_vector_search","className":"hidden","docId":"integrations/vectorstores/databricks_vector_search","unlisted":false},{"type":"link","label":"DingoDB","href":"/docs/integrations/vectorstores/dingo","className":"hidden","docId":"integrations/vectorstores/dingo","unlisted":false},{"type":"link","label":"DocArray HnswSearch","href":"/docs/integrations/vectorstores/docarray_hnsw","className":"hidden","docId":"integrations/vectorstores/docarray_hnsw","unlisted":false},{"type":"link","label":"DocArray InMemorySearch","href":"/docs/integrations/vectorstores/docarray_in_memory","className":"hidden","docId":"integrations/vectorstores/docarray_in_memory","unlisted":false},{"type":"link","label":"Amazon Document DB","href":"/docs/integrations/vectorstores/documentdb","className":"hidden","docId":"integrations/vectorstores/documentdb","unlisted":false},{"type":"link","label":"DuckDB","href":"/docs/integrations/vectorstores/duckdb","className":"hidden","docId":"integrations/vectorstores/duckdb","unlisted":false},{"type":"link","label":"China Mobile ECloud ElasticSearch VectorSearch","href":"/docs/integrations/vectorstores/ecloud_vector_search","className":"hidden","docId":"integrations/vectorstores/ecloud_vector_search","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/vectorstores/elasticsearch","className":"hidden","docId":"integrations/vectorstores/elasticsearch","unlisted":false},{"type":"link","label":"Epsilla","href":"/docs/integrations/vectorstores/epsilla","className":"hidden","docId":"integrations/vectorstores/epsilla","unlisted":false},{"type":"link","label":"Faiss","href":"/docs/integrations/vectorstores/faiss","className":"hidden","docId":"integrations/vectorstores/faiss","unlisted":false},{"type":"link","label":"Faiss (Async)","href":"/docs/integrations/vectorstores/faiss_async","className":"hidden","docId":"integrations/vectorstores/faiss_async","unlisted":false},{"type":"link","label":"FalkorDBVectorStore","href":"/docs/integrations/vectorstores/falkordbvector","className":"hidden","docId":"integrations/vectorstores/falkordbvector","unlisted":false},{"type":"link","label":"Google AlloyDB for PostgreSQL","href":"/docs/integrations/vectorstores/google_alloydb","className":"hidden","docId":"integrations/vectorstores/google_alloydb","unlisted":false},{"type":"link","label":"Google BigQuery Vector Search","href":"/docs/integrations/vectorstores/google_bigquery_vector_search","className":"hidden","docId":"integrations/vectorstores/google_bigquery_vector_search","unlisted":false},{"type":"link","label":"Google Cloud SQL for MySQL","href":"/docs/integrations/vectorstores/google_cloud_sql_mysql","className":"hidden","docId":"integrations/vectorstores/google_cloud_sql_mysql","unlisted":false},{"type":"link","label":"Google Cloud SQL for PostgreSQL","href":"/docs/integrations/vectorstores/google_cloud_sql_pg","className":"hidden","docId":"integrations/vectorstores/google_cloud_sql_pg","unlisted":false},{"type":"link","label":"Firestore","href":"/docs/integrations/vectorstores/google_firestore","className":"hidden","docId":"integrations/vectorstores/google_firestore","unlisted":false},{"type":"link","label":"Google Memorystore for Redis","href":"/docs/integrations/vectorstores/google_memorystore_redis","className":"hidden","docId":"integrations/vectorstores/google_memorystore_redis","unlisted":false},{"type":"link","label":"Google Spanner","href":"/docs/integrations/vectorstores/google_spanner","className":"hidden","docId":"integrations/vectorstores/google_spanner","unlisted":false},{"type":"link","label":"Google Vertex AI Feature Store","href":"/docs/integrations/vectorstores/google_vertex_ai_feature_store","className":"hidden","docId":"integrations/vectorstores/google_vertex_ai_feature_store","unlisted":false},{"type":"link","label":"Google Vertex AI Vector Search","href":"/docs/integrations/vectorstores/google_vertex_ai_vector_search","className":"hidden","docId":"integrations/vectorstores/google_vertex_ai_vector_search","unlisted":false},{"type":"link","label":"Hippo","href":"/docs/integrations/vectorstores/hippo","className":"hidden","docId":"integrations/vectorstores/hippo","unlisted":false},{"type":"link","label":"Hologres","href":"/docs/integrations/vectorstores/hologres","className":"hidden","docId":"integrations/vectorstores/hologres","unlisted":false},{"type":"link","label":"Infinispan","href":"/docs/integrations/vectorstores/infinispanvs","className":"hidden","docId":"integrations/vectorstores/infinispanvs","unlisted":false},{"type":"link","label":"Jaguar Vector Database","href":"/docs/integrations/vectorstores/jaguar","className":"hidden","docId":"integrations/vectorstores/jaguar","unlisted":false},{"type":"link","label":"KDB.AI","href":"/docs/integrations/vectorstores/kdbai","className":"hidden","docId":"integrations/vectorstores/kdbai","unlisted":false},{"type":"link","label":"Kinetica","href":"/docs/integrations/vectorstores/kinetica","className":"hidden","docId":"integrations/vectorstores/kinetica","unlisted":false},{"type":"link","label":"LanceDB","href":"/docs/integrations/vectorstores/lancedb","className":"hidden","docId":"integrations/vectorstores/lancedb","unlisted":false},{"type":"link","label":"Lantern","href":"/docs/integrations/vectorstores/lantern","className":"hidden","docId":"integrations/vectorstores/lantern","unlisted":false},{"type":"link","label":"Lindorm","href":"/docs/integrations/vectorstores/lindorm","className":"hidden","docId":"integrations/vectorstores/lindorm","unlisted":false},{"type":"link","label":"LLMRails","href":"/docs/integrations/vectorstores/llm_rails","className":"hidden","docId":"integrations/vectorstores/llm_rails","unlisted":false},{"type":"link","label":"ManticoreSearch VectorStore","href":"/docs/integrations/vectorstores/manticore_search","className":"hidden","docId":"integrations/vectorstores/manticore_search","unlisted":false},{"type":"link","label":"Marqo","href":"/docs/integrations/vectorstores/marqo","className":"hidden","docId":"integrations/vectorstores/marqo","unlisted":false},{"type":"link","label":"Meilisearch","href":"/docs/integrations/vectorstores/meilisearch","className":"hidden","docId":"integrations/vectorstores/meilisearch","unlisted":false},{"type":"link","label":"Amazon MemoryDB","href":"/docs/integrations/vectorstores/memorydb","className":"hidden","docId":"integrations/vectorstores/memorydb","unlisted":false},{"type":"link","label":"Milvus","href":"/docs/integrations/vectorstores/milvus","className":"hidden","docId":"integrations/vectorstores/milvus","unlisted":false},{"type":"link","label":"Momento Vector Index (MVI)","href":"/docs/integrations/vectorstores/momento_vector_index","className":"hidden","docId":"integrations/vectorstores/momento_vector_index","unlisted":false},{"type":"link","label":"MongoDB Atlas","href":"/docs/integrations/vectorstores/mongodb_atlas","className":"hidden","docId":"integrations/vectorstores/mongodb_atlas","unlisted":false},{"type":"link","label":"MyScale","href":"/docs/integrations/vectorstores/myscale","className":"hidden","docId":"integrations/vectorstores/myscale","unlisted":false},{"type":"link","label":"Neo4j Vector Index","href":"/docs/integrations/vectorstores/neo4jvector","className":"hidden","docId":"integrations/vectorstores/neo4jvector","unlisted":false},{"type":"link","label":"NucliaDB","href":"/docs/integrations/vectorstores/nucliadb","className":"hidden","docId":"integrations/vectorstores/nucliadb","unlisted":false},{"type":"link","label":"Oceanbase","href":"/docs/integrations/vectorstores/oceanbase","className":"hidden","docId":"integrations/vectorstores/oceanbase","unlisted":false},{"type":"link","label":"OpenSearch","href":"/docs/integrations/vectorstores/opensearch","className":"hidden","docId":"integrations/vectorstores/opensearch","unlisted":false},{"type":"link","label":"Oracle AI Vector Search: Vector Store","href":"/docs/integrations/vectorstores/oracle","className":"hidden","docId":"integrations/vectorstores/oracle","unlisted":false},{"type":"link","label":"Pathway","href":"/docs/integrations/vectorstores/pathway","className":"hidden","docId":"integrations/vectorstores/pathway","unlisted":false},{"type":"link","label":"Postgres Embedding","href":"/docs/integrations/vectorstores/pgembedding","className":"hidden","docId":"integrations/vectorstores/pgembedding","unlisted":false},{"type":"link","label":"PGVecto.rs","href":"/docs/integrations/vectorstores/pgvecto_rs","className":"hidden","docId":"integrations/vectorstores/pgvecto_rs","unlisted":false},{"type":"link","label":"PGVector","href":"/docs/integrations/vectorstores/pgvector","className":"hidden","docId":"integrations/vectorstores/pgvector","unlisted":false},{"type":"link","label":"Pinecone","href":"/docs/integrations/vectorstores/pinecone","className":"hidden","docId":"integrations/vectorstores/pinecone","unlisted":false},{"type":"link","label":"Qdrant","href":"/docs/integrations/vectorstores/qdrant","className":"hidden","docId":"integrations/vectorstores/qdrant","unlisted":false},{"type":"link","label":"Redis","href":"/docs/integrations/vectorstores/redis","className":"hidden","docId":"integrations/vectorstores/redis","unlisted":false},{"type":"link","label":"Relyt","href":"/docs/integrations/vectorstores/relyt","className":"hidden","docId":"integrations/vectorstores/relyt","unlisted":false},{"type":"link","label":"Rockset","href":"/docs/integrations/vectorstores/rockset","className":"hidden","docId":"integrations/vectorstores/rockset","unlisted":false},{"type":"link","label":"SAP HANA Cloud Vector Engine","href":"/docs/integrations/vectorstores/sap_hanavector","className":"hidden","docId":"integrations/vectorstores/sap_hanavector","unlisted":false},{"type":"link","label":"ScaNN","href":"/docs/integrations/vectorstores/scann","className":"hidden","docId":"integrations/vectorstores/scann","unlisted":false},{"type":"link","label":"SemaDB","href":"/docs/integrations/vectorstores/semadb","className":"hidden","docId":"integrations/vectorstores/semadb","unlisted":false},{"type":"link","label":"SingleStoreDB","href":"/docs/integrations/vectorstores/singlestoredb","className":"hidden","docId":"integrations/vectorstores/singlestoredb","unlisted":false},{"type":"link","label":"scikit-learn","href":"/docs/integrations/vectorstores/sklearn","className":"hidden","docId":"integrations/vectorstores/sklearn","unlisted":false},{"type":"link","label":"SQLiteVec","href":"/docs/integrations/vectorstores/sqlitevec","className":"hidden","docId":"integrations/vectorstores/sqlitevec","unlisted":false},{"type":"link","label":"SQLite-VSS","href":"/docs/integrations/vectorstores/sqlitevss","className":"hidden","docId":"integrations/vectorstores/sqlitevss","unlisted":false},{"type":"link","label":"SQLServer","href":"/docs/integrations/vectorstores/sqlserver","className":"hidden","docId":"integrations/vectorstores/sqlserver","unlisted":false},{"type":"link","label":"StarRocks","href":"/docs/integrations/vectorstores/starrocks","className":"hidden","docId":"integrations/vectorstores/starrocks","unlisted":false},{"type":"link","label":"Supabase (Postgres)","href":"/docs/integrations/vectorstores/supabase","className":"hidden","docId":"integrations/vectorstores/supabase","unlisted":false},{"type":"link","label":"SurrealDB","href":"/docs/integrations/vectorstores/surrealdb","className":"hidden","docId":"integrations/vectorstores/surrealdb","unlisted":false},{"type":"link","label":"Tablestore","href":"/docs/integrations/vectorstores/tablestore","className":"hidden","docId":"integrations/vectorstores/tablestore","unlisted":false},{"type":"link","label":"Tair","href":"/docs/integrations/vectorstores/tair","className":"hidden","docId":"integrations/vectorstores/tair","unlisted":false},{"type":"link","label":"Tencent Cloud VectorDB","href":"/docs/integrations/vectorstores/tencentvectordb","className":"hidden","docId":"integrations/vectorstores/tencentvectordb","unlisted":false},{"type":"link","label":"ThirdAI NeuralDB","href":"/docs/integrations/vectorstores/thirdai_neuraldb","className":"hidden","docId":"integrations/vectorstores/thirdai_neuraldb","unlisted":false},{"type":"link","label":"TiDB Vector","href":"/docs/integrations/vectorstores/tidb_vector","className":"hidden","docId":"integrations/vectorstores/tidb_vector","unlisted":false},{"type":"link","label":"Tigris","href":"/docs/integrations/vectorstores/tigris","className":"hidden","docId":"integrations/vectorstores/tigris","unlisted":false},{"type":"link","label":"TileDB","href":"/docs/integrations/vectorstores/tiledb","className":"hidden","docId":"integrations/vectorstores/tiledb","unlisted":false},{"type":"link","label":"Timescale Vector (Postgres)","href":"/docs/integrations/vectorstores/timescalevector","className":"hidden","docId":"integrations/vectorstores/timescalevector","unlisted":false},{"type":"link","label":"Typesense","href":"/docs/integrations/vectorstores/typesense","className":"hidden","docId":"integrations/vectorstores/typesense","unlisted":false},{"type":"link","label":"Upstash Vector","href":"/docs/integrations/vectorstores/upstash","className":"hidden","docId":"integrations/vectorstores/upstash","unlisted":false},{"type":"link","label":"USearch","href":"/docs/integrations/vectorstores/usearch","className":"hidden","docId":"integrations/vectorstores/usearch","unlisted":false},{"type":"link","label":"Vald","href":"/docs/integrations/vectorstores/vald","className":"hidden","docId":"integrations/vectorstores/vald","unlisted":false},{"type":"link","label":"VDMS","href":"/docs/integrations/vectorstores/vdms","className":"hidden","docId":"integrations/vectorstores/vdms","unlisted":false},{"type":"link","label":"Vearch","href":"/docs/integrations/vectorstores/vearch","className":"hidden","docId":"integrations/vectorstores/vearch","unlisted":false},{"type":"link","label":"Vectara","href":"/docs/integrations/vectorstores/vectara","className":"hidden","docId":"integrations/vectorstores/vectara","unlisted":false},{"type":"link","label":"Vespa","href":"/docs/integrations/vectorstores/vespa","className":"hidden","docId":"integrations/vectorstores/vespa","unlisted":false},{"type":"link","label":"viking DB","href":"/docs/integrations/vectorstores/vikingdb","className":"hidden","docId":"integrations/vectorstores/vikingdb","unlisted":false},{"type":"link","label":"vlite","href":"/docs/integrations/vectorstores/vlite","className":"hidden","docId":"integrations/vectorstores/vlite","unlisted":false},{"type":"link","label":"Weaviate","href":"/docs/integrations/vectorstores/weaviate","className":"hidden","docId":"integrations/vectorstores/weaviate","unlisted":false},{"type":"link","label":"Xata","href":"/docs/integrations/vectorstores/xata","className":"hidden","docId":"integrations/vectorstores/xata","unlisted":false},{"type":"link","label":"Yellowbrick","href":"/docs/integrations/vectorstores/yellowbrick","className":"hidden","docId":"integrations/vectorstores/yellowbrick","unlisted":false},{"type":"link","label":"Zep","href":"/docs/integrations/vectorstores/zep","className":"hidden","docId":"integrations/vectorstores/zep","unlisted":false},{"type":"link","label":"Zep Cloud","href":"/docs/integrations/vectorstores/zep_cloud","className":"hidden","docId":"integrations/vectorstores/zep_cloud","unlisted":false},{"type":"link","label":"Zilliz","href":"/docs/integrations/vectorstores/zilliz","className":"hidden","docId":"integrations/vectorstores/zilliz","unlisted":false}],"collapsed":false,"href":"/docs/integrations/vectorstores/"},{"type":"category","label":"Embedding models","collapsible":false,"items":[{"type":"link","label":"Embedding models","href":"/docs/integrations/text_embedding/","className":"hidden","docId":"integrations/text_embedding/index","unlisted":false},{"type":"link","label":"AI21","href":"/docs/integrations/text_embedding/ai21","className":"hidden","docId":"integrations/text_embedding/ai21","unlisted":false},{"type":"link","label":"Aleph Alpha","href":"/docs/integrations/text_embedding/aleph_alpha","className":"hidden","docId":"integrations/text_embedding/aleph_alpha","unlisted":false},{"type":"link","label":"Anyscale","href":"/docs/integrations/text_embedding/anyscale","className":"hidden","docId":"integrations/text_embedding/anyscale","unlisted":false},{"type":"link","label":"ascend","href":"/docs/integrations/text_embedding/ascend","className":"hidden","docId":"integrations/text_embedding/ascend","unlisted":false},{"type":"link","label":"AwaDB","href":"/docs/integrations/text_embedding/awadb","className":"hidden","docId":"integrations/text_embedding/awadb","unlisted":false},{"type":"link","label":"AzureOpenAI","href":"/docs/integrations/text_embedding/azureopenai","className":"hidden","docId":"integrations/text_embedding/azureopenai","unlisted":false},{"type":"link","label":"Baichuan Text Embeddings","href":"/docs/integrations/text_embedding/baichuan","className":"hidden","docId":"integrations/text_embedding/baichuan","unlisted":false},{"type":"link","label":"Baidu Qianfan","href":"/docs/integrations/text_embedding/baidu_qianfan_endpoint","className":"hidden","docId":"integrations/text_embedding/baidu_qianfan_endpoint","unlisted":false},{"type":"link","label":"Bedrock","href":"/docs/integrations/text_embedding/bedrock","className":"hidden","docId":"integrations/text_embedding/bedrock","unlisted":false},{"type":"link","label":"BGE on Hugging Face","href":"/docs/integrations/text_embedding/bge_huggingface","className":"hidden","docId":"integrations/text_embedding/bge_huggingface","unlisted":false},{"type":"link","label":"Bookend AI","href":"/docs/integrations/text_embedding/bookend","className":"hidden","docId":"integrations/text_embedding/bookend","unlisted":false},{"type":"link","label":"Clarifai","href":"/docs/integrations/text_embedding/clarifai","className":"hidden","docId":"integrations/text_embedding/clarifai","unlisted":false},{"type":"link","label":"Cloudflare Workers AI","href":"/docs/integrations/text_embedding/cloudflare_workersai","className":"hidden","docId":"integrations/text_embedding/cloudflare_workersai","unlisted":false},{"type":"link","label":"Clova Embeddings","href":"/docs/integrations/text_embedding/clova","className":"hidden","docId":"integrations/text_embedding/clova","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/text_embedding/cohere","className":"hidden","docId":"integrations/text_embedding/cohere","unlisted":false},{"type":"link","label":"DashScope","href":"/docs/integrations/text_embedding/dashscope","className":"hidden","docId":"integrations/text_embedding/dashscope","unlisted":false},{"type":"link","label":"Databricks","href":"/docs/integrations/text_embedding/databricks","className":"hidden","docId":"integrations/text_embedding/databricks","unlisted":false},{"type":"link","label":"DeepInfra","href":"/docs/integrations/text_embedding/deepinfra","className":"hidden","docId":"integrations/text_embedding/deepinfra","unlisted":false},{"type":"link","label":"EDEN AI","href":"/docs/integrations/text_embedding/edenai","className":"hidden","docId":"integrations/text_embedding/edenai","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/text_embedding/elasticsearch","className":"hidden","docId":"integrations/text_embedding/elasticsearch","unlisted":false},{"type":"link","label":"Embaas","href":"/docs/integrations/text_embedding/embaas","className":"hidden","docId":"integrations/text_embedding/embaas","unlisted":false},{"type":"link","label":"ERNIE","href":"/docs/integrations/text_embedding/ernie","className":"hidden","docId":"integrations/text_embedding/ernie","unlisted":false},{"type":"link","label":"Fake Embeddings","href":"/docs/integrations/text_embedding/fake","className":"hidden","docId":"integrations/text_embedding/fake","unlisted":false},{"type":"link","label":"FastEmbed by Qdrant","href":"/docs/integrations/text_embedding/fastembed","className":"hidden","docId":"integrations/text_embedding/fastembed","unlisted":false},{"type":"link","label":"Fireworks","href":"/docs/integrations/text_embedding/fireworks","className":"hidden","docId":"integrations/text_embedding/fireworks","unlisted":false},{"type":"link","label":"GigaChat","href":"/docs/integrations/text_embedding/gigachat","className":"hidden","docId":"integrations/text_embedding/gigachat","unlisted":false},{"type":"link","label":"Google Generative AI Embeddings","href":"/docs/integrations/text_embedding/google_generative_ai","className":"hidden","docId":"integrations/text_embedding/google_generative_ai","unlisted":false},{"type":"link","label":"Google Vertex AI","href":"/docs/integrations/text_embedding/google_vertex_ai_palm","className":"hidden","docId":"integrations/text_embedding/google_vertex_ai_palm","unlisted":false},{"type":"link","label":"GPT4All","href":"/docs/integrations/text_embedding/gpt4all","className":"hidden","docId":"integrations/text_embedding/gpt4all","unlisted":false},{"type":"link","label":"Gradient","href":"/docs/integrations/text_embedding/gradient","className":"hidden","docId":"integrations/text_embedding/gradient","unlisted":false},{"type":"link","label":"Hugging Face","href":"/docs/integrations/text_embedding/huggingfacehub","className":"hidden","docId":"integrations/text_embedding/huggingfacehub","unlisted":false},{"type":"link","label":"IBM watsonx.ai","href":"/docs/integrations/text_embedding/ibm_watsonx","className":"hidden","docId":"integrations/text_embedding/ibm_watsonx","unlisted":false},{"type":"link","label":"Infinity","href":"/docs/integrations/text_embedding/infinity","className":"hidden","docId":"integrations/text_embedding/infinity","unlisted":false},{"type":"link","label":"Instruct Embeddings on Hugging Face","href":"/docs/integrations/text_embedding/instruct_embeddings","className":"hidden","docId":"integrations/text_embedding/instruct_embeddings","unlisted":false},{"type":"link","label":"IPEX-LLM: Local BGE Embeddings on Intel CPU","href":"/docs/integrations/text_embedding/ipex_llm","className":"hidden","docId":"integrations/text_embedding/ipex_llm","unlisted":false},{"type":"link","label":"IPEX-LLM: Local BGE Embeddings on Intel GPU","href":"/docs/integrations/text_embedding/ipex_llm_gpu","className":"hidden","docId":"integrations/text_embedding/ipex_llm_gpu","unlisted":false},{"type":"link","label":"Intel\xae Extension for Transformers Quantized Text Embeddings","href":"/docs/integrations/text_embedding/itrex","className":"hidden","docId":"integrations/text_embedding/itrex","unlisted":false},{"type":"link","label":"Jina","href":"/docs/integrations/text_embedding/jina","className":"hidden","docId":"integrations/text_embedding/jina","unlisted":false},{"type":"link","label":"John Snow Labs","href":"/docs/integrations/text_embedding/johnsnowlabs_embedding","className":"hidden","docId":"integrations/text_embedding/johnsnowlabs_embedding","unlisted":false},{"type":"link","label":"LASER Language-Agnostic SEntence Representations Embeddings by Meta AI","href":"/docs/integrations/text_embedding/laser","className":"hidden","docId":"integrations/text_embedding/laser","unlisted":false},{"type":"link","label":"Lindorm","href":"/docs/integrations/text_embedding/lindorm","className":"hidden","docId":"integrations/text_embedding/lindorm","unlisted":false},{"type":"link","label":"Llama.cpp","href":"/docs/integrations/text_embedding/llamacpp","className":"hidden","docId":"integrations/text_embedding/llamacpp","unlisted":false},{"type":"link","label":"llamafile","href":"/docs/integrations/text_embedding/llamafile","className":"hidden","docId":"integrations/text_embedding/llamafile","unlisted":false},{"type":"link","label":"LLMRails","href":"/docs/integrations/text_embedding/llm_rails","className":"hidden","docId":"integrations/text_embedding/llm_rails","unlisted":false},{"type":"link","label":"LocalAI","href":"/docs/integrations/text_embedding/localai","className":"hidden","docId":"integrations/text_embedding/localai","unlisted":false},{"type":"link","label":"MiniMax","href":"/docs/integrations/text_embedding/minimax","className":"hidden","docId":"integrations/text_embedding/minimax","unlisted":false},{"type":"link","label":"MistralAI","href":"/docs/integrations/text_embedding/mistralai","className":"hidden","docId":"integrations/text_embedding/mistralai","unlisted":false},{"type":"link","label":"model2vec","href":"/docs/integrations/text_embedding/model2vec","className":"hidden","docId":"integrations/text_embedding/model2vec","unlisted":false},{"type":"link","label":"ModelScope","href":"/docs/integrations/text_embedding/modelscope_embedding","className":"hidden","docId":"integrations/text_embedding/modelscope_embedding","unlisted":false},{"type":"link","label":"MosaicML","href":"/docs/integrations/text_embedding/mosaicml","className":"hidden","docId":"integrations/text_embedding/mosaicml","unlisted":false},{"type":"link","label":"Naver","href":"/docs/integrations/text_embedding/naver","className":"hidden","docId":"integrations/text_embedding/naver","unlisted":false},{"type":"link","label":"NLP Cloud","href":"/docs/integrations/text_embedding/nlp_cloud","className":"hidden","docId":"integrations/text_embedding/nlp_cloud","unlisted":false},{"type":"link","label":"Nomic","href":"/docs/integrations/text_embedding/nomic","className":"hidden","docId":"integrations/text_embedding/nomic","unlisted":false},{"type":"link","label":"NVIDIA NIMs","href":"/docs/integrations/text_embedding/nvidia_ai_endpoints","className":"hidden","docId":"integrations/text_embedding/nvidia_ai_endpoints","unlisted":false},{"type":"link","label":"Oracle Cloud Infrastructure Generative AI","href":"/docs/integrations/text_embedding/oci_generative_ai","className":"hidden","docId":"integrations/text_embedding/oci_generative_ai","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/text_embedding/ollama","className":"hidden","docId":"integrations/text_embedding/ollama","unlisted":false},{"type":"link","label":"OpenClip","href":"/docs/integrations/text_embedding/open_clip","className":"hidden","docId":"integrations/text_embedding/open_clip","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/text_embedding/openai","className":"hidden","docId":"integrations/text_embedding/openai","unlisted":false},{"type":"link","label":"OpenVINO","href":"/docs/integrations/text_embedding/openvino","className":"hidden","docId":"integrations/text_embedding/openvino","unlisted":false},{"type":"link","label":"Embedding Documents using Optimized and Quantized Embedders","href":"/docs/integrations/text_embedding/optimum_intel","className":"hidden","docId":"integrations/text_embedding/optimum_intel","unlisted":false},{"type":"link","label":"Oracle AI Vector Search: Generate Embeddings","href":"/docs/integrations/text_embedding/oracleai","className":"hidden","docId":"integrations/text_embedding/oracleai","unlisted":false},{"type":"link","label":"OVHcloud","href":"/docs/integrations/text_embedding/ovhcloud","className":"hidden","docId":"integrations/text_embedding/ovhcloud","unlisted":false},{"type":"link","label":"Pinecone Embeddings","href":"/docs/integrations/text_embedding/pinecone","className":"hidden","docId":"integrations/text_embedding/pinecone","unlisted":false},{"type":"link","label":"PredictionGuardEmbeddings","href":"/docs/integrations/text_embedding/predictionguard","className":"hidden","docId":"integrations/text_embedding/predictionguard","unlisted":false},{"type":"link","label":"PremAI","href":"/docs/integrations/text_embedding/premai","className":"hidden","docId":"integrations/text_embedding/premai","unlisted":false},{"type":"link","label":"SageMaker","href":"/docs/integrations/text_embedding/sagemaker-endpoint","className":"hidden","docId":"integrations/text_embedding/sagemaker-endpoint","unlisted":false},{"type":"link","label":"SambaStudio","href":"/docs/integrations/text_embedding/sambanova","className":"hidden","docId":"integrations/text_embedding/sambanova","unlisted":false},{"type":"link","label":"Self Hosted","href":"/docs/integrations/text_embedding/self-hosted","className":"hidden","docId":"integrations/text_embedding/self-hosted","unlisted":false},{"type":"link","label":"Sentence Transformers on Hugging Face","href":"/docs/integrations/text_embedding/sentence_transformers","className":"hidden","docId":"integrations/text_embedding/sentence_transformers","unlisted":false},{"type":"link","label":"Solar","href":"/docs/integrations/text_embedding/solar","className":"hidden","docId":"integrations/text_embedding/solar","unlisted":false},{"type":"link","label":"SpaCy","href":"/docs/integrations/text_embedding/spacy_embedding","className":"hidden","docId":"integrations/text_embedding/spacy_embedding","unlisted":false},{"type":"link","label":"SparkLLM Text Embeddings","href":"/docs/integrations/text_embedding/sparkllm","className":"hidden","docId":"integrations/text_embedding/sparkllm","unlisted":false},{"type":"link","label":"TensorFlow Hub","href":"/docs/integrations/text_embedding/tensorflowhub","className":"hidden","docId":"integrations/text_embedding/tensorflowhub","unlisted":false},{"type":"link","label":"Text Embeddings Inference","href":"/docs/integrations/text_embedding/text_embeddings_inference","className":"hidden","docId":"integrations/text_embedding/text_embeddings_inference","unlisted":false},{"type":"link","label":"TextEmbed - Embedding Inference Server","href":"/docs/integrations/text_embedding/textembed","className":"hidden","docId":"integrations/text_embedding/textembed","unlisted":false},{"type":"link","label":"Titan Takeoff","href":"/docs/integrations/text_embedding/titan_takeoff","className":"hidden","docId":"integrations/text_embedding/titan_takeoff","unlisted":false},{"type":"link","label":"Together AI","href":"/docs/integrations/text_embedding/together","className":"hidden","docId":"integrations/text_embedding/together","unlisted":false},{"type":"link","label":"Upstage","href":"/docs/integrations/text_embedding/upstage","className":"hidden","docId":"integrations/text_embedding/upstage","unlisted":false},{"type":"link","label":"Volc Engine","href":"/docs/integrations/text_embedding/volcengine","className":"hidden","docId":"integrations/text_embedding/volcengine","unlisted":false},{"type":"link","label":"Voyage AI","href":"/docs/integrations/text_embedding/voyageai","className":"hidden","docId":"integrations/text_embedding/voyageai","unlisted":false},{"type":"link","label":"Xorbits inference (Xinference)","href":"/docs/integrations/text_embedding/xinference","className":"hidden","docId":"integrations/text_embedding/xinference","unlisted":false},{"type":"link","label":"YandexGPT","href":"/docs/integrations/text_embedding/yandex","className":"hidden","docId":"integrations/text_embedding/yandex","unlisted":false},{"type":"link","label":"ZhipuAI","href":"/docs/integrations/text_embedding/zhipuai","className":"hidden","docId":"integrations/text_embedding/zhipuai","unlisted":false}],"collapsed":false,"href":"/docs/integrations/text_embedding/"},{"type":"category","label":"Other","collapsed":true,"items":[{"type":"category","label":"LLMs","collapsible":false,"items":[{"type":"link","label":"LLMs","href":"/docs/integrations/llms/","className":"hidden","docId":"integrations/llms/index","unlisted":false},{"type":"link","label":"AI21 Labs","href":"/docs/integrations/llms/ai21","className":"hidden","docId":"integrations/llms/ai21","unlisted":false},{"type":"link","label":"Aleph Alpha","href":"/docs/integrations/llms/aleph_alpha","className":"hidden","docId":"integrations/llms/aleph_alpha","unlisted":false},{"type":"link","label":"Alibaba Cloud PAI EAS","href":"/docs/integrations/llms/alibabacloud_pai_eas_endpoint","className":"hidden","docId":"integrations/llms/alibabacloud_pai_eas_endpoint","unlisted":false},{"type":"link","label":"Amazon API Gateway","href":"/docs/integrations/llms/amazon_api_gateway","className":"hidden","docId":"integrations/llms/amazon_api_gateway","unlisted":false},{"type":"link","label":"Anthropic","href":"/docs/integrations/llms/anthropic","className":"hidden","docId":"integrations/llms/anthropic","unlisted":false},{"type":"link","label":"Anyscale","href":"/docs/integrations/llms/anyscale","className":"hidden","docId":"integrations/llms/anyscale","unlisted":false},{"type":"link","label":"Aphrodite Engine","href":"/docs/integrations/llms/aphrodite","className":"hidden","docId":"integrations/llms/aphrodite","unlisted":false},{"type":"link","label":"Arcee","href":"/docs/integrations/llms/arcee","className":"hidden","docId":"integrations/llms/arcee","unlisted":false},{"type":"link","label":"Azure ML","href":"/docs/integrations/llms/azure_ml","className":"hidden","docId":"integrations/llms/azure_ml","unlisted":false},{"type":"link","label":"Azure OpenAI","href":"/docs/integrations/llms/azure_openai","className":"hidden","docId":"integrations/llms/azure_openai","unlisted":false},{"type":"link","label":"Baichuan LLM","href":"/docs/integrations/llms/baichuan","className":"hidden","docId":"integrations/llms/baichuan","unlisted":false},{"type":"link","label":"Baidu Qianfan","href":"/docs/integrations/llms/baidu_qianfan_endpoint","className":"hidden","docId":"integrations/llms/baidu_qianfan_endpoint","unlisted":false},{"type":"link","label":"Banana","href":"/docs/integrations/llms/banana","className":"hidden","docId":"integrations/llms/banana","unlisted":false},{"type":"link","label":"Baseten","href":"/docs/integrations/llms/baseten","className":"hidden","docId":"integrations/llms/baseten","unlisted":false},{"type":"link","label":"Beam","href":"/docs/integrations/llms/beam","className":"hidden","docId":"integrations/llms/beam","unlisted":false},{"type":"link","label":"Bedrock","href":"/docs/integrations/llms/bedrock","className":"hidden","docId":"integrations/llms/bedrock","unlisted":false},{"type":"link","label":"Bittensor","href":"/docs/integrations/llms/bittensor","className":"hidden","docId":"integrations/llms/bittensor","unlisted":false},{"type":"link","label":"CerebriumAI","href":"/docs/integrations/llms/cerebriumai","className":"hidden","docId":"integrations/llms/cerebriumai","unlisted":false},{"type":"link","label":"ChatGLM","href":"/docs/integrations/llms/chatglm","className":"hidden","docId":"integrations/llms/chatglm","unlisted":false},{"type":"link","label":"Clarifai","href":"/docs/integrations/llms/clarifai","className":"hidden","docId":"integrations/llms/clarifai","unlisted":false},{"type":"link","label":"Cloudflare Workers AI","href":"/docs/integrations/llms/cloudflare_workersai","className":"hidden","docId":"integrations/llms/cloudflare_workersai","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/llms/cohere","className":"hidden","docId":"integrations/llms/cohere","unlisted":false},{"type":"link","label":"C Transformers","href":"/docs/integrations/llms/ctransformers","className":"hidden","docId":"integrations/llms/ctransformers","unlisted":false},{"type":"link","label":"CTranslate2","href":"/docs/integrations/llms/ctranslate2","className":"hidden","docId":"integrations/llms/ctranslate2","unlisted":false},{"type":"link","label":"Databricks","href":"/docs/integrations/llms/databricks","className":"hidden","docId":"integrations/llms/databricks","unlisted":false},{"type":"link","label":"DeepInfra","href":"/docs/integrations/llms/deepinfra","className":"hidden","docId":"integrations/llms/deepinfra","unlisted":false},{"type":"link","label":"DeepSparse","href":"/docs/integrations/llms/deepsparse","className":"hidden","docId":"integrations/llms/deepsparse","unlisted":false},{"type":"link","label":"Eden AI","href":"/docs/integrations/llms/edenai","className":"hidden","docId":"integrations/llms/edenai","unlisted":false},{"type":"link","label":"ExLlamaV2","href":"/docs/integrations/llms/exllamav2","className":"hidden","docId":"integrations/llms/exllamav2","unlisted":false},{"type":"link","label":"Fireworks","href":"/docs/integrations/llms/fireworks","className":"hidden","docId":"integrations/llms/fireworks","unlisted":false},{"type":"link","label":"ForefrontAI","href":"/docs/integrations/llms/forefrontai","className":"hidden","docId":"integrations/llms/forefrontai","unlisted":false},{"type":"link","label":"Friendli","href":"/docs/integrations/llms/friendli","className":"hidden","docId":"integrations/llms/friendli","unlisted":false},{"type":"link","label":"GigaChat","href":"/docs/integrations/llms/gigachat","className":"hidden","docId":"integrations/llms/gigachat","unlisted":false},{"type":"link","label":"Google AI","href":"/docs/integrations/llms/google_ai","className":"hidden","docId":"integrations/llms/google_ai","unlisted":false},{"type":"link","label":"Google Cloud Vertex AI","href":"/docs/integrations/llms/google_vertex_ai_palm","className":"hidden","docId":"integrations/llms/google_vertex_ai_palm","unlisted":false},{"type":"link","label":"GooseAI","href":"/docs/integrations/llms/gooseai","className":"hidden","docId":"integrations/llms/gooseai","unlisted":false},{"type":"link","label":"GPT4All","href":"/docs/integrations/llms/gpt4all","className":"hidden","docId":"integrations/llms/gpt4all","unlisted":false},{"type":"link","label":"Gradient","href":"/docs/integrations/llms/gradient","className":"hidden","docId":"integrations/llms/gradient","unlisted":false},{"type":"link","label":"Huggingface Endpoints","href":"/docs/integrations/llms/huggingface_endpoint","className":"hidden","docId":"integrations/llms/huggingface_endpoint","unlisted":false},{"type":"link","label":"Hugging Face Local Pipelines","href":"/docs/integrations/llms/huggingface_pipelines","className":"hidden","docId":"integrations/llms/huggingface_pipelines","unlisted":false},{"type":"link","label":"IBM watsonx.ai","href":"/docs/integrations/llms/ibm_watsonx","className":"hidden","docId":"integrations/llms/ibm_watsonx","unlisted":false},{"type":"link","label":"IPEX-LLM","href":"/docs/integrations/llms/ipex_llm","className":"hidden","docId":"integrations/llms/ipex_llm","unlisted":false},{"type":"link","label":"Javelin AI Gateway Tutorial","href":"/docs/integrations/llms/javelin","className":"hidden","docId":"integrations/llms/javelin","unlisted":false},{"type":"link","label":"JSONFormer","href":"/docs/integrations/llms/jsonformer_experimental","className":"hidden","docId":"integrations/llms/jsonformer_experimental","unlisted":false},{"type":"link","label":"KoboldAI API","href":"/docs/integrations/llms/koboldai","className":"hidden","docId":"integrations/llms/koboldai","unlisted":false},{"type":"link","label":"Konko","href":"/docs/integrations/llms/konko","className":"hidden","docId":"integrations/llms/konko","unlisted":false},{"type":"link","label":"Layerup Security","href":"/docs/integrations/llms/layerup_security","className":"hidden","docId":"integrations/llms/layerup_security","unlisted":false},{"type":"link","label":"Llama.cpp","href":"/docs/integrations/llms/llamacpp","className":"hidden","docId":"integrations/llms/llamacpp","unlisted":false},{"type":"link","label":"Llamafile","href":"/docs/integrations/llms/llamafile","className":"hidden","docId":"integrations/llms/llamafile","unlisted":false},{"type":"link","label":"LM Format Enforcer","href":"/docs/integrations/llms/lmformatenforcer_experimental","className":"hidden","docId":"integrations/llms/lmformatenforcer_experimental","unlisted":false},{"type":"link","label":"Manifest","href":"/docs/integrations/llms/manifest","className":"hidden","docId":"integrations/llms/manifest","unlisted":false},{"type":"link","label":"Minimax","href":"/docs/integrations/llms/minimax","className":"hidden","docId":"integrations/llms/minimax","unlisted":false},{"type":"link","label":"MLX Local Pipelines","href":"/docs/integrations/llms/mlx_pipelines","className":"hidden","docId":"integrations/llms/mlx_pipelines","unlisted":false},{"type":"link","label":"Modal","href":"/docs/integrations/llms/modal","className":"hidden","docId":"integrations/llms/modal","unlisted":false},{"type":"link","label":"ModelScope","href":"/docs/integrations/llms/modelscope_endpoint","className":"hidden","docId":"integrations/llms/modelscope_endpoint","unlisted":false},{"type":"link","label":"MoonshotChat","href":"/docs/integrations/llms/moonshot","className":"hidden","docId":"integrations/llms/moonshot","unlisted":false},{"type":"link","label":"MosaicML","href":"/docs/integrations/llms/mosaicml","className":"hidden","docId":"integrations/llms/mosaicml","unlisted":false},{"type":"link","label":"NLP Cloud","href":"/docs/integrations/llms/nlpcloud","className":"hidden","docId":"integrations/llms/nlpcloud","unlisted":false},{"type":"link","label":"NVIDIA","href":"/docs/integrations/llms/nvidia_ai_endpoints","className":"hidden","docId":"integrations/llms/nvidia_ai_endpoints","unlisted":false},{"type":"link","label":"oci_generative_ai","href":"/docs/integrations/llms/oci_generative_ai","className":"hidden","docId":"integrations/llms/oci_generative_ai","unlisted":false},{"type":"link","label":"OCI Data Science Model Deployment Endpoint","href":"/docs/integrations/llms/oci_model_deployment_endpoint","className":"hidden","docId":"integrations/llms/oci_model_deployment_endpoint","unlisted":false},{"type":"link","label":"OctoAI","href":"/docs/integrations/llms/octoai","className":"hidden","docId":"integrations/llms/octoai","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/llms/ollama","className":"hidden","docId":"integrations/llms/ollama","unlisted":false},{"type":"link","label":"OpaquePrompts","href":"/docs/integrations/llms/opaqueprompts","className":"hidden","docId":"integrations/llms/opaqueprompts","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/llms/openai","className":"hidden","docId":"integrations/llms/openai","unlisted":false},{"type":"link","label":"OpenLLM","href":"/docs/integrations/llms/openllm","className":"hidden","docId":"integrations/llms/openllm","unlisted":false},{"type":"link","label":"OpenLM","href":"/docs/integrations/llms/openlm","className":"hidden","docId":"integrations/llms/openlm","unlisted":false},{"type":"link","label":"OpenVINO","href":"/docs/integrations/llms/openvino","className":"hidden","docId":"integrations/llms/openvino","unlisted":false},{"type":"link","label":"Outlines","href":"/docs/integrations/llms/outlines","className":"hidden","docId":"integrations/llms/outlines","unlisted":false},{"type":"link","label":"Petals","href":"/docs/integrations/llms/petals","className":"hidden","docId":"integrations/llms/petals","unlisted":false},{"type":"link","label":"PipelineAI","href":"/docs/integrations/llms/pipelineai","className":"hidden","docId":"integrations/llms/pipelineai","unlisted":false},{"type":"link","label":"Pipeshift","href":"/docs/integrations/llms/pipeshift","className":"hidden","docId":"integrations/llms/pipeshift","unlisted":false},{"type":"link","label":"Predibase","href":"/docs/integrations/llms/predibase","className":"hidden","docId":"integrations/llms/predibase","unlisted":false},{"type":"link","label":"PredictionGuard","href":"/docs/integrations/llms/predictionguard","className":"hidden","docId":"integrations/llms/predictionguard","unlisted":false},{"type":"link","label":"PromptLayer OpenAI","href":"/docs/integrations/llms/promptlayer_openai","className":"hidden","docId":"integrations/llms/promptlayer_openai","unlisted":false},{"type":"link","label":"RELLM","href":"/docs/integrations/llms/rellm_experimental","className":"hidden","docId":"integrations/llms/rellm_experimental","unlisted":false},{"type":"link","label":"Replicate","href":"/docs/integrations/llms/replicate","className":"hidden","docId":"integrations/llms/replicate","unlisted":false},{"type":"link","label":"Runhouse","href":"/docs/integrations/llms/runhouse","className":"hidden","docId":"integrations/llms/runhouse","unlisted":false},{"type":"link","label":"SageMakerEndpoint","href":"/docs/integrations/llms/sagemaker","className":"hidden","docId":"integrations/llms/sagemaker","unlisted":false},{"type":"link","label":"SambaNovaCloud","href":"/docs/integrations/llms/sambanovacloud","className":"hidden","docId":"integrations/llms/sambanovacloud","unlisted":false},{"type":"link","label":"SambaStudio","href":"/docs/integrations/llms/sambastudio","className":"hidden","docId":"integrations/llms/sambastudio","unlisted":false},{"type":"link","label":"Solar","href":"/docs/integrations/llms/solar","className":"hidden","docId":"integrations/llms/solar","unlisted":false},{"type":"link","label":"SparkLLM","href":"/docs/integrations/llms/sparkllm","className":"hidden","docId":"integrations/llms/sparkllm","unlisted":false},{"type":"link","label":"StochasticAI","href":"/docs/integrations/llms/stochasticai","className":"hidden","docId":"integrations/llms/stochasticai","unlisted":false},{"type":"link","label":"Nebula (Symbl.ai)","href":"/docs/integrations/llms/symblai_nebula","className":"hidden","docId":"integrations/llms/symblai_nebula","unlisted":false},{"type":"link","label":"TextGen","href":"/docs/integrations/llms/textgen","className":"hidden","docId":"integrations/llms/textgen","unlisted":false},{"type":"link","label":"Titan Takeoff","href":"/docs/integrations/llms/titan_takeoff","className":"hidden","docId":"integrations/llms/titan_takeoff","unlisted":false},{"type":"link","label":"Together AI","href":"/docs/integrations/llms/together","className":"hidden","docId":"integrations/llms/together","unlisted":false},{"type":"link","label":"Tongyi Qwen","href":"/docs/integrations/llms/tongyi","className":"hidden","docId":"integrations/llms/tongyi","unlisted":false},{"type":"link","label":"vLLM","href":"/docs/integrations/llms/vllm","className":"hidden","docId":"integrations/llms/vllm","unlisted":false},{"type":"link","label":"Volc Engine Maas","href":"/docs/integrations/llms/volcengine_maas","className":"hidden","docId":"integrations/llms/volcengine_maas","unlisted":false},{"type":"link","label":"Intel Weight-Only Quantization","href":"/docs/integrations/llms/weight_only_quantization","className":"hidden","docId":"integrations/llms/weight_only_quantization","unlisted":false},{"type":"link","label":"Writer LLM","href":"/docs/integrations/llms/writer","className":"hidden","docId":"integrations/llms/writer","unlisted":false},{"type":"link","label":"Xorbits Inference (Xinference)","href":"/docs/integrations/llms/xinference","className":"hidden","docId":"integrations/llms/xinference","unlisted":false},{"type":"link","label":"YandexGPT","href":"/docs/integrations/llms/yandex","className":"hidden","docId":"integrations/llms/yandex","unlisted":false},{"type":"link","label":"Yi","href":"/docs/integrations/llms/yi","className":"hidden","docId":"integrations/llms/yi","unlisted":false},{"type":"link","label":"Yuan2.0","href":"/docs/integrations/llms/yuan2","className":"hidden","docId":"integrations/llms/yuan2","unlisted":false}],"collapsed":false,"href":"/docs/integrations/llms/"},{"type":"category","label":"Key-value stores","collapsible":false,"items":[{"type":"link","label":"AstraDB","href":"/docs/integrations/stores/astradb","className":"hidden","docId":"integrations/stores/astradb","unlisted":false},{"type":"link","label":"Cassandra","href":"/docs/integrations/stores/cassandra","className":"hidden","docId":"integrations/stores/cassandra","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/stores/elasticsearch","className":"hidden","docId":"integrations/stores/elasticsearch","unlisted":false},{"type":"link","label":"Local Filesystem","href":"/docs/integrations/stores/file_system","className":"hidden","docId":"integrations/stores/file_system","unlisted":false},{"type":"link","label":"In-memory","href":"/docs/integrations/stores/in_memory","className":"hidden","docId":"integrations/stores/in_memory","unlisted":false},{"type":"link","label":"Key-value stores","href":"/docs/integrations/stores/","className":"hidden","docId":"integrations/stores/index","unlisted":false},{"type":"link","label":"Redis","href":"/docs/integrations/stores/redis","className":"hidden","docId":"integrations/stores/redis","unlisted":false},{"type":"link","label":"Upstash Redis","href":"/docs/integrations/stores/upstash_redis","className":"hidden","docId":"integrations/stores/upstash_redis","unlisted":false}],"collapsed":false,"href":"/docs/integrations/stores/"},{"type":"category","label":"Document transformers","collapsible":false,"items":[{"type":"link","label":"AI21SemanticTextSplitter","href":"/docs/integrations/document_transformers/ai21_semantic_text_splitter","className":"hidden","docId":"integrations/document_transformers/ai21_semantic_text_splitter","unlisted":false},{"type":"link","label":"Beautiful Soup","href":"/docs/integrations/document_transformers/beautiful_soup","className":"hidden","docId":"integrations/document_transformers/beautiful_soup","unlisted":false},{"type":"link","label":"Cross Encoder Reranker","href":"/docs/integrations/document_transformers/cross_encoder_reranker","className":"hidden","docId":"integrations/document_transformers/cross_encoder_reranker","unlisted":false},{"type":"link","label":"DashScope Reranker","href":"/docs/integrations/document_transformers/dashscope_rerank","className":"hidden","docId":"integrations/document_transformers/dashscope_rerank","unlisted":false},{"type":"link","label":"Doctran: extract properties","href":"/docs/integrations/document_transformers/doctran_extract_properties","className":"hidden","docId":"integrations/document_transformers/doctran_extract_properties","unlisted":false},{"type":"link","label":"Doctran: interrogate documents","href":"/docs/integrations/document_transformers/doctran_interrogate_document","className":"hidden","docId":"integrations/document_transformers/doctran_interrogate_document","unlisted":false},{"type":"link","label":"Doctran: language translation","href":"/docs/integrations/document_transformers/doctran_translate_document","className":"hidden","docId":"integrations/document_transformers/doctran_translate_document","unlisted":false},{"type":"link","label":"Google Cloud Vertex AI Reranker","href":"/docs/integrations/document_transformers/google_cloud_vertexai_rerank","className":"hidden","docId":"integrations/document_transformers/google_cloud_vertexai_rerank","unlisted":false},{"type":"link","label":"Google Cloud Document AI","href":"/docs/integrations/document_transformers/google_docai","className":"hidden","docId":"integrations/document_transformers/google_docai","unlisted":false},{"type":"link","label":"Google Translate","href":"/docs/integrations/document_transformers/google_translate","className":"hidden","docId":"integrations/document_transformers/google_translate","unlisted":false},{"type":"link","label":"HTML to text","href":"/docs/integrations/document_transformers/html2text","className":"hidden","docId":"integrations/document_transformers/html2text","unlisted":false},{"type":"link","label":"Infinity Reranker","href":"/docs/integrations/document_transformers/infinity_rerank","className":"hidden","docId":"integrations/document_transformers/infinity_rerank","unlisted":false},{"type":"link","label":"Jina Reranker","href":"/docs/integrations/document_transformers/jina_rerank","className":"hidden","docId":"integrations/document_transformers/jina_rerank","unlisted":false},{"type":"link","label":"Markdownify","href":"/docs/integrations/document_transformers/markdownify","className":"hidden","docId":"integrations/document_transformers/markdownify","unlisted":false},{"type":"link","label":"Nuclia","href":"/docs/integrations/document_transformers/nuclia_transformer","className":"hidden","docId":"integrations/document_transformers/nuclia_transformer","unlisted":false},{"type":"link","label":"OpenAI metadata tagger","href":"/docs/integrations/document_transformers/openai_metadata_tagger","className":"hidden","docId":"integrations/document_transformers/openai_metadata_tagger","unlisted":false},{"type":"link","label":"OpenVINO Reranker","href":"/docs/integrations/document_transformers/openvino_rerank","className":"hidden","docId":"integrations/document_transformers/openvino_rerank","unlisted":false},{"type":"link","label":"RankLLM Reranker","href":"/docs/integrations/document_transformers/rankllm-reranker","className":"hidden","docId":"integrations/document_transformers/rankllm-reranker","unlisted":false},{"type":"link","label":"Volcengine Reranker","href":"/docs/integrations/document_transformers/volcengine_rerank","className":"hidden","docId":"integrations/document_transformers/volcengine_rerank","unlisted":false},{"type":"link","label":"VoyageAI Reranker","href":"/docs/integrations/document_transformers/voyageai-reranker","className":"hidden","docId":"integrations/document_transformers/voyageai-reranker","unlisted":false}],"collapsed":false,"href":"/docs/integrations/document_transformers"},{"type":"link","label":"Model caches","href":"/docs/integrations/llm_caching","docId":"integrations/llm_caching","unlisted":false},{"type":"category","label":"Graphs","collapsible":false,"items":[{"type":"link","label":"Amazon Neptune with Cypher","href":"/docs/integrations/graphs/amazon_neptune_open_cypher","className":"hidden","docId":"integrations/graphs/amazon_neptune_open_cypher","unlisted":false},{"type":"link","label":"Amazon Neptune with SPARQL","href":"/docs/integrations/graphs/amazon_neptune_sparql","className":"hidden","docId":"integrations/graphs/amazon_neptune_sparql","unlisted":false},{"type":"link","label":"Apache AGE","href":"/docs/integrations/graphs/apache_age","className":"hidden","docId":"integrations/graphs/apache_age","unlisted":false},{"type":"link","label":"ArangoDB","href":"/docs/integrations/graphs/arangodb","className":"hidden","docId":"integrations/graphs/arangodb","unlisted":false},{"type":"link","label":"Azure Cosmos DB for Apache Gremlin","href":"/docs/integrations/graphs/azure_cosmosdb_gremlin","className":"hidden","docId":"integrations/graphs/azure_cosmosdb_gremlin","unlisted":false},{"type":"link","label":"Diffbot","href":"/docs/integrations/graphs/diffbot","className":"hidden","docId":"integrations/graphs/diffbot","unlisted":false},{"type":"link","label":"FalkorDB","href":"/docs/integrations/graphs/falkordb","className":"hidden","docId":"integrations/graphs/falkordb","unlisted":false},{"type":"link","label":"HugeGraph","href":"/docs/integrations/graphs/hugegraph","className":"hidden","docId":"integrations/graphs/hugegraph","unlisted":false},{"type":"link","label":"Kuzu","href":"/docs/integrations/graphs/kuzu_db","className":"hidden","docId":"integrations/graphs/kuzu_db","unlisted":false},{"type":"link","label":"Memgraph","href":"/docs/integrations/graphs/memgraph","className":"hidden","docId":"integrations/graphs/memgraph","unlisted":false},{"type":"link","label":"NebulaGraph","href":"/docs/integrations/graphs/nebula_graph","className":"hidden","docId":"integrations/graphs/nebula_graph","unlisted":false},{"type":"link","label":"Neo4j","href":"/docs/integrations/graphs/neo4j_cypher","className":"hidden","docId":"integrations/graphs/neo4j_cypher","unlisted":false},{"type":"link","label":"NetworkX","href":"/docs/integrations/graphs/networkx","className":"hidden","docId":"integrations/graphs/networkx","unlisted":false},{"type":"link","label":"Ontotext GraphDB","href":"/docs/integrations/graphs/ontotext","className":"hidden","docId":"integrations/graphs/ontotext","unlisted":false},{"type":"link","label":"RDFLib","href":"/docs/integrations/graphs/rdflib_sparql","className":"hidden","docId":"integrations/graphs/rdflib_sparql","unlisted":false},{"type":"link","label":"TigerGraph","href":"/docs/integrations/graphs/tigergraph","className":"hidden","docId":"integrations/graphs/tigergraph","unlisted":false}],"collapsed":false,"href":"/docs/integrations/graphs"},{"type":"category","label":"Message histories","collapsible":false,"items":[{"type":"link","label":"Astra DB","href":"/docs/integrations/memory/astradb_chat_message_history","className":"hidden","docId":"integrations/memory/astradb_chat_message_history","unlisted":false},{"type":"link","label":"AWS DynamoDB","href":"/docs/integrations/memory/aws_dynamodb","className":"hidden","docId":"integrations/memory/aws_dynamodb","unlisted":false},{"type":"link","label":"Cassandra","href":"/docs/integrations/memory/cassandra_chat_message_history","className":"hidden","docId":"integrations/memory/cassandra_chat_message_history","unlisted":false},{"type":"link","label":"Couchbase","href":"/docs/integrations/memory/couchbase_chat_message_history","className":"hidden","docId":"integrations/memory/couchbase_chat_message_history","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/memory/elasticsearch_chat_message_history","className":"hidden","docId":"integrations/memory/elasticsearch_chat_message_history","unlisted":false},{"type":"link","label":"FalkorDB","href":"/docs/integrations/memory/falkordb_chat_message_history","className":"hidden","docId":"integrations/memory/falkordb_chat_message_history","unlisted":false},{"type":"link","label":"Google AlloyDB for PostgreSQL","href":"/docs/integrations/memory/google_alloydb","className":"hidden","docId":"integrations/memory/google_alloydb","unlisted":false},{"type":"link","label":"Google Bigtable","href":"/docs/integrations/memory/google_bigtable","className":"hidden","docId":"integrations/memory/google_bigtable","unlisted":false},{"type":"link","label":"Google El Carro Oracle","href":"/docs/integrations/memory/google_el_carro","className":"hidden","docId":"integrations/memory/google_el_carro","unlisted":false},{"type":"link","label":"Google Firestore (Native Mode)","href":"/docs/integrations/memory/google_firestore","className":"hidden","docId":"integrations/memory/google_firestore","unlisted":false},{"type":"link","label":"Google Firestore (Datastore Mode)","href":"/docs/integrations/memory/google_firestore_datastore","className":"hidden","docId":"integrations/memory/google_firestore_datastore","unlisted":false},{"type":"link","label":"Google Memorystore for Redis","href":"/docs/integrations/memory/google_memorystore_redis","className":"hidden","docId":"integrations/memory/google_memorystore_redis","unlisted":false},{"type":"link","label":"Google Spanner","href":"/docs/integrations/memory/google_spanner","className":"hidden","docId":"integrations/memory/google_spanner","unlisted":false},{"type":"link","label":"Google SQL for SQL Server","href":"/docs/integrations/memory/google_sql_mssql","className":"hidden","docId":"integrations/memory/google_sql_mssql","unlisted":false},{"type":"link","label":"Google SQL for MySQL","href":"/docs/integrations/memory/google_sql_mysql","className":"hidden","docId":"integrations/memory/google_sql_mysql","unlisted":false},{"type":"link","label":"Google SQL for PostgreSQL","href":"/docs/integrations/memory/google_sql_pg","className":"hidden","docId":"integrations/memory/google_sql_pg","unlisted":false},{"type":"link","label":"Kafka","href":"/docs/integrations/memory/kafka_chat_message_history","className":"hidden","docId":"integrations/memory/kafka_chat_message_history","unlisted":false},{"type":"link","label":"Momento Cache","href":"/docs/integrations/memory/momento_chat_message_history","className":"hidden","docId":"integrations/memory/momento_chat_message_history","unlisted":false},{"type":"link","label":"MongoDB","href":"/docs/integrations/memory/mongodb_chat_message_history","className":"hidden","docId":"integrations/memory/mongodb_chat_message_history","unlisted":false},{"type":"link","label":"Mot\xf6rhead","href":"/docs/integrations/memory/motorhead_memory","className":"hidden","docId":"integrations/memory/motorhead_memory","unlisted":false},{"type":"link","label":"Neo4j","href":"/docs/integrations/memory/neo4j_chat_message_history","className":"hidden","docId":"integrations/memory/neo4j_chat_message_history","unlisted":false},{"type":"link","label":"Postgres","href":"/docs/integrations/memory/postgres_chat_message_history","className":"hidden","docId":"integrations/memory/postgres_chat_message_history","unlisted":false},{"type":"link","label":"Redis Chat Message History","href":"/docs/integrations/memory/redis_chat_message_history","className":"hidden","docId":"integrations/memory/redis_chat_message_history","unlisted":false},{"type":"link","label":"Remembrall","href":"/docs/integrations/memory/remembrall","className":"hidden","docId":"integrations/memory/remembrall","unlisted":false},{"type":"link","label":"Rockset","href":"/docs/integrations/memory/rockset_chat_message_history","className":"hidden","docId":"integrations/memory/rockset_chat_message_history","unlisted":false},{"type":"link","label":"SingleStoreDB","href":"/docs/integrations/memory/singlestoredb_chat_message_history","className":"hidden","docId":"integrations/memory/singlestoredb_chat_message_history","unlisted":false},{"type":"link","label":"SQL (SQLAlchemy)","href":"/docs/integrations/memory/sql_chat_message_history","className":"hidden","docId":"integrations/memory/sql_chat_message_history","unlisted":false},{"type":"link","label":"SQLite","href":"/docs/integrations/memory/sqlite","className":"hidden","docId":"integrations/memory/sqlite","unlisted":false},{"type":"link","label":"Streamlit","href":"/docs/integrations/memory/streamlit_chat_message_history","className":"hidden","docId":"integrations/memory/streamlit_chat_message_history","unlisted":false},{"type":"link","label":"TiDB","href":"/docs/integrations/memory/tidb_chat_message_history","className":"hidden","docId":"integrations/memory/tidb_chat_message_history","unlisted":false},{"type":"link","label":"Upstash Redis","href":"/docs/integrations/memory/upstash_redis_chat_message_history","className":"hidden","docId":"integrations/memory/upstash_redis_chat_message_history","unlisted":false},{"type":"link","label":"Xata","href":"/docs/integrations/memory/xata_chat_message_history","className":"hidden","docId":"integrations/memory/xata_chat_message_history","unlisted":false},{"type":"link","label":"ZepCloudChatMessageHistory","href":"/docs/integrations/memory/zep_cloud_chat_message_history","className":"hidden","docId":"integrations/memory/zep_cloud_chat_message_history","unlisted":false},{"type":"link","label":"Zep Open Source Memory","href":"/docs/integrations/memory/zep_memory","className":"hidden","docId":"integrations/memory/zep_memory","unlisted":false},{"type":"link","label":"Zep Cloud Memory","href":"/docs/integrations/memory/zep_memory_cloud","className":"hidden","docId":"integrations/memory/zep_memory_cloud","unlisted":false}],"collapsed":false,"href":"/docs/integrations/memory"},{"type":"category","label":"Callbacks","collapsible":false,"items":[{"type":"link","label":"Argilla","href":"/docs/integrations/callbacks/argilla","className":"hidden","docId":"integrations/callbacks/argilla","unlisted":false},{"type":"link","label":"Comet Tracing","href":"/docs/integrations/callbacks/comet_tracing","className":"hidden","docId":"integrations/callbacks/comet_tracing","unlisted":false},{"type":"link","label":"Confident","href":"/docs/integrations/callbacks/confident","className":"hidden","docId":"integrations/callbacks/confident","unlisted":false},{"type":"link","label":"Context","href":"/docs/integrations/callbacks/context","className":"hidden","docId":"integrations/callbacks/context","unlisted":false},{"type":"link","label":"Fiddler","href":"/docs/integrations/callbacks/fiddler","className":"hidden","docId":"integrations/callbacks/fiddler","unlisted":false},{"type":"link","label":"Infino","href":"/docs/integrations/callbacks/infino","className":"hidden","docId":"integrations/callbacks/infino","unlisted":false},{"type":"link","label":"Label Studio","href":"/docs/integrations/callbacks/labelstudio","className":"hidden","docId":"integrations/callbacks/labelstudio","unlisted":false},{"type":"link","label":"LLMonitor","href":"/docs/integrations/callbacks/llmonitor","className":"hidden","docId":"integrations/callbacks/llmonitor","unlisted":false},{"type":"link","label":"PromptLayer","href":"/docs/integrations/callbacks/promptlayer","className":"hidden","docId":"integrations/callbacks/promptlayer","unlisted":false},{"type":"link","label":"SageMaker Tracking","href":"/docs/integrations/callbacks/sagemaker_tracking","className":"hidden","docId":"integrations/callbacks/sagemaker_tracking","unlisted":false},{"type":"link","label":"Streamlit","href":"/docs/integrations/callbacks/streamlit","className":"hidden","docId":"integrations/callbacks/streamlit","unlisted":false},{"type":"link","label":"Trubrics","href":"/docs/integrations/callbacks/trubrics","className":"hidden","docId":"integrations/callbacks/trubrics","unlisted":false},{"type":"link","label":"Upstash Ratelimit Callback","href":"/docs/integrations/callbacks/upstash_ratelimit","className":"hidden","docId":"integrations/callbacks/upstash_ratelimit","unlisted":false},{"type":"link","label":"uptrain","href":"/docs/integrations/callbacks/uptrain","className":"hidden","docId":"integrations/callbacks/uptrain","unlisted":false}],"collapsed":false,"href":"/docs/integrations/callbacks"},{"type":"category","label":"Chat loaders","collapsible":false,"items":[{"type":"link","label":"Discord","href":"/docs/integrations/chat_loaders/discord","className":"hidden","docId":"integrations/chat_loaders/discord","unlisted":false},{"type":"link","label":"Facebook Messenger","href":"/docs/integrations/chat_loaders/facebook","className":"hidden","docId":"integrations/chat_loaders/facebook","unlisted":false},{"type":"link","label":"GMail","href":"/docs/integrations/chat_loaders/gmail","className":"hidden","docId":"integrations/chat_loaders/gmail","unlisted":false},{"type":"link","label":"iMessage","href":"/docs/integrations/chat_loaders/imessage","className":"hidden","docId":"integrations/chat_loaders/imessage","unlisted":false},{"type":"link","label":"LangSmith Chat Datasets","href":"/docs/integrations/chat_loaders/langsmith_dataset","className":"hidden","docId":"integrations/chat_loaders/langsmith_dataset","unlisted":false},{"type":"link","label":"LangSmith LLM Runs","href":"/docs/integrations/chat_loaders/langsmith_llm_runs","className":"hidden","docId":"integrations/chat_loaders/langsmith_llm_runs","unlisted":false},{"type":"link","label":"Slack","href":"/docs/integrations/chat_loaders/slack","className":"hidden","docId":"integrations/chat_loaders/slack","unlisted":false},{"type":"link","label":"Telegram","href":"/docs/integrations/chat_loaders/telegram","className":"hidden","docId":"integrations/chat_loaders/telegram","unlisted":false},{"type":"link","label":"Twitter (via Apify)","href":"/docs/integrations/chat_loaders/twitter","className":"hidden","docId":"integrations/chat_loaders/twitter","unlisted":false},{"type":"link","label":"WeChat","href":"/docs/integrations/chat_loaders/wechat","className":"hidden","docId":"integrations/chat_loaders/wechat","unlisted":false},{"type":"link","label":"WhatsApp","href":"/docs/integrations/chat_loaders/whatsapp","className":"hidden","docId":"integrations/chat_loaders/whatsapp","unlisted":false}],"collapsed":false,"href":"/docs/integrations/chat_loaders"},{"type":"category","label":"Adapters","collapsible":false,"items":[{"type":"link","label":"OpenAI Adapter(Old)","href":"/docs/integrations/adapters/openai-old","className":"hidden","docId":"integrations/adapters/openai-old","unlisted":false},{"type":"link","label":"OpenAI Adapter","href":"/docs/integrations/adapters/openai","className":"hidden","docId":"integrations/adapters/openai","unlisted":false}],"collapsed":false,"href":"/docs/integrations/adapters"}],"collapsible":true}],"collapsed":false,"href":"/docs/integrations/components"}],"contributing":[{"type":"link","label":"Welcome Contributors","href":"/docs/contributing/","docId":"contributing/index","unlisted":false},{"type":"category","label":"Tutorials","collapsible":false,"items":[{"type":"link","label":"Make your first docs PR","href":"/docs/contributing/tutorials/docs","className":"hidden","docId":"contributing/tutorials/docs","unlisted":false},{"type":"link","label":"Tutorials","href":"/docs/contributing/tutorials/","className":"hidden","docId":"contributing/tutorials/index","unlisted":false}],"collapsed":false,"href":"/docs/contributing/tutorials/"},{"type":"category","label":"How-to guides","collapsible":false,"items":[{"type":"link","label":"Testing","href":"/docs/contributing/how_to/testing","className":"hidden","docId":"contributing/how_to/testing","unlisted":false},{"type":"category","label":"Contribute Code","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"General guidelines","href":"/docs/contributing/how_to/code/guidelines","docId":"contributing/how_to/code/guidelines","unlisted":false},{"type":"link","label":"Setup","href":"/docs/contributing/how_to/code/setup","docId":"contributing/how_to/code/setup","unlisted":false}],"className":"hidden","href":"/docs/contributing/how_to/code/"},{"type":"category","label":"Contribute Documentation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Setup","href":"/docs/contributing/how_to/documentation/setup","className":"hidden","docId":"contributing/how_to/documentation/setup","unlisted":false},{"type":"link","label":"Documentation Style Guide","href":"/docs/contributing/how_to/documentation/style_guide","className":"hidden","docId":"contributing/how_to/documentation/style_guide","unlisted":false}],"className":"hidden","href":"/docs/contributing/how_to/documentation/"},{"type":"link","label":"How-to Guides","href":"/docs/contributing/how_to/","className":"hidden","docId":"contributing/how_to/index","unlisted":false},{"type":"category","label":"Contribute Integrations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"community","href":"/docs/contributing/how_to/integrations/community","docId":"contributing/how_to/integrations/community","unlisted":false},{"type":"link","label":"How to publish an integration package from a template","href":"/docs/contributing/how_to/integrations/from_template","docId":"contributing/how_to/integrations/from_template","unlisted":false},{"type":"link","label":"How to implement an integration package","href":"/docs/contributing/how_to/integrations/package","docId":"contributing/how_to/integrations/package","unlisted":false},{"type":"link","label":"Publishing your package","href":"/docs/contributing/how_to/integrations/publish","docId":"contributing/how_to/integrations/publish","unlisted":false},{"type":"link","label":"How to add standard tests to an integration","href":"/docs/contributing/how_to/integrations/standard_tests","docId":"contributing/how_to/integrations/standard_tests","unlisted":false}],"className":"hidden","href":"/docs/contributing/how_to/integrations/"}],"collapsed":false,"href":"/docs/contributing/how_to/"},{"type":"category","label":"Reference & FAQ","collapsible":false,"items":[{"type":"link","label":"Repository Structure","href":"/docs/contributing/reference/repo_structure","className":"hidden","docId":"contributing/reference/repo_structure","unlisted":false},{"type":"link","label":"FAQ","href":"/docs/contributing/reference/faq","className":"hidden","docId":"contributing/reference/faq","unlisted":false},{"type":"link","label":"Reference","href":"/docs/contributing/reference/","className":"hidden","docId":"contributing/reference/index","unlisted":false},{"type":"link","label":"Review Process","href":"/docs/contributing/reference/review_process","className":"hidden","docId":"contributing/reference/review_process","unlisted":false}],"collapsed":false,"href":"/docs/contributing/reference/"}]},"docs":{"additional_resources/arxiv_references":{"id":"additional_resources/arxiv_references","title":"arXiv","description":"LangChain implements the latest research in the field of Natural Language Processing."},"additional_resources/dependents":{"id":"additional_resources/dependents","title":"Dependents","description":"Dependents stats for langchain-ai/langchain"},"additional_resources/tutorials":{"id":"additional_resources/tutorials","title":"3rd Party Tutorials","description":"Tutorials"},"additional_resources/youtube":{"id":"additional_resources/youtube","title":"YouTube videos","description":"[Updated 2024-05-16]"},"changes/changelog/core":{"id":"changes/changelog/core","title":"langchain-core","description":"0.1.x"},"changes/changelog/langchain":{"id":"changes/changelog/langchain","title":"langchain","description":"0.2.0"},"concepts/agents":{"id":"concepts/agents","title":"Agents","description":"By themselves, language models can\'t take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.","sidebar":"docs"},"concepts/architecture":{"id":"concepts/architecture","title":"Architecture","description":"LangChain is a framework that consists of a number of packages.","sidebar":"docs"},"concepts/async":{"id":"concepts/async","title":"Async programming with langchain","description":"* Runnable interface","sidebar":"docs"},"concepts/callbacks":{"id":"concepts/callbacks","title":"Callbacks","description":"- Runnable interface","sidebar":"docs"},"concepts/chat_history":{"id":"concepts/chat_history","title":"Chat history","description":"- Messages","sidebar":"docs"},"concepts/chat_models":{"id":"concepts/chat_models","title":"Chat models","description":"Overview","sidebar":"docs"},"concepts/document_loaders":{"id":"concepts/document_loaders","title":"Document loaders","description":"* Document loaders API reference","sidebar":"docs"},"concepts/embedding_models":{"id":"concepts/embedding_models","title":"Embedding models","description":"* Documents","sidebar":"docs"},"concepts/evaluation":{"id":"concepts/evaluation","title":"Evaluation","description":"Evaluation is the process of assessing the performance and effectiveness of your LLM-powered applications.","sidebar":"docs"},"concepts/example_selectors":{"id":"concepts/example_selectors","title":"Example selectors","description":"- Chat models","sidebar":"docs"},"concepts/few_shot_prompting":{"id":"concepts/few_shot_prompting","title":"Few-shot prompting","description":"- Chat models","sidebar":"docs"},"concepts/index":{"id":"concepts/index","title":"Conceptual guide","description":"This guide provides explanations of the key concepts behind the LangChain framework and AI applications more broadly.","sidebar":"docs"},"concepts/key_value_stores":{"id":"concepts/key_value_stores","title":"Key-value stores","description":"Overview","sidebar":"docs"},"concepts/lcel":{"id":"concepts/lcel","title":"LangChain Expression Language (LCEL)","description":"* Runnable Interface","sidebar":"docs"},"concepts/messages":{"id":"concepts/messages","title":"Messages","description":"- Chat Models","sidebar":"docs"},"concepts/multimodality":{"id":"concepts/multimodality","title":"Multimodality","description":"Overview","sidebar":"docs"},"concepts/output_parsers":{"id":"concepts/output_parsers","title":"Output parsers","description":"The information here refers to parsers that take a text output from a model try to parse it into a more structured representation.","sidebar":"docs"},"concepts/prompt_templates":{"id":"concepts/prompt_templates","title":"Prompt Templates","description":"Prompt templates help to translate user input and parameters into instructions for a language model.","sidebar":"docs"},"concepts/rag":{"id":"concepts/rag","title":"Retrieval augmented generation (RAG)","description":"* Retrieval","sidebar":"docs"},"concepts/retrieval":{"id":"concepts/retrieval","title":"Retrieval","description":"* Retrievers","sidebar":"docs"},"concepts/retrievers":{"id":"concepts/retrievers","title":"Retrievers","description":"* Vector stores","sidebar":"docs"},"concepts/runnables":{"id":"concepts/runnables","title":"Runnable interface","description":"The Runnable interface is the foundation for working with LangChain components, and it\'s implemented across many of them, such as language models, output parsers, retrievers, [compiled LangGraph graphs](","sidebar":"docs"},"concepts/streaming":{"id":"concepts/streaming","title":"Streaming","description":"* Runnable Interface","sidebar":"docs"},"concepts/structured_outputs":{"id":"concepts/structured_outputs","title":"Structured outputs","description":"Overview","sidebar":"docs"},"concepts/testing":{"id":"concepts/testing","title":"Testing","description":"Testing is a critical part of the development process that ensures your code works as expected and meets the desired quality standards.","sidebar":"docs"},"concepts/text_llms":{"id":"concepts/text_llms","title":"String-in, string-out llms","description":"You are probably looking for the Chat Model Concept Guide page for more information.","sidebar":"docs"},"concepts/text_splitters":{"id":"concepts/text_splitters","title":"Text splitters","description":"* Documents","sidebar":"docs"},"concepts/tokens":{"id":"concepts/tokens","title":"Tokens","description":"Modern large language models (LLMs) are typically based on a transformer architecture that processes a sequence of units known as tokens. Tokens are the fundamental elements that models use to break down input and generate output. In this section, we\'ll discuss what tokens are and how they are used by language models.","sidebar":"docs"},"concepts/tool_calling":{"id":"concepts/tool_calling","title":"Tool calling","description":"* Tools","sidebar":"docs"},"concepts/tools":{"id":"concepts/tools","title":"Tools","description":"- Chat models","sidebar":"docs"},"concepts/tracing":{"id":"concepts/tracing","title":"Tracing","description":"A trace is essentially a series of steps that your application takes to go from input to output.","sidebar":"docs"},"concepts/vectorstores":{"id":"concepts/vectorstores","title":"Vector stores","description":"* Embeddings","sidebar":"docs"},"concepts/why_langchain":{"id":"concepts/why_langchain","title":"Why LangChain?","description":"The goal of langchain the Python package and LangChain the company is to make it as easy as possible for developers to build applications that reason.","sidebar":"docs"},"contributing/how_to/code/guidelines":{"id":"contributing/how_to/code/guidelines","title":"General guidelines","description":"Here are some things to keep in mind for all types of contributions:","sidebar":"contributing"},"contributing/how_to/code/index":{"id":"contributing/how_to/code/index","title":"Contribute Code","description":"If you would like to add a new feature or update an existing one, please read the resources below before getting started:","sidebar":"contributing"},"contributing/how_to/code/setup":{"id":"contributing/how_to/code/setup","title":"Setup","description":"This guide walks through how to run the repository locally and check in your first code.","sidebar":"contributing"},"contributing/how_to/documentation/index":{"id":"contributing/how_to/documentation/index","title":"Contribute Documentation","description":"Documentation is a vital part of LangChain. We welcome both new documentation for new features and","sidebar":"contributing"},"contributing/how_to/documentation/setup":{"id":"contributing/how_to/documentation/setup","title":"Setup","description":"LangChain documentation consists of two components:","sidebar":"contributing"},"contributing/how_to/documentation/style_guide":{"id":"contributing/how_to/documentation/style_guide","title":"Documentation Style Guide","description":"As LangChain continues to grow, the amount of documentation required to cover the various concepts and integrations continues to grow too.","sidebar":"contributing"},"contributing/how_to/index":{"id":"contributing/how_to/index","title":"How-to Guides","description":"- Documentation: Help improve our docs, including this one!","sidebar":"contributing"},"contributing/how_to/integrations/community":{"id":"contributing/how_to/integrations/community","title":"community","description":"How to add a community integration (not recommended)","sidebar":"contributing"},"contributing/how_to/integrations/from_template":{"id":"contributing/how_to/integrations/from_template","title":"How to publish an integration package from a template","description":"This guide is a work-in-progress.","sidebar":"contributing"},"contributing/how_to/integrations/index":{"id":"contributing/how_to/integrations/index","title":"Contribute Integrations","description":"Integrations are a core component of LangChain.","sidebar":"contributing"},"contributing/how_to/integrations/package":{"id":"contributing/how_to/integrations/package","title":"How to implement an integration package","description":"This guide walks through the process of implementing a LangChain integration","sidebar":"contributing"},"contributing/how_to/integrations/publish":{"id":"contributing/how_to/integrations/publish","title":"Publishing your package","description":"Now that your package is implemented and tested, you can:","sidebar":"contributing"},"contributing/how_to/integrations/standard_tests":{"id":"contributing/how_to/integrations/standard_tests","title":"How to add standard tests to an integration","description":"When creating either a custom class for yourself or to publish in a LangChain integration, it is important to add standard tests to ensure it works as expected. This guide will show you how to add standard tests to each integration type.","sidebar":"contributing"},"contributing/how_to/testing":{"id":"contributing/how_to/testing","title":"Testing","description":"All of our packages have unit tests and integration tests, and we favor unit tests over integration tests.","sidebar":"contributing"},"contributing/index":{"id":"contributing/index","title":"Welcome Contributors","description":"Hi there! Thank you for your interest in contributing to LangChain.","sidebar":"contributing"},"contributing/reference/faq":{"id":"contributing/reference/faq","title":"Frequently Asked Questions","description":"Pull Requests (PRs)","sidebar":"contributing"},"contributing/reference/index":{"id":"contributing/reference/index","title":"Reference","description":"- Repository Structure: Understand the high level structure of the repository.","sidebar":"contributing"},"contributing/reference/repo_structure":{"id":"contributing/reference/repo_structure","title":"Repository Structure","description":"If you plan on contributing to LangChain code or documentation, it can be useful","sidebar":"contributing"},"contributing/reference/review_process":{"id":"contributing/reference/review_process","title":"Review Process","description":"Overview","sidebar":"contributing"},"contributing/tutorials/docs":{"id":"contributing/tutorials/docs","title":"Make your first docs PR","description":"This tutorial will guide you through making a simple documentation edit, like correcting a typo.","sidebar":"contributing"},"contributing/tutorials/index":{"id":"contributing/tutorials/index","title":"Tutorials","description":"More coming soon! We are working on tutorials to help you make your first contribution to the project.","sidebar":"contributing"},"how_to/add_scores_retriever":{"id":"how_to/add_scores_retriever","title":"How to add scores to retriever results","description":"Retrievers will return sequences of Document objects, which by default include no information about the process that retrieved them (e.g., a similarity score against a query). Here we demonstrate how to add retrieval scores to the .metadata of documents:","sidebar":"docs"},"how_to/agent_executor":{"id":"how_to/agent_executor","title":"Build an Agent with AgentExecutor (Legacy)","description":"This section will cover building with the legacy LangChain AgentExecutor. These are fine for getting started, but past a certain point, you will likely want flexibility and control that they do not offer. For working with more advanced agents, we\'d recommend checking out LangGraph Agents or the migration guide","sidebar":"docs"},"how_to/assign":{"id":"how_to/assign","title":"How to add values to a chain\'s state","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/binding":{"id":"how_to/binding","title":"How to add default invocation args to a Runnable","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/caching_embeddings":{"id":"how_to/caching_embeddings","title":"Caching","description":"Embeddings can be stored or temporarily cached to avoid needing to recompute them.","sidebar":"docs"},"how_to/callbacks_async":{"id":"how_to/callbacks_async","title":"How to use callbacks in async environments","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/callbacks_attach":{"id":"how_to/callbacks_attach","title":"How to attach callbacks to a runnable","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/callbacks_constructor":{"id":"how_to/callbacks_constructor","title":"How to propagate callbacks  constructor","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/callbacks_custom_events":{"id":"how_to/callbacks_custom_events","title":"How to dispatch custom callback events","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/callbacks_runtime":{"id":"how_to/callbacks_runtime","title":"How to pass callbacks in at runtime","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/character_text_splitter":{"id":"how_to/character_text_splitter","title":"How to split by character","description":"This is the simplest method. This splits based on a given character sequence, which defaults to \\"\\\\n\\\\n\\". Chunk length is measured by number of characters.","sidebar":"docs"},"how_to/chat_model_caching":{"id":"how_to/chat_model_caching","title":"How to cache chat model responses","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/chat_model_rate_limiting":{"id":"how_to/chat_model_rate_limiting","title":"How to handle rate limits","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/chat_models_universal_init":{"id":"how_to/chat_models_universal_init","title":"How to init any model in one line","description":"Many LLM applications let end users specify what model provider and model they want the application to be powered by. This requires writing some logic to initialize different chat models based on some user configuration. The initchat_model() helper method makes it easy to initialize a number of different model integrations without having to worry about import paths and class names.","sidebar":"docs"},"how_to/chat_streaming":{"id":"how_to/chat_streaming","title":"How to stream chat model responses","description":"All chat models implement the Runnable interface, which comes with a default implementations of standard runnable methods (i.e. ainvoke, batch, abatch, stream, astream, astream_events).","sidebar":"docs"},"how_to/chat_token_usage_tracking":{"id":"how_to/chat_token_usage_tracking","title":"How to track token usage in ChatModels","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/chatbots_memory":{"id":"how_to/chatbots_memory","title":"How to add memory to chatbots","description":"A key feature of chatbots is their ability to use the content of previous conversational turns as context. This state management can take several forms, including:","sidebar":"docs"},"how_to/chatbots_retrieval":{"id":"how_to/chatbots_retrieval","title":"How to add retrieval to chatbots","description":"Retrieval is a common technique chatbots use to augment their responses with data outside a chat model\'s training data. This section will cover how to implement retrieval in the context of chatbots, but it\'s worth noting that retrieval is a very subtle and deep topic - we encourage you to explore other parts of the documentation that go into greater depth!","sidebar":"docs"},"how_to/chatbots_tools":{"id":"how_to/chatbots_tools","title":"How to add tools to chatbots","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/code_splitter":{"id":"how_to/code_splitter","title":"How to split code","description":"RecursiveCharacterTextSplitter includes pre-built lists of separators that are useful for splitting text in a specific programming language.","sidebar":"docs"},"how_to/configure":{"id":"how_to/configure","title":"How to configure runtime chain internals","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/contextual_compression":{"id":"how_to/contextual_compression","title":"How to do retrieval with contextual compression","description":"One challenge with retrieval is that usually you don\'t know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.","sidebar":"docs"},"how_to/convert_runnable_to_tool":{"id":"how_to/convert_runnable_to_tool","title":"How to convert Runnables to Tools","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/custom_callbacks":{"id":"how_to/custom_callbacks","title":"How to create custom callback handlers","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/custom_chat_model":{"id":"how_to/custom_chat_model","title":"How to create a custom chat model class","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/custom_embeddings":{"id":"how_to/custom_embeddings","title":"Custom Embeddings","description":"LangChain is integrated with many 3rd party embedding models. In this guide we\'ll show you how to create a custom Embedding class, in case a built-in one does not already exist. Embeddings are critical in natural language processing applications as they convert text into a numerical form that algorithms can understand, thereby enabling a wide range of applications such as similarity search, text classification, and clustering.","sidebar":"docs"},"how_to/custom_llm":{"id":"how_to/custom_llm","title":"How to create a custom LLM class","description":"This notebook goes over how to create a custom LLM wrapper, in case you want to use your own LLM or a different wrapper than one that is supported in LangChain.","sidebar":"docs"},"how_to/custom_retriever":{"id":"how_to/custom_retriever","title":"Custom Retriever","description":"Overview","sidebar":"docs"},"how_to/custom_tools":{"id":"how_to/custom_tools","title":"How to create tools","description":"When constructing an agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:","sidebar":"docs"},"how_to/debugging":{"id":"how_to/debugging","title":"How to debug your LLM apps","description":"Like building any type of software, at some point you\'ll need to debug when building with LLMs. A model call will fail, or model output will be misformatted, or there will be some nested model calls and it won\'t be clear where along the way an incorrect output was created.","sidebar":"docs"},"how_to/document_loader_csv":{"id":"how_to/document_loader_csv","title":"How to load CSVs","description":"A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.","sidebar":"docs"},"how_to/document_loader_custom":{"id":"how_to/document_loader_custom","title":"Custom Document Loader","description":"Overview","sidebar":"docs"},"how_to/document_loader_directory":{"id":"how_to/document_loader_directory","title":"How to load documents from a directory","description":"LangChain\'s DirectoryLoader implements functionality for reading files from disk into LangChain Document objects. Here we demonstrate:","sidebar":"docs"},"how_to/document_loader_html":{"id":"how_to/document_loader_html","title":"How to load HTML","description":"The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.","sidebar":"docs"},"how_to/document_loader_json":{"id":"how_to/document_loader_json","title":"How to load JSON","description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute\u2013value pairs and arrays (or other serializable values).","sidebar":"docs"},"how_to/document_loader_markdown":{"id":"how_to/document_loader_markdown","title":"How to load Markdown","description":"Markdown is a lightweight markup language for creating formatted text using a plain-text editor.","sidebar":"docs"},"how_to/document_loader_office_file":{"id":"how_to/document_loader_office_file","title":"How to load Microsoft Office files","description":"The Microsoft Office suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.","sidebar":"docs"},"how_to/document_loader_pdf":{"id":"how_to/document_loader_pdf","title":"How to load PDFs","description":"Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.","sidebar":"docs"},"how_to/document_loader_web":{"id":"how_to/document_loader_web","title":"How to load web pages","description":"This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.","sidebar":"docs"},"how_to/dynamic_chain":{"id":"how_to/dynamic_chain","title":"How to create a dynamic (self-constructing) chain","description":"This guide assumes familiarity with the following:","sidebar":"docs"},"how_to/embed_text":{"id":"how_to/embed_text","title":"Text embedding models","description":"Head to Integrations for documentation on built-in integrations with text embedding model providers.","sidebar":"docs"},"how_to/ensemble_retriever":{"id":"how_to/ensemble_retriever","title":"How to combine results from multiple retrievers","description":"The EnsembleRetriever supports ensembling of results from multiple retrievers. It is initialized with a list of BaseRetriever objects. EnsembleRetrievers rerank the results of the constituent retrievers based on the Reciprocal Rank Fusion algorithm.","sidebar":"docs"},"how_to/example_selectors":{"id":"how_to/example_selectors","title":"How to use example selectors","description":"If you have a large number of examples, you may need to select which ones to include in the prompt. The Example Selector is the class responsible for doing so.","sidebar":"docs"},"how_to/example_selectors_langsmith":{"id":"how_to/example_selectors_langsmith","title":"How to select examples from a LangSmith dataset","description":"<Prerequisites titlesAndLinks={[","sidebar":"docs"},"how_to/example_selectors_length_based":{"id":"how_to/example_selectors_length_based","title":"How to select examples by length","description":"This example selector selects which examples to use based on length. This is useful when you are worried about constructing a prompt that will go over the length of the context window. For longer inputs, it will select fewer examples to include, while for shorter inputs it will select more.","sidebar":"docs"},"how_to/example_selectors_mmr":{"id":"how_to/example_selectors_mmr","title":"How to select examples by maximal marginal relevance (MMR)","description":"The MaxMarginalRelevanceExampleSelector selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.","sidebar":"docs"},"how_to/example_selectors_ngram":{"id":"how_to/example_selectors_ngram","title":"How to select examples by n-gram overlap","description":"The NGramOverlapExampleSelector selects and orders examples based on which examples are most similar to the input, according to an ngram overlap score. The ngram overlap score is a float between 0.0 and 1.0, inclusive.","sidebar":"docs"},"how_to/example_selectors_similarity":{"id":"how_to/example_selectors_similarity","title":"How to select examples by similarity","description":"This object selects examples based on similarity to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs.","sidebar":"docs"},"how_to/extraction_examples":{"id":"how_to/extraction_examples","title":"How to use reference examples when doing extraction","description":"The quality of extractions can often be improved by providing reference examples to the LLM.","sidebar":"docs"},"how_to/extraction_long_text":{"id":"how_to/extraction_long_text","title":"How to handle long text when doing extraction","description":"When working with files, like PDFs, you\'re likely to encounter text that exceeds your language model\'s context window. To process this text, consider these strategies:","sidebar":"docs"},"how_to/extraction_parse":{"id":"how_to/extraction_parse","title":"How to use prompting alone (no tool calling) to do extraction","description":"Tool calling features are not required for generating structured output from LLMs. LLMs that are able to follow prompt instructions well can be tasked with outputting information in a given format.","sidebar":"docs"},"how_to/fallbacks":{"id":"how_to/fallbacks","title":"How to add fallbacks to a runnable","description":"When working with language models, you may often encounter issues from the underlying APIs, whether these be rate limiting or downtime. Therefore, as you go to move your LLM applications into production it becomes more and more important to safeguard against these. That\'s why we\'ve introduced the concept of fallbacks.","sidebar":"docs"},"how_to/few_shot_examples":{"id":"how_to/few_shot_examples","title":"How to use few shot examples","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/few_shot_examples_chat":{"id":"how_to/few_shot_examples_chat","title":"How to use few shot examples in chat models","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/filter_messages":{"id":"how_to/filter_messages","title":"How to filter messages","description":"In more complex chains and agents we might track state with a list of messages. This list can start to accumulate messages from multiple different models, speakers, sub-chains, etc., and we may only want to pass subsets of this full list of messages to each model call in the chain/agent.","sidebar":"docs"},"how_to/function_calling":{"id":"how_to/function_calling","title":"How to do tool/function calling","description":"We use the term tool calling interchangeably with function calling. Although","sidebar":"docs"},"how_to/functions":{"id":"how_to/functions","title":"How to run custom functions","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/graph_constructing":{"id":"how_to/graph_constructing","title":"How to construct knowledge graphs","description":"In this guide we\'ll go over the basic ways of constructing a knowledge graph based on unstructured text. The constructured graph can then be used as knowledge base in a RAG application.","sidebar":"docs"},"how_to/graph_semantic":{"id":"how_to/graph_semantic","title":"How to add a semantic layer over graph database","description":"You can use database queries to retrieve information from a graph database like Neo4j.","sidebar":"docs"},"how_to/hybrid":{"id":"how_to/hybrid","title":"Hybrid Search","description":"The standard search in LangChain is done by vector similarity. However, a number of vector store implementations (Astra DB, ElasticSearch, Neo4J, AzureSearch, Qdrant...) also support more advanced search combining vector similarity search and other search techniques (full-text, BM25, and so on). This is generally referred to as \\"Hybrid\\" search.","sidebar":"docs"},"how_to/index":{"id":"how_to/index","title":"How-to guides","description":"Here you\u2019ll find answers to \u201cHow do I\u2026.?\u201d types of questions.","sidebar":"docs"},"how_to/indexing":{"id":"how_to/indexing","title":"How to use the LangChain indexing API","description":"Here, we will look at a basic indexing workflow using the LangChain indexing API.","sidebar":"docs"},"how_to/inspect":{"id":"how_to/inspect","title":"How to inspect runnables","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/installation":{"id":"how_to/installation","title":"How to install LangChain packages","description":"The LangChain ecosystem is split into different packages, which allow you to choose exactly which pieces of","sidebar":"docs"},"how_to/lcel_cheatsheet":{"id":"how_to/lcel_cheatsheet","title":"LangChain Expression Language Cheatsheet","description":"This is a quick reference for all the most important LCEL primitives. For more advanced usage see the LCEL how-to guides and the full API reference.","sidebar":"docs"},"how_to/llm_caching":{"id":"how_to/llm_caching","title":"How to cache LLM responses","description":"LangChain provides an optional caching layer for LLMs. This is useful for two reasons:","sidebar":"docs"},"how_to/llm_token_usage_tracking":{"id":"how_to/llm_token_usage_tracking","title":"How to track token usage for LLMs","description":"Tracking token usage to calculate cost is an important part of putting your app in production. This guide goes over how to obtain this information from your LangChain model calls.","sidebar":"docs"},"how_to/local_llms":{"id":"how_to/local_llms","title":"Run models locally","description":"Use case","sidebar":"docs"},"how_to/logprobs":{"id":"how_to/logprobs","title":"How to get log probabilities","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/long_context_reorder":{"id":"how_to/long_context_reorder","title":"How to reorder retrieved results to mitigate the \\"lost in the middle\\" effect","description":"Substantial performance degradations in RAG applications have been documented as the number of retrieved documents grows (e.g., beyond ten). In brief: models are liable to miss relevant information in the middle of long contexts.","sidebar":"docs"},"how_to/markdown_header_metadata_splitter":{"id":"how_to/markdown_header_metadata_splitter","title":"How to split Markdown by Headers","description":"Motivation","sidebar":"docs"},"how_to/merge_message_runs":{"id":"how_to/merge_message_runs","title":"How to merge consecutive messages of the same type","description":"Certain models do not support passing in consecutive messages of the same type (a.k.a. \\"runs\\" of the same message type).","sidebar":"docs"},"how_to/message_history":{"id":"how_to/message_history","title":"How to add message history","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/migrate_agent":{"id":"how_to/migrate_agent","title":"How to migrate from legacy LangChain agents to LangGraph","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/multi_vector":{"id":"how_to/multi_vector","title":"How to retrieve using multiple vectors per document","description":"It can often be useful to store multiple vectors per document. There are multiple use cases where this is beneficial. For example, we can embed multiple chunks of a document and associate those embeddings with the parent document, allowing retriever hits on the chunks to return the larger document.","sidebar":"docs"},"how_to/multimodal_inputs":{"id":"how_to/multimodal_inputs","title":"How to pass multimodal data directly to models","description":"Here we demonstrate how to pass multimodal input directly to models.","sidebar":"docs"},"how_to/multimodal_prompts":{"id":"how_to/multimodal_prompts","title":"How to use multimodal prompts","description":"Here we demonstrate how to use prompt templates to format multimodal inputs to models.","sidebar":"docs"},"how_to/MultiQueryRetriever":{"id":"how_to/MultiQueryRetriever","title":"How to use the MultiQueryRetriever","description":"Distance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on a distance metric. But, retrieval may produce different results with subtle changes in query wording, or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.","sidebar":"docs"},"how_to/output_parser_custom":{"id":"how_to/output_parser_custom","title":"How to create a custom Output Parser","description":"In some situations you may want to implement a custom parser to structure the model output into a custom format.","sidebar":"docs"},"how_to/output_parser_fixing":{"id":"how_to/output_parser_fixing","title":"How to use the output-fixing parser","description":"This output parser wraps another output parser, and in the event that the first one fails it calls out to another LLM to fix any errors.","sidebar":"docs"},"how_to/output_parser_json":{"id":"how_to/output_parser_json","title":"How to parse JSON output","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/output_parser_retry":{"id":"how_to/output_parser_retry","title":"How to retry when a parsing error occurs","description":"While in some cases it is possible to fix any parsing mistakes by only looking at the output, in other cases it isn\'t. An example of this is when the output is not just in the incorrect format, but is partially complete. Consider the below example.","sidebar":"docs"},"how_to/output_parser_string":{"id":"how_to/output_parser_string","title":"How to parse text from message objects","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/output_parser_structured":{"id":"how_to/output_parser_structured","title":"How to use output parsers to parse an LLM response into structured format","description":"Language models output text. But there are times where you want to get more structured information than just text back. While some model providers support built-in ways to return structured output, not all do.","sidebar":"docs"},"how_to/output_parser_xml":{"id":"how_to/output_parser_xml","title":"How to parse XML output","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/output_parser_yaml":{"id":"how_to/output_parser_yaml","title":"How to parse YAML output","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/parallel":{"id":"how_to/parallel","title":"How to invoke runnables in parallel","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/parent_document_retriever":{"id":"how_to/parent_document_retriever","title":"How to use the Parent Document Retriever","description":"When splitting documents for retrieval, there are often conflicting desires:","sidebar":"docs"},"how_to/passthrough":{"id":"how_to/passthrough","title":"How to pass through arguments from one step to the next","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/prompts_composition":{"id":"how_to/prompts_composition","title":"How to compose prompts together","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/prompts_partial":{"id":"how_to/prompts_partial","title":"How to partially format prompt templates","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/pydantic_compatibility":{"id":"how_to/pydantic_compatibility","title":"How to use LangChain with different Pydantic versions","description":"As of the 0.3 release, LangChain uses Pydantic 2 internally.","sidebar":"docs"},"how_to/qa_chat_history_how_to":{"id":"how_to/qa_chat_history_how_to","title":"How to add chat history","description":"This guide previously used the RunnableWithMessageHistory abstraction. You can access this version of the documentation in the v0.2 docs.","sidebar":"docs"},"how_to/qa_citations":{"id":"how_to/qa_citations","title":"How to get a RAG application to add citations","description":"This guide reviews methods to get a model to cite which parts of the source documents it referenced in generating its response.","sidebar":"docs"},"how_to/qa_per_user":{"id":"how_to/qa_per_user","title":"How to do per-user retrieval","description":"This guide demonstrates how to configure runtime properties of a retrieval chain. An example application is to limit the documents available to a retriever based on the user.","sidebar":"docs"},"how_to/qa_sources":{"id":"how_to/qa_sources","title":"How to get your RAG application to return sources","description":"Often in Q&A applications it\'s important to show users the sources that were used to generate the answer. The simplest way to do this is for the chain to return the Documents that were retrieved in each generation.","sidebar":"docs"},"how_to/qa_streaming":{"id":"how_to/qa_streaming","title":"How to stream results from your RAG application","description":"This guide explains how to stream results from a RAG application. It covers streaming tokens from the final output as well as intermediate steps of a chain (e.g., from query re-writing).","sidebar":"docs"},"how_to/query_constructing_filters":{"id":"how_to/query_constructing_filters","title":"How to construct filters for query analysis","description":"We may want to do query analysis to extract filters to pass into retrievers. One way we ask the LLM to represent these filters is as a Pydantic model. There is then the issue of converting that Pydantic model into a filter that can be passed into a retriever.","sidebar":"docs"},"how_to/query_few_shot":{"id":"how_to/query_few_shot","title":"How to add examples to the prompt for query analysis","description":"As our query analysis becomes more complex, the LLM may struggle to understand how exactly it should respond in certain scenarios. In order to improve performance here, we can add examples to the prompt to guide the LLM.","sidebar":"docs"},"how_to/query_high_cardinality":{"id":"how_to/query_high_cardinality","title":"How deal with high cardinality categoricals when doing query analysis","description":"You may want to do query analysis to create a filter on a categorical column. One of the difficulties here is that you usually need to specify the EXACT categorical value. The issue is you need to make sure the LLM generates that categorical value exactly. This can be done relatively easy with prompting when there are only a few values that are valid. When there are a high number of valid values then it becomes more difficult, as those values may not fit in the LLM context, or (if they do) there may be too many for the LLM to properly attend to.","sidebar":"docs"},"how_to/query_multiple_queries":{"id":"how_to/query_multiple_queries","title":"How to handle multiple queries when doing query analysis","description":"Sometimes, a query analysis technique may allow for multiple queries to be generated. In these cases, we need to remember to run all queries and then to combine the results. We will show a simple example (using mock data) of how to do that.","sidebar":"docs"},"how_to/query_multiple_retrievers":{"id":"how_to/query_multiple_retrievers","title":"How to handle multiple retrievers when doing query analysis","description":"Sometimes, a query analysis technique may allow for selection of which retriever to use. To use this, you will need to add some logic to select the retriever to do. We will show a simple example (using mock data) of how to do that.","sidebar":"docs"},"how_to/query_no_queries":{"id":"how_to/query_no_queries","title":"How to handle cases where no queries are generated","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","sidebar":"docs"},"how_to/recursive_json_splitter":{"id":"how_to/recursive_json_splitter","title":"How to split JSON data","description":"This json splitter splits json data while allowing control over chunk sizes. It traverses json data depth first and builds smaller json chunks. It attempts to keep nested json objects whole but will split them if needed to keep chunks between a minchunksize and the maxchunk_size.","sidebar":"docs"},"how_to/recursive_text_splitter":{"id":"how_to/recursive_text_splitter","title":"How to recursively split text by characters","description":"This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\\"\\\\n\\\\n\\", \\"\\\\n\\", \\" \\", \\"\\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.","sidebar":"docs"},"how_to/response_metadata":{"id":"how_to/response_metadata","title":"Response metadata","description":"Many model providers include some metadata in their chat generation responses. This metadata can be accessed via the AIMessage.responsemetadata: Dict attribute. Depending on the model provider and model configuration, this can contain information like token counts, logprobs, and more.","sidebar":"docs"},"how_to/routing":{"id":"how_to/routing","title":"How to route between sub-chains","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/runnable_runtime_secrets":{"id":"how_to/runnable_runtime_secrets","title":"How to pass runtime secrets to runnables","description":"We can pass in secrets to our runnables at runtime using the RunnableConfig. Specifically we can pass in secrets with a ` prefix to the configurable` field. This will ensure that these secrets aren\'t traced as part of the invocation:","sidebar":"docs"},"how_to/self_query":{"id":"how_to/self_query","title":"How to do \\"self-querying\\" retrieval","description":"Head to Integrations for documentation on vector stores with built-in support for self-querying.","sidebar":"docs"},"how_to/semantic-chunker":{"id":"how_to/semantic-chunker","title":"How to split text based on semantic similarity","description":"Taken from Greg Kamradt\'s wonderful notebook:","sidebar":"docs"},"how_to/sequence":{"id":"how_to/sequence","title":"How to chain runnables","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/serialization":{"id":"how_to/serialization","title":"How to save and load LangChain objects","description":"LangChain classes implement standard methods for serialization. Serializing LangChain objects using these methods confer some advantages:","sidebar":"docs"},"how_to/split_by_token":{"id":"how_to/split_by_token","title":"How to split text by tokens","description":"Language models have a token limit. You should not exceed the token limit. When you split your text into chunks it is therefore a good idea to count the number of tokens. There are many tokenizers. When you count tokens in your text you should use the same tokenizer as used in the language model.","sidebar":"docs"},"how_to/split_html":{"id":"how_to/split_html","title":"How to split HTML","description":"Splitting HTML documents into manageable chunks is essential for various text processing tasks such as natural language processing, search indexing, and more. In this guide, we will explore three different text splitters provided by LangChain that you can use to split HTML content effectively:","sidebar":"docs"},"how_to/sql_csv":{"id":"how_to/sql_csv","title":"How to do question answering over CSVs","description":"LLMs are great for building question-answering systems over various types of data sources. In this section we\'ll go over how to build Q&A systems over data stored in a CSV file(s). Like working with SQL databases, the key to working with CSV files is to give an LLM access to tools for querying and interacting with the data. The two main ways to do this are to either:","sidebar":"docs"},"how_to/sql_large_db":{"id":"how_to/sql_large_db","title":"How to deal with large databases when doing SQL question-answering","description":"In order to write valid queries against a database, we need to feed the model the table names, table schemas, and feature values for it to query over. When there are many tables, columns, and/or high-cardinality columns, it becomes impossible for us to dump the full information about our database in every prompt. Instead, we must find ways to dynamically insert into the prompt only the most relevant information.","sidebar":"docs"},"how_to/sql_prompting":{"id":"how_to/sql_prompting","title":"How to better prompt when doing SQL question-answering","description":"In this guide we\'ll go over prompting strategies to improve SQL query generation using createsqlquerychain. We\'ll largely focus on methods for getting relevant database-specific information in your prompt.","sidebar":"docs"},"how_to/sql_query_checking":{"id":"how_to/sql_query_checking","title":"How to do query validation as part of SQL question-answering","description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we\'ll go over some strategies for validating our queries and handling invalid queries.","sidebar":"docs"},"how_to/streaming":{"id":"how_to/streaming","title":"How to stream runnables","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/streaming_llm":{"id":"how_to/streaming_llm","title":"How to stream responses from an LLM","description":"All LLMs implement the Runnable interface, which comes with **default** implementations of standard runnable methods (i.e. ainvoke, batch, abatch, stream, astream, astreamevents).","sidebar":"docs"},"how_to/structured_output":{"id":"how_to/structured_output","title":"How to return structured data from a model","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/summarize_map_reduce":{"id":"how_to/summarize_map_reduce","title":"How to summarize text through parallelization","description":"LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially when the amount of text is large compared to the size of the model\'s context window, it can be helpful (or necessary) to break up the summarization task into smaller components.","sidebar":"docs"},"how_to/summarize_refine":{"id":"how_to/summarize_refine","title":"How to summarize text through iterative refinement","description":"LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially when the amount of text is large compared to the size of the model\'s context window, it can be helpful (or necessary) to break up the summarization task into smaller components.","sidebar":"docs"},"how_to/summarize_stuff":{"id":"how_to/summarize_stuff","title":"How to summarize text in a single LLM call","description":"LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially for models with larger context windows, this can be adequately achieved via a single LLM call.","sidebar":"docs"},"how_to/time_weighted_vectorstore":{"id":"how_to/time_weighted_vectorstore","title":"How to use a time-weighted vector store retriever","description":"This retriever uses a combination of semantic similarity and a time decay.","sidebar":"docs"},"how_to/tool_artifacts":{"id":"how_to/tool_artifacts","title":"How to return artifacts from a tool","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tool_calling":{"id":"how_to/tool_calling","title":"How to use chat models to call tools","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tool_calling_parallel":{"id":"how_to/tool_calling_parallel","title":"How to disable parallel tool calling","description":"This API is currently only supported by OpenAI.","sidebar":"docs"},"how_to/tool_choice":{"id":"how_to/tool_choice","title":"How to force models to call a tool","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tool_configure":{"id":"how_to/tool_configure","title":"How to access the RunnableConfig from a tool","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tool_results_pass_to_model":{"id":"how_to/tool_results_pass_to_model","title":"How to pass tool outputs to chat models","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tool_runtime":{"id":"how_to/tool_runtime","title":"How to pass run time values to tools","description":"<Prerequisites titlesAndLinks={[","sidebar":"docs"},"how_to/tool_stream_events":{"id":"how_to/tool_stream_events","title":"How to stream events from a tool","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tool_streaming":{"id":"how_to/tool_streaming","title":"How to stream tool calls","description":"When tools are called in a streaming context,","sidebar":"docs"},"how_to/toolkits":{"id":"how_to/toolkits","title":"How to use toolkits","description":"Toolkits are collections of tools that are designed to be used together for specific tasks. They have convenient loading methods.","sidebar":"docs"},"how_to/tools_as_openai_functions":{"id":"how_to/tools_as_openai_functions","title":"How to convert tools to OpenAI Functions","description":"This notebook goes over how to use LangChain tools as OpenAI functions.","sidebar":"docs"},"how_to/tools_builtin":{"id":"how_to/tools_builtin","title":"How to use built-in tools and toolkits","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tools_chain":{"id":"how_to/tools_chain","title":"How to use tools in a chain","description":"In this guide, we will go over the basic ways to create Chains and Agents that call Tools. Tools can be just about anything \u2014\xa0APIs, functions, databases, etc. Tools allow us to extend the capabilities of a model beyond just outputting text/messages. The key to using models with tools is correctly prompting a model and parsing its response so that it chooses the right tools and provides the right inputs for them.","sidebar":"docs"},"how_to/tools_error":{"id":"how_to/tools_error","title":"How to handle tool errors","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/tools_few_shot":{"id":"how_to/tools_few_shot","title":"How to use few-shot prompting with tool calling","description":"For more complex tool use it\'s very useful to add few-shot examples to the prompt. We can do this by adding AIMessages with ToolCalls and corresponding ToolMessages to our prompt.","sidebar":"docs"},"how_to/tools_human":{"id":"how_to/tools_human","title":"How to add a human-in-the-loop for tools","description":"There are certain tools that we don\'t trust a model to execute on its own. One thing we can do in such situations is require human approval before the tool is invoked.","sidebar":"docs"},"how_to/tools_model_specific":{"id":"how_to/tools_model_specific","title":"How to bind model-specific tools","description":"Providers adopt different conventions for formatting tool schemas.","sidebar":"docs"},"how_to/tools_prompting":{"id":"how_to/tools_prompting","title":"How to add ad-hoc tool calling capability to LLMs and Chat Models","description":"Some models have been fine-tuned for tool calling and provide a dedicated API for tool calling. Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling. Please see the how to use a chat model to call tools guide for more information.","sidebar":"docs"},"how_to/trim_messages":{"id":"how_to/trim_messages","title":"How to trim messages","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"how_to/vectorstore_retriever":{"id":"how_to/vectorstore_retriever","title":"How to use a vectorstore as a retriever","description":"A vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the vector store class to make it conform to the retriever interface.","sidebar":"docs"},"how_to/vectorstores":{"id":"how_to/vectorstores","title":"How to create and query vector stores","description":"Head to Integrations for documentation on built-in integrations with 3rd-party vector stores.","sidebar":"docs"},"integrations/adapters/openai":{"id":"integrations/adapters/openai","title":"OpenAI Adapter","description":"Please ensure OpenAI library is version 1.0.0 or higher; otherwise, refer to the older doc OpenAI Adapter(Old).","sidebar":"integrations"},"integrations/adapters/openai-old":{"id":"integrations/adapters/openai-old","title":"OpenAI Adapter(Old)","description":"Please ensure OpenAI library is less than 1.0.0; otherwise, refer to the newer doc OpenAI Adapter.","sidebar":"integrations"},"integrations/caches/redis_llm_caching":{"id":"integrations/caches/redis_llm_caching","title":"Redis Cache for LangChain","description":"This notebook demonstrates how to use the RedisCache and RedisSemanticCache classes from the langchain-redis package to implement caching for LLM responses."},"integrations/callbacks/argilla":{"id":"integrations/callbacks/argilla","title":"Argilla","description":"Argilla is an open-source data curation platform for LLMs.","sidebar":"integrations"},"integrations/callbacks/comet_tracing":{"id":"integrations/callbacks/comet_tracing","title":"Comet Tracing","description":"There are two ways to trace your LangChains executions with Comet:","sidebar":"integrations"},"integrations/callbacks/confident":{"id":"integrations/callbacks/confident","title":"Confident","description":"DeepEval package for unit testing LLMs.","sidebar":"integrations"},"integrations/callbacks/context":{"id":"integrations/callbacks/context","title":"Context","description":"Context provides user analytics for LLM-powered products and features.","sidebar":"integrations"},"integrations/callbacks/fiddler":{"id":"integrations/callbacks/fiddler","title":"Fiddler","description":"Fiddler is the pioneer in enterprise Generative and Predictive system ops, offering a unified platform that enables Data Science, MLOps, Risk, Compliance, Analytics, and other LOB teams to monitor, explain, analyze, and improve ML deployments at enterprise scale.","sidebar":"integrations"},"integrations/callbacks/infino":{"id":"integrations/callbacks/infino","title":"Infino","description":"Infino is a scalable telemetry store designed for logs, metrics, and traces. Infino can function as a standalone observability solution or as the storage layer in your observability stack.","sidebar":"integrations"},"integrations/callbacks/labelstudio":{"id":"integrations/callbacks/labelstudio","title":"Label Studio","description":"Label Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.","sidebar":"integrations"},"integrations/callbacks/llmonitor":{"id":"integrations/callbacks/llmonitor","title":"LLMonitor","description":"LLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.","sidebar":"integrations"},"integrations/callbacks/promptlayer":{"id":"integrations/callbacks/promptlayer","title":"PromptLayer","description":"PromptLayer is a platform for prompt engineering. It also helps with the LLM observability to visualize requests, version prompts, and track usage.","sidebar":"integrations"},"integrations/callbacks/sagemaker_tracking":{"id":"integrations/callbacks/sagemaker_tracking","title":"SageMaker Tracking","description":"Amazon SageMaker is a fully managed service that is used to quickly and easily build, train and deploy machine learning (ML) models.","sidebar":"integrations"},"integrations/callbacks/streamlit":{"id":"integrations/callbacks/streamlit","title":"Streamlit","description":"Streamlit is a faster way to build and share data apps.","sidebar":"integrations"},"integrations/callbacks/trubrics":{"id":"integrations/callbacks/trubrics","title":"Trubrics","description":"Trubrics is an LLM user analytics platform that lets you collect, analyse and manage user","sidebar":"integrations"},"integrations/callbacks/upstash_ratelimit":{"id":"integrations/callbacks/upstash_ratelimit","title":"Upstash Ratelimit Callback","description":"In this guide, we will go over how to add rate limiting based on number of requests or the number of tokens using UpstashRatelimitHandler. This handler uses ratelimit library of Upstash, which utilizes Upstash Redis.","sidebar":"integrations"},"integrations/callbacks/uptrain":{"id":"integrations/callbacks/uptrain","title":"uptrain","description":"UpTrain [github || website || docs] is an open-source platform to evaluate and improve LLM applications. It provides grades for 20+ preconfigured checks (covering language, code, embedding use cases), performs root cause analyses on instances of failure cases and provides guidance for resolving them.","sidebar":"integrations"},"integrations/chat_loaders/discord":{"id":"integrations/chat_loaders/discord","title":"Discord","description":"This notebook shows how to create your own chat loader that works on copy-pasted messages (from dms) to a list of LangChain messages.","sidebar":"integrations"},"integrations/chat_loaders/facebook":{"id":"integrations/chat_loaders/facebook","title":"Facebook Messenger","description":"This notebook shows how to load data from Facebook in a format you can fine-tune on. The overall steps are:","sidebar":"integrations"},"integrations/chat_loaders/gmail":{"id":"integrations/chat_loaders/gmail","title":"GMail","description":"This loader goes over how to load data from GMail. There are many ways you could want to load data from GMail. This loader is currently fairly opinionated in how to do so. The way it does it is it first looks for all messages that you have sent. It then looks for messages where you are responding to a previous email. It then fetches that previous email, and creates a training example of that email, followed by your email.","sidebar":"integrations"},"integrations/chat_loaders/imessage":{"id":"integrations/chat_loaders/imessage","title":"iMessage","description":"This notebook shows how to use the iMessage chat loader. This class helps convert iMessage conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat_loaders/langsmith_dataset":{"id":"integrations/chat_loaders/langsmith_dataset","title":"LangSmith Chat Datasets","description":"This notebook demonstrates an easy way to load a LangSmith chat dataset fine-tune a model on that data.","sidebar":"integrations"},"integrations/chat_loaders/langsmith_llm_runs":{"id":"integrations/chat_loaders/langsmith_llm_runs","title":"LangSmith LLM Runs","description":"This notebook demonstrates how to directly load data from LangSmith\'s LLM runs and fine-tune a model on that data.","sidebar":"integrations"},"integrations/chat_loaders/slack":{"id":"integrations/chat_loaders/slack","title":"Slack","description":"This notebook shows how to use the Slack chat loader. This class helps map exported slack conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat_loaders/telegram":{"id":"integrations/chat_loaders/telegram","title":"Telegram","description":"This notebook shows how to use the Telegram chat loader. This class helps map exported Telegram conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat_loaders/twitter":{"id":"integrations/chat_loaders/twitter","title":"Twitter (via Apify)","description":"This notebook shows how to load chat messages from Twitter to fine-tune on. We do this by utilizing Apify.","sidebar":"integrations"},"integrations/chat_loaders/wechat":{"id":"integrations/chat_loaders/wechat","title":"WeChat","description":"There is not yet a straightforward way to export personal WeChat messages. However if you just need no more than few hundreds of messages for model fine-tuning or few-shot examples, this notebook shows how to create your own chat loader that works on copy-pasted WeChat messages to a list of LangChain messages.","sidebar":"integrations"},"integrations/chat_loaders/whatsapp":{"id":"integrations/chat_loaders/whatsapp","title":"WhatsApp","description":"This notebook shows how to use the WhatsApp chat loader. This class helps map exported WhatsApp conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat/abso":{"id":"integrations/chat/abso","title":"ChatAbso","description":"This will help you getting started with ChatAbso chat models. For detailed documentation of all ChatAbso features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/ai21":{"id":"integrations/chat/ai21","title":"ChatAI21","description":"Overview","sidebar":"integrations"},"integrations/chat/alibaba_cloud_pai_eas":{"id":"integrations/chat/alibaba_cloud_pai_eas","title":"Alibaba Cloud PAI EAS","description":"Alibaba Cloud PAI (Platform for AI) is a lightweight and cost-efficient machine learning platform that uses cloud-native technologies. It provides you with an end-to-end modelling service. It accelerates model training based on tens of billions of features and hundreds of billions of samples in more than 100 scenarios.","sidebar":"integrations"},"integrations/chat/anthropic":{"id":"integrations/chat/anthropic","title":"ChatAnthropic","description":"This notebook provides a quick overview for getting started with Anthropic chat models. For detailed documentation of all ChatAnthropic features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/anthropic_functions":{"id":"integrations/chat/anthropic_functions","title":"[Deprecated] Experimental Anthropic Tools Wrapper","description":"The Anthropic API officially supports tool-calling so this workaround is no longer needed. Please use ChatAnthropic with langchain-anthropic>=0.1.15.","sidebar":"integrations"},"integrations/chat/anyscale":{"id":"integrations/chat/anyscale","title":"ChatAnyscale","description":"This notebook demonstrates the use of langchain.chat_models.ChatAnyscale for Anyscale Endpoints.","sidebar":"integrations"},"integrations/chat/azure_ai":{"id":"integrations/chat/azure_ai","title":"AzureAIChatCompletionsModel","description":"This will help you getting started with AzureAIChatCompletionsModel chat models. For detailed documentation of all AzureAIChatCompletionsModel features and configurations head to the API reference","sidebar":"integrations"},"integrations/chat/azure_chat_openai":{"id":"integrations/chat/azure_chat_openai","title":"AzureChatOpenAI","description":"This guide will help you get started with AzureOpenAI chat models. For detailed documentation of all AzureChatOpenAI features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/azureml_chat_endpoint":{"id":"integrations/chat/azureml_chat_endpoint","title":"AzureMLChatOnlineEndpoint","description":"Azure Machine Learning is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides foundational and general purpose models from different providers.","sidebar":"integrations"},"integrations/chat/baichuan":{"id":"integrations/chat/baichuan","title":"Chat with Baichuan-192K","description":"Baichuan chat models API by Baichuan Intelligent Technology. For more information, see https://platform.baichuan-ai.com/docs/api","sidebar":"integrations"},"integrations/chat/baidu_qianfan_endpoint":{"id":"integrations/chat/baidu_qianfan_endpoint","title":"QianfanChatEndpoint","description":"Baidu AI Cloud Qianfan Platform is a one-stop large model development and service operation platform for enterprise developers. Qianfan not only provides including the model of Wenxin Yiyan (ERNIE-Bot) and the third-party open-source models, but also provides various AI development tools and the whole set of development environment, which facilitates customers to use and develop large model applications easily.","sidebar":"integrations"},"integrations/chat/bedrock":{"id":"integrations/chat/bedrock","title":"ChatBedrock","description":"This doc will help you get started with AWS Bedrock chat models. Amazon Bedrock is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon via a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and evaluate top FMs for your use case, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources. Since Amazon Bedrock is serverless, you don\'t have to manage any infrastructure, and you can securely integrate and deploy generative AI capabilities into your applications using the AWS services you are already familiar with.","sidebar":"integrations"},"integrations/chat/cerebras":{"id":"integrations/chat/cerebras","title":"ChatCerebras","description":"This notebook provides a quick overview for getting started with Cerebras chat models. For detailed documentation of all ChatCerebras features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/cloudflare_workersai":{"id":"integrations/chat/cloudflare_workersai","title":"ChatCloudflareWorkersAI","description":"This will help you getting started with CloudflareWorkersAI chat models. For detailed documentation of all available Cloudflare WorkersAI models head to the API reference.","sidebar":"integrations"},"integrations/chat/cohere":{"id":"integrations/chat/cohere","title":"Cohere","description":"This notebook covers how to get started with Cohere chat models.","sidebar":"integrations"},"integrations/chat/contextual":{"id":"integrations/chat/contextual","title":"ChatContextual","description":"This will help you getting started with Contextual AI\'s Grounded Language Model chat models.","sidebar":"integrations"},"integrations/chat/coze":{"id":"integrations/chat/coze","title":"Chat with Coze Bot","description":"ChatCoze chat models API by coze.com. For more information, see https://www.coze.com/open/docs/chat","sidebar":"integrations"},"integrations/chat/dappier":{"id":"integrations/chat/dappier","title":"Dappier AI","description":"Dappier: Powering AI with Dynamic, Real-Time Data Models","sidebar":"integrations"},"integrations/chat/databricks":{"id":"integrations/chat/databricks","title":"ChatDatabricks","description":"Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.","sidebar":"integrations"},"integrations/chat/deepinfra":{"id":"integrations/chat/deepinfra","title":"DeepInfra","description":"DeepInfra is a serverless inference as a service that provides access to a variety of LLMs and embeddings models. This notebook goes over how to use LangChain with DeepInfra for chat models.","sidebar":"integrations"},"integrations/chat/deepseek":{"id":"integrations/chat/deepseek","title":"ChatDeepSeek","description":"This will help you getting started with DeepSeek\'s hosted chat models. For detailed documentation of all ChatDeepSeek features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/edenai":{"id":"integrations/chat/edenai","title":"Eden AI","description":"Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)","sidebar":"integrations"},"integrations/chat/ernie":{"id":"integrations/chat/ernie","title":"ErnieBotChat","description":"ERNIE-Bot is a large language model developed by Baidu, covering a huge amount of Chinese data.","sidebar":"integrations"},"integrations/chat/everlyai":{"id":"integrations/chat/everlyai","title":"ChatEverlyAI","description":"EverlyAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.","sidebar":"integrations"},"integrations/chat/fireworks":{"id":"integrations/chat/fireworks","title":"ChatFireworks","description":"This doc help you get started with Fireworks AI chat models. For detailed documentation of all ChatFireworks features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/friendli":{"id":"integrations/chat/friendli","title":"ChatFriendli","description":"Friendli enhances AI application performance and optimizes cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads.","sidebar":"integrations"},"integrations/chat/gigachat":{"id":"integrations/chat/gigachat","title":"GigaChat","description":"This notebook shows how to use LangChain with GigaChat.","sidebar":"integrations"},"integrations/chat/goodfire":{"id":"integrations/chat/goodfire","title":"ChatGoodfire","description":"This will help you getting started with Goodfire chat models. For detailed documentation of all ChatGoodfire features and configurations head to the PyPI project page, or go directly to the Goodfire SDK docs. All of the Goodfire-specific functionality (e.g. SAE features, variants, etc.) is available via the main goodfire package. This integration is a wrapper around the Goodfire SDK.","sidebar":"integrations"},"integrations/chat/google_generative_ai":{"id":"integrations/chat/google_generative_ai","title":"ChatGoogleGenerativeAI","description":"This docs will help you get started with Google AI chat models. For detailed documentation of all ChatGoogleGenerativeAI features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/google_vertex_ai_palm":{"id":"integrations/chat/google_vertex_ai_palm","title":"ChatVertexAI","description":"This page provides a quick overview for getting started with VertexAI chat models. For detailed documentation of all ChatVertexAI features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/gpt_router":{"id":"integrations/chat/gpt_router","title":"GPTRouter","description":"GPTRouter is an open source LLM API Gateway that offers a universal API for 30+ LLMs, vision, and image models, with smart fallbacks based on uptime and latency, automatic retries, and streaming.","sidebar":"integrations"},"integrations/chat/groq":{"id":"integrations/chat/groq","title":"ChatGroq","description":"This will help you getting started with Groq chat models. For detailed documentation of all ChatGroq features and configurations head to the API reference. For a list of all Groq models, visit this link.","sidebar":"integrations"},"integrations/chat/huggingface":{"id":"integrations/chat/huggingface","title":"ChatHuggingFace","description":"This will help you getting started with langchainhuggingface chat models. For detailed documentation of all ChatHuggingFace features and configurations head to the API reference. For a list of models supported by Hugging Face check out this page.","sidebar":"integrations"},"integrations/chat/ibm_watsonx":{"id":"integrations/chat/ibm_watsonx","title":"ChatWatsonx","description":"ChatWatsonx is a wrapper for IBM watsonx.ai foundation models.","sidebar":"integrations"},"integrations/chat/index":{"id":"integrations/chat/index","title":"Chat models","description":"Chat models are language models that use a sequence of messages as inputs and return messages as outputs (as opposed to using plain text). These are generally newer models.","sidebar":"integrations"},"integrations/chat/jinachat":{"id":"integrations/chat/jinachat","title":"JinaChat","description":"This notebook covers how to get started with JinaChat chat models.","sidebar":"integrations"},"integrations/chat/kinetica":{"id":"integrations/chat/kinetica","title":"Kinetica Language To SQL Chat Model","description":"This notebook demonstrates how to use Kinetica to transform natural language into SQL","sidebar":"integrations"},"integrations/chat/konko":{"id":"integrations/chat/konko","title":"ChatKonko","description":"Konko API is a fully managed Web API designed to help application developers:","sidebar":"integrations"},"integrations/chat/litellm":{"id":"integrations/chat/litellm","title":"ChatLiteLLM","description":"LiteLLM is a library that simplifies calling Anthropic, Azure, Huggingface, Replicate, etc.","sidebar":"integrations"},"integrations/chat/litellm_router":{"id":"integrations/chat/litellm_router","title":"ChatLiteLLMRouter","description":"LiteLLM is a library that simplifies calling Anthropic, Azure, Huggingface, Replicate, etc.","sidebar":"integrations"},"integrations/chat/llama_api":{"id":"integrations/chat/llama_api","title":"ChatLlamaAPI","description":"This notebook shows how to use LangChain with LlamaAPI - a hosted version of Llama2 that adds in support for function calling.","sidebar":"integrations"},"integrations/chat/llama_edge":{"id":"integrations/chat/llama_edge","title":"LlamaEdge","description":"LlamaEdge allows you to chat with LLMs of GGUF format both locally and via chat service.","sidebar":"integrations"},"integrations/chat/llama2_chat":{"id":"integrations/chat/llama2_chat","title":"Llama2Chat","description":"This notebook shows how to augment Llama-2 LLMs with the Llama2Chat wrapper to support the Llama-2 chat prompt format. Several LLM implementations in LangChain can be used as interface to Llama-2 chat models. These include ChatHuggingFace, LlamaCpp, GPT4All, ..., to mention a few examples.","sidebar":"integrations"},"integrations/chat/llamacpp":{"id":"integrations/chat/llamacpp","title":"Llama.cpp","description":"llama.cpp python library is a simple Python bindings for @ggerganov","sidebar":"integrations"},"integrations/chat/maritalk":{"id":"integrations/chat/maritalk","title":"maritalk","description":"Introduction","sidebar":"integrations"},"integrations/chat/minimax":{"id":"integrations/chat/minimax","title":"MiniMaxChat","description":"Minimax is a Chinese startup that provides LLM service for companies and individuals.","sidebar":"integrations"},"integrations/chat/mistralai":{"id":"integrations/chat/mistralai","title":"ChatMistralAI","description":"This will help you getting started with Mistral chat models. For detailed documentation of all ChatMistralAI features and configurations head to the API reference. The ChatMistralAI class is built on top of the Mistral API. For a list of all the models supported by Mistral, check out this page.","sidebar":"integrations"},"integrations/chat/mlx":{"id":"integrations/chat/mlx","title":"MLX","description":"This notebook shows how to get started using MLX LLM\'s as chat models.","sidebar":"integrations"},"integrations/chat/modelscope_chat_endpoint":{"id":"integrations/chat/modelscope_chat_endpoint","title":"ModelScopeChatEndpoint","description":"ModelScope (Home | GitHub) is built upon the notion of \u201cModel-as-a-Service\u201d (MaaS). It seeks to bring together most advanced machine learning models from the AI community, and streamlines the process of leveraging AI models in real-world applications. The core ModelScope library open-sourced in this repository provides the interfaces and implementations that allow developers to perform model inference, training and evaluation.","sidebar":"integrations"},"integrations/chat/moonshot":{"id":"integrations/chat/moonshot","title":"MoonshotChat","description":"Moonshot is a Chinese startup that provides LLM service for companies and individuals.","sidebar":"integrations"},"integrations/chat/naver":{"id":"integrations/chat/naver","title":"ChatClovaX","description":"This notebook provides a quick overview for getting started with Naver\u2019s HyperCLOVA X chat models via CLOVA Studio. For detailed documentation of all ChatClovaX features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/nvidia_ai_endpoints":{"id":"integrations/chat/nvidia_ai_endpoints","title":"ChatNVIDIA","description":"This will help you getting started with NVIDIA chat models. For detailed documentation of all ChatNVIDIA features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/oci_data_science":{"id":"integrations/chat/oci_data_science","title":"ChatOCIModelDeployment","description":"This will help you getting started with OCIModelDeployment chat models. For detailed documentation of all ChatOCIModelDeployment features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/oci_generative_ai":{"id":"integrations/chat/oci_generative_ai","title":"ChatOCIGenAI","description":"This notebook provides a quick overview for getting started with OCIGenAI chat models. For detailed documentation of all ChatOCIGenAI features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/octoai":{"id":"integrations/chat/octoai","title":"ChatOctoAI","description":"OctoAI offers easy access to efficient compute and enables users to integrate their choice of AI models into applications. The OctoAI compute service helps you run, tune, and scale AI applications easily.","sidebar":"integrations"},"integrations/chat/ollama":{"id":"integrations/chat/ollama","title":"ChatOllama","description":"Ollama allows you to run open-source large language models, such as Llama 2, locally.","sidebar":"integrations"},"integrations/chat/openai":{"id":"integrations/chat/openai","title":"ChatOpenAI","description":"This notebook provides a quick overview for getting started with OpenAI chat models. For detailed documentation of all ChatOpenAI features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/outlines":{"id":"integrations/chat/outlines","title":"ChatOutlines","description":"This will help you getting started with Outlines chat models. For detailed documentation of all ChatOutlines features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/perplexity":{"id":"integrations/chat/perplexity","title":"ChatPerplexity","description":"This notebook covers how to get started with Perplexity chat models.","sidebar":"integrations"},"integrations/chat/pipeshift":{"id":"integrations/chat/pipeshift","title":"ChatPipeshift","description":"This will help you getting started with Pipeshift chat models. For detailed documentation of all ChatPipeshift features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/predictionguard":{"id":"integrations/chat/predictionguard","title":"ChatPredictionGuard","description":"Prediction Guard is a secure, scalable GenAI platform that safeguards sensitive data, prevents common AI malfunctions, and runs on affordable hardware.","sidebar":"integrations"},"integrations/chat/premai":{"id":"integrations/chat/premai","title":"ChatPremAI","description":"PremAI is an all-in-one platform that simplifies the creation of robust, production-ready applications powered by Generative AI. By streamlining the development process, PremAI allows you to concentrate on enhancing user experience and driving overall growth for your application. You can quickly start using our platform here.","sidebar":"integrations"},"integrations/chat/promptlayer_chatopenai":{"id":"integrations/chat/promptlayer_chatopenai","title":"PromptLayerChatOpenAI","description":"This example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.","sidebar":"integrations"},"integrations/chat/reka":{"id":"integrations/chat/reka","title":"ChatReka","description":"This notebook provides a quick overview for getting started with Reka chat models.","sidebar":"integrations"},"integrations/chat/sambanova":{"id":"integrations/chat/sambanova","title":"ChatSambaNovaCloud","description":"This will help you getting started with SambaNovaCloud chat models. For detailed documentation of all ChatSambaNovaCloud features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/sambastudio":{"id":"integrations/chat/sambastudio","title":"ChatSambaStudio","description":"This will help you getting started with SambaStudio chat models. For detailed documentation of all ChatStudio features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/snowflake":{"id":"integrations/chat/snowflake","title":"Snowflake Cortex","description":"Snowflake Cortex gives you instant access to industry-leading large language models (LLMs) trained by researchers at companies like Mistral, Reka, Meta, and Google, including Snowflake Arctic, an open enterprise-grade model developed by Snowflake.","sidebar":"integrations"},"integrations/chat/solar":{"id":"integrations/chat/solar","title":"solar","description":"Related","sidebar":"integrations"},"integrations/chat/sparkllm":{"id":"integrations/chat/sparkllm","title":"SparkLLM Chat","description":"SparkLLM chat models API by iFlyTek. For more information, see iFlyTek Open Platform.","sidebar":"integrations"},"integrations/chat/symblai_nebula":{"id":"integrations/chat/symblai_nebula","title":"Nebula (Symbl.ai)","description":"Overview","sidebar":"integrations"},"integrations/chat/tencent_hunyuan":{"id":"integrations/chat/tencent_hunyuan","title":"Tencent Hunyuan","description":"Tencent\'s hybrid model API (Hunyuan API)","sidebar":"integrations"},"integrations/chat/together":{"id":"integrations/chat/together","title":"ChatTogether","description":"This page will help you get started with Together AI chat models. For detailed documentation of all ChatTogether features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/tongyi":{"id":"integrations/chat/tongyi","title":"ChatTongyi","description":"Tongyi Qwen is a large language model developed by Alibaba\'s Damo Academy. It is capable of understanding user intent through natural language understanding and semantic analysis, based on user input in natural language. It provides services and assistance to users in different domains and tasks. By providing clear and detailed instructions, you can obtain results that better align with your expectations.","sidebar":"integrations"},"integrations/chat/upstage":{"id":"integrations/chat/upstage","title":"ChatUpstage","description":"This notebook covers how to get started with Upstage chat models.","sidebar":"integrations"},"integrations/chat/vllm":{"id":"integrations/chat/vllm","title":"vLLM Chat","description":"vLLM can be deployed as a server that mimics the OpenAI API protocol. This allows vLLM to be used as a drop-in replacement for applications using OpenAI API. This server can be queried in the same format as OpenAI API.","sidebar":"integrations"},"integrations/chat/volcengine_maas":{"id":"integrations/chat/volcengine_maas","title":"VolcEngineMaasChat","description":"This notebook provides you with a guide on how to get started with volc engine maas chat models.","sidebar":"integrations"},"integrations/chat/writer":{"id":"integrations/chat/writer","title":"Chat Writer","description":"This notebook provides a quick overview for getting started with Writer chat.","sidebar":"integrations"},"integrations/chat/xai":{"id":"integrations/chat/xai","title":"ChatXAI","description":"This page will help you get started with xAI chat models. For detailed documentation of all ChatXAI features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/xinference":{"id":"integrations/chat/xinference","title":"ChatXinference","description":"Xinference is a powerful and versatile library designed to serve LLMs,","sidebar":"integrations"},"integrations/chat/yandex":{"id":"integrations/chat/yandex","title":"ChatYandexGPT","description":"This notebook goes over how to use Langchain with YandexGPT chat model.","sidebar":"integrations"},"integrations/chat/yi":{"id":"integrations/chat/yi","title":"ChatYI","description":"This will help you getting started with Yi chat models. For detailed documentation of all ChatYi features and configurations head to the API reference.","sidebar":"integrations"},"integrations/chat/yuan2":{"id":"integrations/chat/yuan2","title":"Yuan2.0","description":"This notebook shows how to use YUAN2 API in LangChain with the langchain.chatmodels.ChatYuan2.","sidebar":"integrations"},"integrations/chat/zhipuai":{"id":"integrations/chat/zhipuai","title":"ZHIPU AI","description":"This notebook shows how to use ZHIPU AI API in LangChain with the langchain.chat_models.ChatZhipuAI.","sidebar":"integrations"},"integrations/document_loaders/acreom":{"id":"integrations/document_loaders/acreom","title":"acreom","description":"acreom is a dev-first knowledge base with tasks running on local markdown files.","sidebar":"integrations"},"integrations/document_loaders/agentql":{"id":"integrations/document_loaders/agentql","title":"AgentQLLoader","description":"AgentQL\'s document loader provides structured data extraction from any web page using an AgentQL query. AgentQL can be used across multiple languages and web pages without breaking over time and change.","sidebar":"integrations"},"integrations/document_loaders/airbyte":{"id":"integrations/document_loaders/airbyte","title":"AirbyteLoader","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_cdk":{"id":"integrations/document_loaders/airbyte_cdk","title":"Airbyte CDK (Deprecated)","description":"Note: AirbyteCDKLoader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_gong":{"id":"integrations/document_loaders/airbyte_gong","title":"Airbyte Gong (Deprecated)","description":"Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_hubspot":{"id":"integrations/document_loaders/airbyte_hubspot","title":"Airbyte Hubspot (Deprecated)","description":"Note: AirbyteHubspotLoader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_json":{"id":"integrations/document_loaders/airbyte_json","title":"Airbyte JSON (Deprecated)","description":"Note: AirbyteJSONLoader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_salesforce":{"id":"integrations/document_loaders/airbyte_salesforce","title":"Airbyte Salesforce (Deprecated)","description":"Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_shopify":{"id":"integrations/document_loaders/airbyte_shopify","title":"Airbyte Shopify (Deprecated)","description":"Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_stripe":{"id":"integrations/document_loaders/airbyte_stripe","title":"Airbyte Stripe (Deprecated)","description":"Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_typeform":{"id":"integrations/document_loaders/airbyte_typeform","title":"Airbyte Typeform (Deprecated)","description":"Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airbyte_zendesk_support":{"id":"integrations/document_loaders/airbyte_zendesk_support","title":"Airbyte Zendesk Support (Deprecated)","description":"Note: This connector-specific loader is deprecated. Please use AirbyteLoader instead.","sidebar":"integrations"},"integrations/document_loaders/airtable":{"id":"integrations/document_loaders/airtable","title":"Airtable","description":"* Get your API key here.","sidebar":"integrations"},"integrations/document_loaders/alibaba_cloud_maxcompute":{"id":"integrations/document_loaders/alibaba_cloud_maxcompute","title":"Alibaba Cloud MaxCompute","description":"Alibaba Cloud MaxCompute (previously known as ODPS) is a general purpose, fully managed, multi-tenancy data processing platform for large-scale data warehousing. MaxCompute supports various data importing solutions and distributed computing models, enabling users to effectively query massive datasets, reduce production costs, and ensure data security.","sidebar":"integrations"},"integrations/document_loaders/amazon_textract":{"id":"integrations/document_loaders/amazon_textract","title":"Amazon Textract","description":"Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from scanned documents.","sidebar":"integrations"},"integrations/document_loaders/apify_dataset":{"id":"integrations/document_loaders/apify_dataset","title":"Apify Dataset","description":"Apify Dataset is a scalable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of Apify Actors\u2014serverless cloud programs for various web scraping, crawling, and data extraction use cases.","sidebar":"integrations"},"integrations/document_loaders/arcgis":{"id":"integrations/document_loaders/arcgis","title":"ArcGIS","description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","sidebar":"integrations"},"integrations/document_loaders/arxiv":{"id":"integrations/document_loaders/arxiv","title":"ArxivLoader","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.","sidebar":"integrations"},"integrations/document_loaders/assemblyai":{"id":"integrations/document_loaders/assemblyai","title":"AssemblyAI Audio Transcripts","description":"The AssemblyAIAudioTranscriptLoader allows to transcribe audio files with the AssemblyAI API and loads the transcribed text into documents.","sidebar":"integrations"},"integrations/document_loaders/astradb":{"id":"integrations/document_loaders/astradb","title":"AstraDB","description":"DataStax Astra DB is a serverless vector-capable database built on Cassandra and made conveniently available through an easy-to-use JSON API.","sidebar":"integrations"},"integrations/document_loaders/async_chromium":{"id":"integrations/document_loaders/async_chromium","title":"Async Chromium","description":"Chromium is one of the browsers supported by Playwright, a library used to control browser automation.","sidebar":"integrations"},"integrations/document_loaders/async_html":{"id":"integrations/document_loaders/async_html","title":"AsyncHtml","description":"AsyncHtmlLoader loads raw HTML from a list of URLs concurrently.","sidebar":"integrations"},"integrations/document_loaders/athena":{"id":"integrations/document_loaders/athena","title":"Athena","description":"Amazon Athena is a serverless, interactive analytics service built","sidebar":"integrations"},"integrations/document_loaders/aws_s3_directory":{"id":"integrations/document_loaders/aws_s3_directory","title":"AWS S3 Directory","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service","sidebar":"integrations"},"integrations/document_loaders/aws_s3_file":{"id":"integrations/document_loaders/aws_s3_file","title":"AWS S3 File","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service.","sidebar":"integrations"},"integrations/document_loaders/azlyrics":{"id":"integrations/document_loaders/azlyrics","title":"AZLyrics","description":"AZLyrics is a large, legal, every day growing collection of lyrics.","sidebar":"integrations"},"integrations/document_loaders/azure_ai_data":{"id":"integrations/document_loaders/azure_ai_data","title":"Azure AI Data","description":"Azure AI Studio provides the capability to upload data assets to cloud storage and register existing data assets from the following sources:","sidebar":"integrations"},"integrations/document_loaders/azure_blob_storage_container":{"id":"integrations/document_loaders/azure_blob_storage_container","title":"Azure Blob Storage Container","description":"Azure Blob Storage is Microsoft\'s object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn\'t adhere to a particular data model or definition, such as text or binary data.","sidebar":"integrations"},"integrations/document_loaders/azure_blob_storage_file":{"id":"integrations/document_loaders/azure_blob_storage_file","title":"Azure Blob Storage File","description":"Azure Files offers fully managed file shares in the cloud that are accessible via the industry standard Server Message Block (SMB) protocol, Network File System (NFS) protocol, and Azure Files REST API.","sidebar":"integrations"},"integrations/document_loaders/azure_document_intelligence":{"id":"integrations/document_loaders/azure_document_intelligence","title":"Azure AI Document Intelligence","description":"Azure AI Document Intelligence (formerly known as Azure Form Recognizer) is machine-learning","sidebar":"integrations"},"integrations/document_loaders/bibtex":{"id":"integrations/document_loaders/bibtex","title":"BibTeX","description":"BibTeX is a file format and reference management system commonly used in conjunction with LaTeX typesetting. It serves as a way to organize and store bibliographic information for academic and research documents.","sidebar":"integrations"},"integrations/document_loaders/bilibili":{"id":"integrations/document_loaders/bilibili","title":"BiliBili","description":"Bilibili is one of the most beloved long-form video sites in China.","sidebar":"integrations"},"integrations/document_loaders/blackboard":{"id":"integrations/document_loaders/blackboard","title":"Blackboard","description":"Blackboard Learn (previously the Blackboard Learning Management System) is a web-based virtual learning environment and learning management system developed by Blackboard Inc. The software features course management, customizable open architecture, and scalable design that allows integration with student information systems and authentication protocols. It may be installed on local servers, hosted by Blackboard ASP Solutions, or provided as Software as a Service hosted on Amazon Web Services. Its main purposes are stated to include the addition of online elements to courses traditionally delivered face-to-face and development of completely online courses with few or no face-to-face meetings","sidebar":"integrations"},"integrations/document_loaders/blockchain":{"id":"integrations/document_loaders/blockchain","title":"Blockchain","description":"Overview","sidebar":"integrations"},"integrations/document_loaders/box":{"id":"integrations/document_loaders/box","title":"BoxLoader and BoxBlobLoader","description":"The langchain-box package provides two methods to index your files from Box: BoxLoader and BoxBlobLoader. BoxLoader allows you to ingest text representations of files that have a text representation in Box. The BoxBlobLoader allows you download the blob for any document or image file for processing with the blob parser of your choice.","sidebar":"integrations"},"integrations/document_loaders/brave_search":{"id":"integrations/document_loaders/brave_search","title":"Brave Search","description":"Brave Search is a search engine developed by Brave Software.","sidebar":"integrations"},"integrations/document_loaders/browserbase":{"id":"integrations/document_loaders/browserbase","title":"Browserbase","description":"Browserbase is a developer platform to reliably run, manage, and monitor headless browsers.","sidebar":"integrations"},"integrations/document_loaders/browserless":{"id":"integrations/document_loaders/browserless","title":"Browserless","description":"Browserless is a service that allows you to run headless Chrome instances in the cloud. It\'s a great way to run browser-based automation at scale without having to worry about managing your own infrastructure.","sidebar":"integrations"},"integrations/document_loaders/bshtml":{"id":"integrations/document_loaders/bshtml","title":"BSHTMLLoader","description":"This notebook provides a quick overview for getting started with BeautifulSoup4 document loader. For detailed documentation of all ModuleNameLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/cassandra":{"id":"integrations/document_loaders/cassandra","title":"Cassandra","description":"Cassandra is a NoSQL, row-oriented, highly scalable and highly available database.Starting with version 5.0, the database ships with vector search capabilities.","sidebar":"integrations"},"integrations/document_loaders/chatgpt_loader":{"id":"integrations/document_loaders/chatgpt_loader","title":"ChatGPT Data","description":"ChatGPT is an artificial intelligence (AI) chatbot developed by OpenAI.","sidebar":"integrations"},"integrations/document_loaders/college_confidential":{"id":"integrations/document_loaders/college_confidential","title":"College Confidential","description":"College Confidential gives information on 3,800+ colleges and universities.","sidebar":"integrations"},"integrations/document_loaders/concurrent":{"id":"integrations/document_loaders/concurrent","title":"Concurrent Loader","description":"Works just like the GenericLoader but concurrently for those who choose to optimize their workflow.","sidebar":"integrations"},"integrations/document_loaders/confluence":{"id":"integrations/document_loaders/confluence","title":"Confluence","description":"Confluence is a wiki collaboration platform that saves and organizes all of the project-related material. Confluence is a knowledge base that primarily handles content management activities.","sidebar":"integrations"},"integrations/document_loaders/conll-u":{"id":"integrations/document_loaders/conll-u","title":"CoNLL-U","description":"CoNLL-U is revised version of the CoNLL-X format. Annotations are encoded in plain text files (UTF-8, normalized to NFC, using only the LF character as line break, including an LF character at the end of file) with three types of lines:","sidebar":"integrations"},"integrations/document_loaders/copypaste":{"id":"integrations/document_loaders/copypaste","title":"Copy Paste","description":"This notebook covers how to load a document object from something you just want to copy and paste. In this case, you don\'t even need to use a DocumentLoader, but rather can just construct the Document directly.","sidebar":"integrations"},"integrations/document_loaders/couchbase":{"id":"integrations/document_loaders/couchbase","title":"Couchbase","description":"Couchbase is an award-winning distributed NoSQL cloud database that delivers unmatched versatility, performance, scalability, and financial value for all of your cloud, mobile, AI, and edge computing applications.","sidebar":"integrations"},"integrations/document_loaders/csv":{"id":"integrations/document_loaders/csv","title":"CSV","description":"A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.","sidebar":"integrations"},"integrations/document_loaders/cube_semantic":{"id":"integrations/document_loaders/cube_semantic","title":"Cube Semantic Layer","description":"This notebook demonstrates the process of retrieving Cube\'s data model metadata in a format suitable for passing to LLMs as embeddings, thereby enhancing contextual information.","sidebar":"integrations"},"integrations/document_loaders/datadog_logs":{"id":"integrations/document_loaders/datadog_logs","title":"Datadog Logs","description":"Datadog is a monitoring and analytics platform for cloud-scale applications.","sidebar":"integrations"},"integrations/document_loaders/dedoc":{"id":"integrations/document_loaders/dedoc","title":"Dedoc","description":"This sample demonstrates the use of Dedoc in combination with LangChain as a DocumentLoader.","sidebar":"integrations"},"integrations/document_loaders/diffbot":{"id":"integrations/document_loaders/diffbot","title":"Diffbot","description":"Diffbot is a suite of ML-based products that make it easy to structure web data.","sidebar":"integrations"},"integrations/document_loaders/discord":{"id":"integrations/document_loaders/discord","title":"Discord","description":"Discord is a VoIP and instant messaging social platform. Users have the ability to communicate with voice calls, video calls, text messaging, media and files in private chats or as part of communities called \\"servers\\". A server is a collection of persistent chat rooms and voice channels which can be accessed via invite links.","sidebar":"integrations"},"integrations/document_loaders/docling":{"id":"integrations/document_loaders/docling","title":"Docling","description":"Docling parses PDF, DOCX, PPTX, HTML, and other formats into a rich unified representation including document layout, tables etc., making them ready for generative AI workflows like RAG.","sidebar":"integrations"},"integrations/document_loaders/docugami":{"id":"integrations/document_loaders/docugami","title":"Docugami","description":"This notebook covers how to load documents from Docugami. It provides the advantages of using this system over alternative data loaders.","sidebar":"integrations"},"integrations/document_loaders/docusaurus":{"id":"integrations/document_loaders/docusaurus","title":"Docusaurus","description":"Docusaurus is a static-site generator which provides out-of-the-box documentation features.","sidebar":"integrations"},"integrations/document_loaders/dropbox":{"id":"integrations/document_loaders/dropbox","title":"Dropbox","description":"Dropbox is a file hosting service that brings everything-traditional files, cloud content, and web shortcuts together in one place.","sidebar":"integrations"},"integrations/document_loaders/duckdb":{"id":"integrations/document_loaders/duckdb","title":"DuckDB","description":"DuckDB is an in-process SQL OLAP database management system.","sidebar":"integrations"},"integrations/document_loaders/email":{"id":"integrations/document_loaders/email","title":"Email","description":"This notebook shows how to load email (.eml) or Microsoft Outlook (.msg) files.","sidebar":"integrations"},"integrations/document_loaders/epub":{"id":"integrations/document_loaders/epub","title":"EPub","description":"EPUB is an e-book file format that uses the \\".epub\\" file extension. The term is short for electronic publication and is sometimes styled ePub. EPUB is supported by many e-readers, and compatible software is available for most smartphones, tablets, and computers.","sidebar":"integrations"},"integrations/document_loaders/etherscan":{"id":"integrations/document_loaders/etherscan","title":"Etherscan","description":"Etherscan  is the leading blockchain explorer, search, API and analytics platform for Ethereum,","sidebar":"integrations"},"integrations/document_loaders/evernote":{"id":"integrations/document_loaders/evernote","title":"EverNote","description":"EverNote is intended for archiving and creating notes in which photos, audio and saved web content can be embedded. Notes are stored in virtual \\"notebooks\\" and can be tagged, annotated, edited, searched, and exported.","sidebar":"integrations"},"integrations/document_loaders/example_data/example":{"id":"integrations/document_loaders/example_data/example","title":"Sample Markdown Document","description":"Introduction","sidebar":"integrations"},"integrations/document_loaders/facebook_chat":{"id":"integrations/document_loaders/facebook_chat","title":"Facebook Chat","description":"Messenger) is an American proprietary instant messaging app and platform developed by Meta Platforms. Originally developed as Facebook Chat in 2008, the company revamped its messaging service in 2010.","sidebar":"integrations"},"integrations/document_loaders/fauna":{"id":"integrations/document_loaders/fauna","title":"Fauna","description":"Fauna is a Document Database.","sidebar":"integrations"},"integrations/document_loaders/figma":{"id":"integrations/document_loaders/figma","title":"Figma","description":"Figma is a collaborative web application for interface design.","sidebar":"integrations"},"integrations/document_loaders/firecrawl":{"id":"integrations/document_loaders/firecrawl","title":"FireCrawl","description":"FireCrawl crawls and convert any website into LLM-ready data. It crawls all accessible subpages and give you clean markdown and metadata for each. No sitemap required.","sidebar":"integrations"},"integrations/document_loaders/geopandas":{"id":"integrations/document_loaders/geopandas","title":"Geopandas","description":"Geopandas is an open-source project to make working with geospatial data in python easier.","sidebar":"integrations"},"integrations/document_loaders/git":{"id":"integrations/document_loaders/git","title":"Git","description":"Git is a distributed version control system that tracks changes in any set of computer files, usually used for coordinating work among programmers collaboratively developing source code during software development.","sidebar":"integrations"},"integrations/document_loaders/gitbook":{"id":"integrations/document_loaders/gitbook","title":"GitBook","description":"GitBook is a modern documentation platform where teams can document everything from products to internal knowledge bases and APIs.","sidebar":"integrations"},"integrations/document_loaders/github":{"id":"integrations/document_loaders/github","title":"GitHub","description":"This notebooks shows how you can load issues and pull requests (PRs) for a given repository on GitHub. Also shows how you can load github files for a given repository on GitHub. We will use the LangChain Python repository as an example.","sidebar":"integrations"},"integrations/document_loaders/glue_catalog":{"id":"integrations/document_loaders/glue_catalog","title":"Glue Catalog","description":"The AWS Glue Data Catalog is a centralized metadata repository that allows you to manage, access, and share metadata about your data stored in AWS. It acts as a metadata store for your data assets, enabling various AWS services and your applications to query and connect to the data they need efficiently.","sidebar":"integrations"},"integrations/document_loaders/google_alloydb":{"id":"integrations/document_loaders/google_alloydb","title":"Google AlloyDB for PostgreSQL","description":"AlloyDB is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. AlloyDB is 100% compatible with PostgreSQL. Extend your database application to build AI-powered experiences leveraging AlloyDB\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_bigquery":{"id":"integrations/document_loaders/google_bigquery","title":"Google BigQuery","description":"Google BigQuery is a serverless and cost-effective enterprise data warehouse that works across clouds and scales with your data.","sidebar":"integrations"},"integrations/document_loaders/google_bigtable":{"id":"integrations/document_loaders/google_bigtable","title":"Google Bigtable","description":"Bigtable is a key-value and wide-column store, ideal for fast access to structured, semi-structured, or unstructured data. Extend your database application to build AI-powered experiences leveraging Bigtable\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_sql_mssql":{"id":"integrations/document_loaders/google_cloud_sql_mssql","title":"Google Cloud SQL for SQL server","description":"Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers MySQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_sql_mysql":{"id":"integrations/document_loaders/google_cloud_sql_mysql","title":"Google Cloud SQL for MySQL","description":"Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers MySQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_sql_pg":{"id":"integrations/document_loaders/google_cloud_sql_pg","title":"Google Cloud SQL for PostgreSQL","description":"Cloud SQL for PostgreSQL is a fully-managed database service that helps you set up, maintain, manage, and administer your PostgreSQL relational databases on Google Cloud Platform. Extend your database application to build AI-powered experiences leveraging Cloud SQL for PostgreSQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_storage_directory":{"id":"integrations/document_loaders/google_cloud_storage_directory","title":"Google Cloud Storage Directory","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_storage_file":{"id":"integrations/document_loaders/google_cloud_storage_file","title":"Google Cloud Storage File","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"integrations"},"integrations/document_loaders/google_datastore":{"id":"integrations/document_loaders/google_datastore","title":"Google Firestore in Datastore Mode","description":"Firestore in Datastore Mode is a NoSQL document database built for automatic scaling, high performance and ease of application development. Extend your database application to build AI-powered experiences leveraging Datastore\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_drive":{"id":"integrations/document_loaders/google_drive","title":"Google Drive","description":"Google Drive is a file storage and synchronization service developed by Google.","sidebar":"integrations"},"integrations/document_loaders/google_el_carro":{"id":"integrations/document_loaders/google_el_carro","title":"Google El Carro for Oracle Workloads","description":"Google El Carro Oracle Operator","sidebar":"integrations"},"integrations/document_loaders/google_firestore":{"id":"integrations/document_loaders/google_firestore","title":"Google Firestore (Native Mode)","description":"Firestore is a serverless document-oriented database that scales to meet any demand. Extend your database application to build AI-powered experiences leveraging Firestore\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_memorystore_redis":{"id":"integrations/document_loaders/google_memorystore_redis","title":"Google Memorystore for Redis","description":"Google Memorystore for Redis is a fully-managed service that is powered by the Redis in-memory data store to build application caches that provide sub-millisecond data access. Extend your database application to build AI-powered experiences leveraging Memorystore for Redis\'s Langchain integrations.","sidebar":"integrations"},"integrations/document_loaders/google_spanner":{"id":"integrations/document_loaders/google_spanner","title":"Google Spanner","description":"Spanner is a highly scalable database that combines unlimited scalability with relational semantics, such as secondary indexes, strong consistency, schemas, and SQL providing 99.999% availability in one easy solution.","sidebar":"integrations"},"integrations/document_loaders/google_speech_to_text":{"id":"integrations/document_loaders/google_speech_to_text","title":"Google Speech-to-Text Audio Transcripts","description":"The SpeechToTextLoader allows to transcribe audio files with the Google Cloud Speech-to-Text API and loads the transcribed text into documents.","sidebar":"integrations"},"integrations/document_loaders/grobid":{"id":"integrations/document_loaders/grobid","title":"Grobid","description":"GROBID is a machine learning library for extracting, parsing, and re-structuring raw documents.","sidebar":"integrations"},"integrations/document_loaders/gutenberg":{"id":"integrations/document_loaders/gutenberg","title":"Gutenberg","description":"Project Gutenberg is an online library of free eBooks.","sidebar":"integrations"},"integrations/document_loaders/hacker_news":{"id":"integrations/document_loaders/hacker_news","title":"Hacker News","description":"Hacker News (sometimes abbreviated as HN) is a social news website focusing on computer science and entrepreneurship. It is run by the investment fund and startup incubator Y Combinator. In general, content that can be submitted is defined as \\"anything that gratifies one\'s intellectual curiosity.\\"","sidebar":"integrations"},"integrations/document_loaders/huawei_obs_directory":{"id":"integrations/document_loaders/huawei_obs_directory","title":"Huawei OBS Directory","description":"The following code demonstrates how to load objects from the Huawei OBS (Object Storage Service) as documents.","sidebar":"integrations"},"integrations/document_loaders/huawei_obs_file":{"id":"integrations/document_loaders/huawei_obs_file","title":"Huawei OBS File","description":"The following code demonstrates how to load an object from the Huawei OBS (Object Storage Service) as document.","sidebar":"integrations"},"integrations/document_loaders/hugging_face_dataset":{"id":"integrations/document_loaders/hugging_face_dataset","title":"HuggingFace dataset","description":"The Hugging Face Hub is home to over 5,000 datasets in more than 100 languages that can be used for a broad range of tasks across NLP, Computer Vision, and Audio. They used for a diverse range of tasks such as translation,","sidebar":"integrations"},"integrations/document_loaders/hyperbrowser":{"id":"integrations/document_loaders/hyperbrowser","title":"HyperbrowserLoader","description":"Hyperbrowser is a platform for running and scaling headless browsers. It lets you launch and manage browser sessions at scale and provides easy to use solutions for any webscraping needs, such as scraping a single page or crawling an entire site.","sidebar":"integrations"},"integrations/document_loaders/ifixit":{"id":"integrations/document_loaders/ifixit","title":"iFixit","description":"iFixit is the largest, open repair community on the web. The site contains nearly 100k repair manuals, 200k Questions & Answers on 42k devices, and all the data is licensed under CC-BY-NC-SA 3.0.","sidebar":"integrations"},"integrations/document_loaders/image":{"id":"integrations/document_loaders/image","title":"Images","description":"This covers how to load images into a document format that we can use downstream with other LangChain modules.","sidebar":"integrations"},"integrations/document_loaders/image_captions":{"id":"integrations/document_loaders/image_captions","title":"Image captions","description":"By default, the loader utilizes the pre-trained Salesforce BLIP image captioning model.","sidebar":"integrations"},"integrations/document_loaders/imsdb":{"id":"integrations/document_loaders/imsdb","title":"IMSDb","description":"IMSDb is the Internet Movie Script Database.","sidebar":"integrations"},"integrations/document_loaders/index":{"id":"integrations/document_loaders/index","title":"Document loaders","description":"DocumentLoaders load data into the standard LangChain Document format.","sidebar":"integrations"},"integrations/document_loaders/iugu":{"id":"integrations/document_loaders/iugu","title":"Iugu","description":"Iugu is a Brazilian services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"integrations"},"integrations/document_loaders/joplin":{"id":"integrations/document_loaders/joplin","title":"Joplin","description":"Joplin is an open-source note-taking app. Capture your thoughts and securely access them from any device.","sidebar":"integrations"},"integrations/document_loaders/json":{"id":"integrations/document_loaders/json","title":"JSONLoader","description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/jupyter_notebook":{"id":"integrations/document_loaders/jupyter_notebook","title":"Jupyter Notebook","description":"Jupyter Notebook (formerly IPython Notebook) is a web-based interactive computational environment for creating notebook documents.","sidebar":"integrations"},"integrations/document_loaders/kinetica":{"id":"integrations/document_loaders/kinetica","title":"Kinetica","description":"This notebooks goes over how to load documents from Kinetica","sidebar":"integrations"},"integrations/document_loaders/lakefs":{"id":"integrations/document_loaders/lakefs","title":"lakeFS","description":"lakeFS provides scalable version control over the data lake, and uses Git-like semantics to create and access those versions.","sidebar":"integrations"},"integrations/document_loaders/langsmith":{"id":"integrations/document_loaders/langsmith","title":"LangSmithLoader","description":"This notebook provides a quick overview for getting started with the LangSmith document loader. For detailed documentation of all LangSmithLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/larksuite":{"id":"integrations/document_loaders/larksuite","title":"LarkSuite (FeiShu)","description":"LarkSuite is an enterprise collaboration platform developed by ByteDance.","sidebar":"integrations"},"integrations/document_loaders/llmsherpa":{"id":"integrations/document_loaders/llmsherpa","title":"LLM Sherpa","description":"This notebook covers how to use LLM Sherpa to load files of many types. LLM Sherpa supports different file formats including DOCX, PPTX, HTML, TXT, and XML.","sidebar":"integrations"},"integrations/document_loaders/mastodon":{"id":"integrations/document_loaders/mastodon","title":"Mastodon","description":"Mastodon is a federated social media and social networking service.","sidebar":"integrations"},"integrations/document_loaders/mathpix":{"id":"integrations/document_loaders/mathpix","title":"MathPixPDFLoader","description":"Inspired by Daniel Gross\'s snippet here//gist.github.com/danielgross/3ab4104e14faccc12b49200843adab21","sidebar":"integrations"},"integrations/document_loaders/mediawikidump":{"id":"integrations/document_loaders/mediawikidump","title":"MediaWiki Dump","description":"MediaWiki XML Dumps contain the content of a wiki (wiki pages with all their revisions), without the site-related data. A XML dump does not create a full backup of the wiki database, the dump does not contain user accounts, images, edit logs, etc.","sidebar":"integrations"},"integrations/document_loaders/merge_doc":{"id":"integrations/document_loaders/merge_doc","title":"Merge Documents Loader","description":"Merge the documents returned from a set of specified data loaders.","sidebar":"integrations"},"integrations/document_loaders/mhtml":{"id":"integrations/document_loaders/mhtml","title":"mhtml","description":"MHTML is a is used both for emails but also for archived webpages. MHTML, sometimes referred as MHT, stands for MIME HTML is a single file in which entire webpage is archived. When one saves a webpage as MHTML format, this file extension will contain HTML code, images, audio files, flash animation etc.","sidebar":"integrations"},"integrations/document_loaders/microsoft_excel":{"id":"integrations/document_loaders/microsoft_excel","title":"Microsoft Excel","description":"The UnstructuredExcelLoader is used to load Microsoft Excel files. The loader works with both .xlsx and .xls files. The page content will be the raw text of the Excel file. If you use the loader in \\"elements\\" mode, an HTML representation of the Excel file will be available in the document metadata under the textashtml key.","sidebar":"integrations"},"integrations/document_loaders/microsoft_onedrive":{"id":"integrations/document_loaders/microsoft_onedrive","title":"Microsoft OneDrive","description":"Microsoft OneDrive (formerly SkyDrive) is a file hosting service operated by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/microsoft_onenote":{"id":"integrations/document_loaders/microsoft_onenote","title":"Microsoft OneNote","description":"This notebook covers how to load documents from OneNote.","sidebar":"integrations"},"integrations/document_loaders/microsoft_powerpoint":{"id":"integrations/document_loaders/microsoft_powerpoint","title":"Microsoft PowerPoint","description":"Microsoft PowerPoint is a presentation program by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/microsoft_sharepoint":{"id":"integrations/document_loaders/microsoft_sharepoint","title":"Microsoft SharePoint","description":"Microsoft SharePoint is a website-based collaboration system that uses workflow applications, \u201clist\u201d databases, and other web parts and security features to empower business teams to work together developed by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/microsoft_word":{"id":"integrations/document_loaders/microsoft_word","title":"Microsoft Word","description":"Microsoft Word is a word processor developed by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/mintbase":{"id":"integrations/document_loaders/mintbase","title":"Near Blockchain","description":"Overview","sidebar":"integrations"},"integrations/document_loaders/modern_treasury":{"id":"integrations/document_loaders/modern_treasury","title":"Modern Treasury","description":"Modern Treasury simplifies complex payment operations. It is a unified platform to power products and processes that move money.","sidebar":"integrations"},"integrations/document_loaders/mongodb":{"id":"integrations/document_loaders/mongodb","title":"MongoDB","description":"MongoDB is a NoSQL , document-oriented database that supports JSON-like documents with a dynamic schema.","sidebar":"integrations"},"integrations/document_loaders/needle":{"id":"integrations/document_loaders/needle","title":"Needle Document Loader","description":"Needle makes it easy to create your RAG pipelines with minimal effort.","sidebar":"integrations"},"integrations/document_loaders/news":{"id":"integrations/document_loaders/news","title":"News URL","description":"This covers how to load HTML news articles from a list of URLs into a document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/notion":{"id":"integrations/document_loaders/notion","title":"Notion DB 2/2","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban boards, tasks, wikis and databases. It is an all-in-one workspace for notetaking, knowledge and data management, and project and task management.","sidebar":"integrations"},"integrations/document_loaders/nuclia":{"id":"integrations/document_loaders/nuclia","title":"Nuclia","description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","sidebar":"integrations"},"integrations/document_loaders/obsidian":{"id":"integrations/document_loaders/obsidian","title":"Obsidian","description":"Obsidian is a powerful and extensible knowledge base","sidebar":"integrations"},"integrations/document_loaders/odt":{"id":"integrations/document_loaders/odt","title":"Open Document Format (ODT)","description":"The Open Document Format for Office Applications (ODF), also known as OpenDocument, is an open file format for word processing documents, spreadsheets, presentations and graphics and using ZIP-compressed XML files. It was developed with the aim of providing an open, XML-based file format specification for office applications.","sidebar":"integrations"},"integrations/document_loaders/open_city_data":{"id":"integrations/document_loaders/open_city_data","title":"Open City Data","description":"Socrata provides an API for city open data.","sidebar":"integrations"},"integrations/document_loaders/oracleadb_loader":{"id":"integrations/document_loaders/oracleadb_loader","title":"Oracle Autonomous Database","description":"Oracle autonomous database is a cloud database that uses machine learning to automate database tuning, security, backups, updates, and other routine management tasks traditionally performed by DBAs.","sidebar":"integrations"},"integrations/document_loaders/oracleai":{"id":"integrations/document_loaders/oracleai","title":"Oracle AI Vector Search: Document Processing","description":"Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads that allows you to query data based on semantics, rather than keywords.","sidebar":"integrations"},"integrations/document_loaders/org_mode":{"id":"integrations/document_loaders/org_mode","title":"Org-mode","description":"A Org Mode document is a document editing, formatting, and organizing mode, designed for notes, planning, and authoring within the free software text editor Emacs.","sidebar":"integrations"},"integrations/document_loaders/pandas_dataframe":{"id":"integrations/document_loaders/pandas_dataframe","title":"Pandas DataFrame","description":"This notebook goes over how to load data from a pandas DataFrame.","sidebar":"integrations"},"integrations/document_loaders/parsers/azure_openai_whisper_parser":{"id":"integrations/document_loaders/parsers/azure_openai_whisper_parser","title":"Azure OpenAI Whisper Parser","description":"Azure OpenAI Whisper Parser is a wrapper around the Azure OpenAI Whisper API which utilizes machine learning to transcribe audio files to english text.","sidebar":"integrations"},"integrations/document_loaders/parsers/writer_pdf_parser":{"id":"integrations/document_loaders/parsers/writer_pdf_parser","title":"Writer PDF Parser","description":"This notebook provides a quick overview for getting started with the Writer PDFParser document loader.","sidebar":"integrations"},"integrations/document_loaders/pdfminer":{"id":"integrations/document_loaders/pdfminer","title":"PDFMinerLoader","description":"This notebook provides a quick overview for getting started with PDFMiner document loader. For detailed documentation of all ModuleNameLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/pdfplumber":{"id":"integrations/document_loaders/pdfplumber","title":"PDFPlumber","description":"Like PyMuPDF, the output Documents contain detailed metadata about the PDF and its pages, and returns one document per page.","sidebar":"integrations"},"integrations/document_loaders/pebblo":{"id":"integrations/document_loaders/pebblo","title":"Pebblo Safe DocumentLoader","description":"Pebblo enables developers to safely load data and promote their Gen AI app to deployment without worrying about the organization\u2019s compliance and security requirements. The project identifies semantic topics and entities found in the loaded data and summarizes them on the UI or a PDF report.","sidebar":"integrations"},"integrations/document_loaders/polars_dataframe":{"id":"integrations/document_loaders/polars_dataframe","title":"Polars DataFrame","description":"This notebook goes over how to load data from a polars DataFrame.","sidebar":"integrations"},"integrations/document_loaders/powerscale":{"id":"integrations/document_loaders/powerscale","title":"Dell PowerScale Document Loader","description":"Dell PowerScale is an enterprise scale out storage system that hosts industry leading OneFS filesystem that can be hosted on-prem or deployed in the cloud.","sidebar":"integrations"},"integrations/document_loaders/psychic":{"id":"integrations/document_loaders/psychic","title":"Psychic","description":"This notebook covers how to load documents from Psychic. See here for more details.","sidebar":"integrations"},"integrations/document_loaders/pubmed":{"id":"integrations/document_loaders/pubmed","title":"PubMed","description":"PubMed\xae by The National Center for Biotechnology Information, National Library of Medicine comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full text content from PubMed Central and publisher web sites.","sidebar":"integrations"},"integrations/document_loaders/pull_md":{"id":"integrations/document_loaders/pull_md","title":"PullMdLoader","description":"Loader for converting URLs into Markdown using the pull.md service.","sidebar":"integrations"},"integrations/document_loaders/pymupdf":{"id":"integrations/document_loaders/pymupdf","title":"PyMuPDFLoader","description":"This notebook provides a quick overview for getting started with PyMuPDF document loader. For detailed documentation of all ModuleNameLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/pymupdf4llm":{"id":"integrations/document_loaders/pymupdf4llm","title":"PyMuPDF4LLMLoader","description":"This notebook provides a quick overview for getting started with PyMuPDF4LLM document loader. For detailed documentation of all PyMuPDF4LLMLoader features and configurations head to the GitHub repository.","sidebar":"integrations"},"integrations/document_loaders/pypdfdirectory":{"id":"integrations/document_loaders/pypdfdirectory","title":"PyPDFDirectoryLoader","description":"This loader loads all PDF files from a specific directory.","sidebar":"integrations"},"integrations/document_loaders/pypdfium2":{"id":"integrations/document_loaders/pypdfium2","title":"PyPDFium2Loader","description":"This notebook provides a quick overview for getting started with PyPDF document loader. For detailed documentation of all DocumentLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/pypdfloader":{"id":"integrations/document_loaders/pypdfloader","title":"PyPDFLoader","description":"This notebook provides a quick overview for getting started with PyPDF document loader. For detailed documentation of all DocumentLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/pyspark_dataframe":{"id":"integrations/document_loaders/pyspark_dataframe","title":"PySpark","description":"This notebook goes over how to load data from a PySpark DataFrame.","sidebar":"integrations"},"integrations/document_loaders/quip":{"id":"integrations/document_loaders/quip","title":"Quip","description":"Quip is a collaborative productivity software suite for mobile and Web. It allows groups of people to create and edit documents and spreadsheets as a group, typically for business purposes.","sidebar":"integrations"},"integrations/document_loaders/readthedocs_documentation":{"id":"integrations/document_loaders/readthedocs_documentation","title":"ReadTheDocs Documentation","description":"Read the Docs is an open-sourced free software documentation hosting platform. It generates documentation written with the Sphinx documentation generator.","sidebar":"integrations"},"integrations/document_loaders/recursive_url":{"id":"integrations/document_loaders/recursive_url","title":"Recursive URL","description":"The RecursiveUrlLoader lets you recursively scrape all child links from a root URL and parse them into Documents.","sidebar":"integrations"},"integrations/document_loaders/reddit":{"id":"integrations/document_loaders/reddit","title":"Reddit","description":"Reddit is an American social news aggregation, content rating, and discussion website.","sidebar":"integrations"},"integrations/document_loaders/roam":{"id":"integrations/document_loaders/roam","title":"Roam","description":"ROAM is a note-taking tool for networked thought, designed to create a personal knowledge base.","sidebar":"integrations"},"integrations/document_loaders/rockset":{"id":"integrations/document_loaders/rockset","title":"Rockset","description":"Rockset is a real-time analytics database which enables queries on massive, semi-structured data without operational burden. With Rockset, ingested data is queryable within one second and analytical queries against that data typically execute in milliseconds. Rockset is compute optimized, making it suitable for serving high concurrency applications in the sub-100TB range (or larger than 100s of TBs with rollups).","sidebar":"integrations"},"integrations/document_loaders/rspace":{"id":"integrations/document_loaders/rspace","title":"rspace","description":"This notebook shows how to use the RSpace document loader to import research notes and documents from RSpace Electronic","sidebar":"integrations"},"integrations/document_loaders/rss":{"id":"integrations/document_loaders/rss","title":"RSS Feeds","description":"This covers how to load HTML news articles from a list of RSS feed URLs into a document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/rst":{"id":"integrations/document_loaders/rst","title":"RST","description":"A reStructured Text (RST) file is a file format for textual data used primarily in the Python programming language community for technical documentation.","sidebar":"integrations"},"integrations/document_loaders/scrapfly":{"id":"integrations/document_loaders/scrapfly","title":"scrapfly","description":"ScrapFly","sidebar":"integrations"},"integrations/document_loaders/scrapingant":{"id":"integrations/document_loaders/scrapingant","title":"ScrapingAnt","description":"Overview","sidebar":"integrations"},"integrations/document_loaders/sitemap":{"id":"integrations/document_loaders/sitemap","title":"Sitemap","description":"Extends from the WebBaseLoader, SitemapLoader loads a sitemap from a given URL, and then scrapes and loads all pages in the sitemap, returning each page as a Document.","sidebar":"integrations"},"integrations/document_loaders/slack":{"id":"integrations/document_loaders/slack","title":"Slack","description":"Slack is an instant messaging program.","sidebar":"integrations"},"integrations/document_loaders/snowflake":{"id":"integrations/document_loaders/snowflake","title":"Snowflake","description":"This notebooks goes over how to load documents from Snowflake","sidebar":"integrations"},"integrations/document_loaders/source_code":{"id":"integrations/document_loaders/source_code","title":"Source Code","description":"This notebook covers how to load source code files using a special approach with language parsing: each top-level function and class in the code is loaded into separate documents. Any remaining code top-level code outside the already loaded functions and classes will be loaded into a separate document.","sidebar":"integrations"},"integrations/document_loaders/spider":{"id":"integrations/document_loaders/spider","title":"Spider","description":"Spider is the fastest and most affordable crawler and scraper that returns LLM-ready data.","sidebar":"integrations"},"integrations/document_loaders/spreedly":{"id":"integrations/document_loaders/spreedly","title":"Spreedly","description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","sidebar":"integrations"},"integrations/document_loaders/stripe":{"id":"integrations/document_loaders/stripe","title":"Stripe","description":"Stripe is an Irish-American financial services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"integrations"},"integrations/document_loaders/subtitle":{"id":"integrations/document_loaders/subtitle","title":"Subtitle","description":"The SubRip file format is described on the Matroska multimedia container format website as \\"perhaps the most basic of all subtitle formats.\\" SubRip (SubRip Text) files are named with the extension .srt, and contain formatted lines of plain text in groups separated by a blank line. Subtitles are numbered sequentially, starting at 1. The timecode format used is hoursseconds,milliseconds with time units fixed to two zero-padded digits and fractions fixed to three zero-padded digits (0000,000). The fractional separator used is the comma, since the program was written in France.","sidebar":"integrations"},"integrations/document_loaders/surrealdb":{"id":"integrations/document_loaders/surrealdb","title":"SurrealDB","description":"SurrealDB is an end-to-end cloud-native database designed for modern applications, including web, mobile, serverless, Jamstack, backend, and traditional applications. With SurrealDB, you can simplify your database and API infrastructure, reduce development time, and build secure, performant apps quickly and cost-effectively.","sidebar":"integrations"},"integrations/document_loaders/telegram":{"id":"integrations/document_loaders/telegram","title":"Telegram","description":"Telegram Messenger is a globally accessible freemium, cross-platform, encrypted, cloud-based and centralized instant messaging service. The application also provides optional end-to-end encrypted chats and video calling, VoIP, file sharing and several other features.","sidebar":"integrations"},"integrations/document_loaders/tencent_cos_directory":{"id":"integrations/document_loaders/tencent_cos_directory","title":"Tencent COS Directory","description":"Tencent Cloud Object Storage (COS) is a distributed","sidebar":"integrations"},"integrations/document_loaders/tencent_cos_file":{"id":"integrations/document_loaders/tencent_cos_file","title":"Tencent COS File","description":"Tencent Cloud Object Storage (COS) is a distributed","sidebar":"integrations"},"integrations/document_loaders/tensorflow_datasets":{"id":"integrations/document_loaders/tensorflow_datasets","title":"TensorFlow Datasets","description":"TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax. All datasets are exposed as tf.data.Datasets, enabling easy-to-use and high-performance input pipelines. To get started see the guide and the list of datasets.","sidebar":"integrations"},"integrations/document_loaders/tidb":{"id":"integrations/document_loaders/tidb","title":"TiDB","description":"TiDB Cloud, is a comprehensive Database-as-a-Service (DBaaS) solution, that provides dedicated and serverless options. TiDB Serverless is now integrating a built-in vector search into the MySQL landscape. With this enhancement, you can seamlessly develop AI applications using TiDB Serverless without the need for a new database or additional technical stacks. Be among the first to experience it by joining the waitlist for the private beta at https://tidb.cloud/ai.","sidebar":"integrations"},"integrations/document_loaders/tomarkdown":{"id":"integrations/document_loaders/tomarkdown","title":"2Markdown","description":"2markdown service transforms website content into structured markdown files.","sidebar":"integrations"},"integrations/document_loaders/toml":{"id":"integrations/document_loaders/toml","title":"TOML","description":"TOML is a file format for configuration files. It is intended to be easy to read and write, and is designed to map unambiguously to a dictionary. Its specification is open-source. TOML is implemented in many programming languages. The name TOML is an acronym for \\"Tom\'s Obvious, Minimal Language\\" referring to its creator, Tom Preston-Werner.","sidebar":"integrations"},"integrations/document_loaders/trello":{"id":"integrations/document_loaders/trello","title":"Trello","description":"Trello is a web-based project management and collaboration tool that allows individuals and teams to organize and track their tasks and projects. It provides a visual interface known as a \\"board\\" where users can create lists and cards to represent their tasks and activities.","sidebar":"integrations"},"integrations/document_loaders/tsv":{"id":"integrations/document_loaders/tsv","title":"TSV","description":"A tab-separated values (TSV) file is a simple, text-based file format for storing tabular data.[3] Records are separated by newlines, and values within a record are separated by tab characters.","sidebar":"integrations"},"integrations/document_loaders/twitter":{"id":"integrations/document_loaders/twitter","title":"Twitter","description":"Twitter is an online social media and social networking service.","sidebar":"integrations"},"integrations/document_loaders/unstructured_file":{"id":"integrations/document_loaders/unstructured_file","title":"Unstructured","description":"This notebook covers how to use Unstructured document loader to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more.","sidebar":"integrations"},"integrations/document_loaders/unstructured_markdown":{"id":"integrations/document_loaders/unstructured_markdown","title":"UnstructuredMarkdownLoader","description":"This notebook provides a quick overview for getting started with UnstructuredMarkdown document loader. For detailed documentation of all ModuleNameLoader features and configurations head to the API reference.","sidebar":"integrations"},"integrations/document_loaders/unstructured_pdfloader":{"id":"integrations/document_loaders/unstructured_pdfloader","title":"UnstructuredPDFLoader","description":"Overview","sidebar":"integrations"},"integrations/document_loaders/upstage":{"id":"integrations/document_loaders/upstage","title":"UpstageDocumentParseLoader","description":"This notebook covers how to get started with UpstageDocumentParseLoader.","sidebar":"integrations"},"integrations/document_loaders/url":{"id":"integrations/document_loaders/url","title":"URL","description":"This example covers how to load HTML documents from a list of URLs into the Document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/vsdx":{"id":"integrations/document_loaders/vsdx","title":"Vsdx","description":"A visio file (with extension .vsdx) is associated with Microsoft Visio, a diagram creation software. It stores information about the structure, layout, and graphical elements of a diagram. This format facilitates the creation and sharing of visualizations in areas such as business, engineering, and computer science.","sidebar":"integrations"},"integrations/document_loaders/weather":{"id":"integrations/document_loaders/weather","title":"Weather","description":"OpenWeatherMap is an open-source weather service provider","sidebar":"integrations"},"integrations/document_loaders/web_base":{"id":"integrations/document_loaders/web_base","title":"WebBaseLoader","description":"This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.","sidebar":"integrations"},"integrations/document_loaders/whatsapp_chat":{"id":"integrations/document_loaders/whatsapp_chat","title":"WhatsApp Chat","description":"WhatsApp (also called WhatsApp Messenger) is a freeware, cross-platform, centralized instant messaging (IM) and voice-over-IP (VoIP) service. It allows users to send text and voice messages, make voice and video calls, and share images, documents, user locations, and other content.","sidebar":"integrations"},"integrations/document_loaders/wikipedia":{"id":"integrations/document_loaders/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/document_loaders/xml":{"id":"integrations/document_loaders/xml","title":"UnstructuredXMLLoader","description":"This notebook provides a quick overview for getting started with UnstructuredXMLLoader document loader. The UnstructuredXMLLoader is used to load XML files. The loader works with .xml files. The page content will be the text extracted from the XML tags.","sidebar":"integrations"},"integrations/document_loaders/xorbits":{"id":"integrations/document_loaders/xorbits","title":"Xorbits Pandas DataFrame","description":"This notebook goes over how to load data from a xorbits.pandas DataFrame.","sidebar":"integrations"},"integrations/document_loaders/youtube_audio":{"id":"integrations/document_loaders/youtube_audio","title":"YouTube audio","description":"Building chat or QA applications on YouTube videos is a topic of high interest.","sidebar":"integrations"},"integrations/document_loaders/youtube_transcript":{"id":"integrations/document_loaders/youtube_transcript","title":"YouTube transcripts","description":"YouTube is an online video sharing and social media platform created by Google.","sidebar":"integrations"},"integrations/document_loaders/yt_dlp":{"id":"integrations/document_loaders/yt_dlp","title":"YoutubeLoaderDL","description":"Loader for Youtube leveraging the yt-dlp library.","sidebar":"integrations"},"integrations/document_loaders/yuque":{"id":"integrations/document_loaders/yuque","title":"Yuque","description":"Yuque is a professional cloud-based knowledge base for team collaboration in documentation.","sidebar":"integrations"},"integrations/document_loaders/zeroxpdfloader":{"id":"integrations/document_loaders/zeroxpdfloader","title":"ZeroxPDFLoader","description":"Overview","sidebar":"integrations"},"integrations/document_transformers/ai21_semantic_text_splitter":{"id":"integrations/document_transformers/ai21_semantic_text_splitter","title":"AI21SemanticTextSplitter","description":"This example goes over how to use AI21SemanticTextSplitter in LangChain.","sidebar":"integrations"},"integrations/document_transformers/beautiful_soup":{"id":"integrations/document_transformers/beautiful_soup","title":"Beautiful Soup","description":"Beautiful Soup is a Python package for parsing","sidebar":"integrations"},"integrations/document_transformers/cross_encoder_reranker":{"id":"integrations/document_transformers/cross_encoder_reranker","title":"Cross Encoder Reranker","description":"This notebook shows how to implement reranker in a retriever with your own cross encoder from Hugging Face cross encoder models or Hugging Face models that implements cross encoder function (example: BAAI/bge-reranker-base). SagemakerEndpointCrossEncoder enables you to use these HuggingFace models loaded on Sagemaker.","sidebar":"integrations"},"integrations/document_transformers/dashscope_rerank":{"id":"integrations/document_transformers/dashscope_rerank","title":"DashScope Reranker","description":"This notebook shows how to use DashScope Reranker for document compression and retrieval. DashScope is the generative AI service from Alibaba Cloud (Aliyun).","sidebar":"integrations"},"integrations/document_transformers/doctran_extract_properties":{"id":"integrations/document_transformers/doctran_extract_properties","title":"Doctran: extract properties","description":"We can extract useful features of documents using the Doctran library, which uses OpenAI\'s function calling feature to extract specific metadata.","sidebar":"integrations"},"integrations/document_transformers/doctran_interrogate_document":{"id":"integrations/document_transformers/doctran_interrogate_document","title":"Doctran: interrogate documents","description":"Documents used in a vector store knowledge base are typically stored in a narrative or conversational format. However, most user queries are in question format. If we convert documents into Q&A format before vectorizing them, we can increase the likelihood of retrieving relevant documents, and decrease the likelihood of retrieving irrelevant documents.","sidebar":"integrations"},"integrations/document_transformers/doctran_translate_document":{"id":"integrations/document_transformers/doctran_translate_document","title":"Doctran: language translation","description":"Comparing documents through embeddings has the benefit of working across multiple languages. \\"Harrison says hello\\" and \\"Harrison dice hola\\" will occupy similar positions in the vector space because they have the same meaning semantically.","sidebar":"integrations"},"integrations/document_transformers/google_cloud_vertexai_rerank":{"id":"integrations/document_transformers/google_cloud_vertexai_rerank","title":"Google Cloud Vertex AI Reranker","description":"The Vertex Search Ranking API is one of the standalone APIs in Vertex AI Agent Builder. It takes a list of documents and reranks those documents based on how relevant the documents are to a query. Compared to embeddings, which look only at the semantic similarity of a document and a query, the ranking API can give you precise scores for how well a document answers a given query. The ranking API can be used to improve the quality of search results after retrieving an initial set of candidate documents.","sidebar":"integrations"},"integrations/document_transformers/google_docai":{"id":"integrations/document_transformers/google_docai","title":"Google Cloud Document AI","description":"Document AI is a document understanding platform from Google Cloud to transform unstructured data from documents into structured data, making it easier to understand, analyze, and consume.","sidebar":"integrations"},"integrations/document_transformers/google_translate":{"id":"integrations/document_transformers/google_translate","title":"Google Translate","description":"Google Translate is a multilingual neural machine translation service developed by Google to translate text, documents and websites from one language into another.","sidebar":"integrations"},"integrations/document_transformers/html2text":{"id":"integrations/document_transformers/html2text","title":"HTML to text","description":"html2text is a Python package that converts a page of HTML into clean, easy-to-read plain ASCII text.","sidebar":"integrations"},"integrations/document_transformers/infinity_rerank":{"id":"integrations/document_transformers/infinity_rerank","title":"Infinity Reranker","description":"Infinity is a high-throughput, low-latency REST API for serving text-embeddings, reranking models and clip.","sidebar":"integrations"},"integrations/document_transformers/jina_rerank":{"id":"integrations/document_transformers/jina_rerank","title":"Jina Reranker","description":"This notebook shows how to use Jina Reranker for document compression and retrieval.","sidebar":"integrations"},"integrations/document_transformers/markdownify":{"id":"integrations/document_transformers/markdownify","title":"Markdownify","description":"markdownify is a Python package that converts HTML documents to Markdown format with customizable options for handling tags (links, images, ...), heading styles and other.","sidebar":"integrations"},"integrations/document_transformers/nuclia_transformer":{"id":"integrations/document_transformers/nuclia_transformer","title":"Nuclia","description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","sidebar":"integrations"},"integrations/document_transformers/openai_metadata_tagger":{"id":"integrations/document_transformers/openai_metadata_tagger","title":"OpenAI metadata tagger","description":"It can often be useful to tag ingested documents with structured metadata, such as the title, tone, or length of a document, to allow for a more targeted similarity search later. However, for large numbers of documents, performing this labelling process manually can be tedious.","sidebar":"integrations"},"integrations/document_transformers/openvino_rerank":{"id":"integrations/document_transformers/openvino_rerank","title":"OpenVINO Reranker","description":"OpenVINO\u2122 is an open-source toolkit for optimizing and deploying AI inference. The OpenVINO\u2122 Runtime supports various hardware devices including x86 and ARM CPUs, and Intel GPUs. It can help to boost deep learning performance in Computer Vision, Automatic Speech Recognition, Natural Language Processing and other common tasks.","sidebar":"integrations"},"integrations/document_transformers/rankllm-reranker":{"id":"integrations/document_transformers/rankllm-reranker","title":"RankLLM Reranker","description":"RankLLM offers a suite of listwise rerankers, albeit with focus on open source LLMs finetuned for the task - RankVicuna and RankZephyr being two of them.","sidebar":"integrations"},"integrations/document_transformers/volcengine_rerank":{"id":"integrations/document_transformers/volcengine_rerank","title":"Volcengine Reranker","description":"This notebook shows how to use Volcengine Reranker for document compression and retrieval. Volcengine is a cloud service platform developed by ByteDance, the parent company of TikTok.","sidebar":"integrations"},"integrations/document_transformers/voyageai-reranker":{"id":"integrations/document_transformers/voyageai-reranker","title":"VoyageAI Reranker","description":"Voyage AI provides cutting-edge embedding/vectorizations models.","sidebar":"integrations"},"integrations/graphs/amazon_neptune_open_cypher":{"id":"integrations/graphs/amazon_neptune_open_cypher","title":"Amazon Neptune with Cypher","description":"Amazon Neptune is a high-performance graph analytics and serverless database for superior scalability and availability.","sidebar":"integrations"},"integrations/graphs/amazon_neptune_sparql":{"id":"integrations/graphs/amazon_neptune_sparql","title":"Amazon Neptune with SPARQL","description":"Amazon Neptune is a high-performance graph analytics and serverless database for superior scalability and availability.","sidebar":"integrations"},"integrations/graphs/apache_age":{"id":"integrations/graphs/apache_age","title":"Apache AGE","description":"Apache AGE is a PostgreSQL extension that provides graph database functionality. AGE is an acronym for A Graph Extension, and is inspired by Bitnine\u2019s fork of PostgreSQL 10, AgensGraph, which is a multi-model database. The goal of the project is to create single storage that can handle both relational and graph model data so that users can use standard ANSI SQL along with openCypher, the Graph query language. The data elements Apache AGE stores are nodes, edges connecting them, and attributes of nodes and edges.","sidebar":"integrations"},"integrations/graphs/arangodb":{"id":"integrations/graphs/arangodb","title":"ArangoDB","description":"Open In Colab","sidebar":"integrations"},"integrations/graphs/azure_cosmosdb_gremlin":{"id":"integrations/graphs/azure_cosmosdb_gremlin","title":"Azure Cosmos DB for Apache Gremlin","description":"Azure Cosmos DB for Apache Gremlin is a graph database service that can be used to store massive graphs with billions of vertices and edges. You can query the graphs with millisecond latency and evolve the graph structure easily.","sidebar":"integrations"},"integrations/graphs/diffbot":{"id":"integrations/graphs/diffbot","title":"Diffbot","description":"Diffbot is a suite of ML-based products that make it easy to structure web data.","sidebar":"integrations"},"integrations/graphs/falkordb":{"id":"integrations/graphs/falkordb","title":"FalkorDB","description":"FalkorDB is a low-latency Graph Database that delivers knowledge to GenAI.","sidebar":"integrations"},"integrations/graphs/hugegraph":{"id":"integrations/graphs/hugegraph","title":"HugeGraph","description":"HugeGraph is a convenient, efficient, and adaptable graph database compatible with","sidebar":"integrations"},"integrations/graphs/kuzu_db":{"id":"integrations/graphs/kuzu_db","title":"Kuzu","description":"K\xf9zu is an embeddable, scalable, extremely fast graph database.","sidebar":"integrations"},"integrations/graphs/memgraph":{"id":"integrations/graphs/memgraph","title":"Memgraph","description":"Memgraph is an open-source graph database, tuned for dynamic analytics environments and compatible with Neo4j. To query the database, Memgraph uses Cypher - the most widely adopted, fully-specified, and open query language for property graph databases.","sidebar":"integrations"},"integrations/graphs/nebula_graph":{"id":"integrations/graphs/nebula_graph","title":"NebulaGraph","description":"NebulaGraph is an open-source, distributed, scalable, lightning-fast","sidebar":"integrations"},"integrations/graphs/neo4j_cypher":{"id":"integrations/graphs/neo4j_cypher","title":"Neo4j","description":"Neo4j is a graph database management system developed by Neo4j, Inc.","sidebar":"integrations"},"integrations/graphs/networkx":{"id":"integrations/graphs/networkx","title":"NetworkX","description":"NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.","sidebar":"integrations"},"integrations/graphs/ontotext":{"id":"integrations/graphs/ontotext","title":"Ontotext GraphDB","description":"Ontotext GraphDB is a graph database and knowledge discovery tool compliant with RDF and SPARQL.","sidebar":"integrations"},"integrations/graphs/rdflib_sparql":{"id":"integrations/graphs/rdflib_sparql","title":"RDFLib","description":"RDFLib is a pure Python package for working with RDF. RDFLib contains most things you need to work with RDF, including:","sidebar":"integrations"},"integrations/graphs/tigergraph":{"id":"integrations/graphs/tigergraph","title":"TigerGraph","description":"TigerGraph is a natively distributed and high-performance graph database.","sidebar":"integrations"},"integrations/llm_caching":{"id":"integrations/llm_caching","title":"Model caches","description":"This notebook covers how to cache results of individual LLM calls using different caches.","sidebar":"integrations"},"integrations/llms/ai21":{"id":"integrations/llms/ai21","title":"AI21LLM","description":"See this page for the updated ChatAI21 object.","sidebar":"integrations"},"integrations/llms/aleph_alpha":{"id":"integrations/llms/aleph_alpha","title":"Aleph Alpha","description":"The Luminous series is a family of large language models.","sidebar":"integrations"},"integrations/llms/alibabacloud_pai_eas_endpoint":{"id":"integrations/llms/alibabacloud_pai_eas_endpoint","title":"Alibaba Cloud PAI EAS","description":"Machine Learning Platform for AI of Alibaba Cloud is a machine learning or deep learning engineering platform intended for enterprises and developers. It provides easy-to-use, cost-effective, high-performance, and easy-to-scale plug-ins that can be applied to various industry scenarios. With over 140 built-in optimization algorithms, Machine Learning Platform for AI provides whole-process AI engineering capabilities including data labeling (PAI-iTAG), model building (PAI-Designer and PAI-DSW), model training (PAI-DLC), compilation optimization, and inference deployment (PAI-EAS). PAI-EAS supports different types of hardware resources, including CPUs and GPUs, and features high throughput and low latency. It allows you to deploy large-scale complex models with a few clicks and perform elastic scale-ins and scale-outs in real time. It also provides a comprehensive O&M and monitoring system.","sidebar":"integrations"},"integrations/llms/amazon_api_gateway":{"id":"integrations/llms/amazon_api_gateway","title":"Amazon API Gateway","description":"Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any >scale. APIs act as the \\"front door\\" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and >WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.","sidebar":"integrations"},"integrations/llms/anthropic":{"id":"integrations/llms/anthropic","title":"AnthropicLLM","description":"You are currently on a page documenting the use of Anthropic legacy Claude 2 models as text completion models. The latest and most popular Anthropic models are chat completion models, and the text completion models have been deprecated.","sidebar":"integrations"},"integrations/llms/anyscale":{"id":"integrations/llms/anyscale","title":"Anyscale","description":"Anyscale is a fully-managed Ray platform, on which you can build, deploy, and manage scalable AI and Python applications","sidebar":"integrations"},"integrations/llms/aphrodite":{"id":"integrations/llms/aphrodite","title":"Aphrodite Engine","description":"Aphrodite is the open-source large-scale inference engine designed to serve thousands of users on the PygmalionAI website.","sidebar":"integrations"},"integrations/llms/arcee":{"id":"integrations/llms/arcee","title":"Arcee","description":"This notebook demonstrates how to use the Arcee class for generating text using Arcee\'s Domain Adapted Language Models (DALMs).","sidebar":"integrations"},"integrations/llms/azure_ml":{"id":"integrations/llms/azure_ml","title":"Azure ML","description":"Azure ML is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides foundational and general purpose models from different providers.","sidebar":"integrations"},"integrations/llms/azure_openai":{"id":"integrations/llms/azure_openai","title":"Azure OpenAI","description":"You are currently on a page documenting the use of Azure OpenAI text completion models. The latest and most popular Azure OpenAI models are chat completion models.","sidebar":"integrations"},"integrations/llms/baichuan":{"id":"integrations/llms/baichuan","title":"Baichuan LLM","description":"Baichuan Inc. (https Efficiency, Health, and Happiness.","sidebar":"integrations"},"integrations/llms/baidu_qianfan_endpoint":{"id":"integrations/llms/baidu_qianfan_endpoint","title":"Baidu Qianfan","description":"Baidu AI Cloud Qianfan Platform is a one-stop large model development and service operation platform for enterprise developers. Qianfan not only provides including the model of Wenxin Yiyan (ERNIE-Bot) and the third-party open-source models, but also provides various AI development tools and the whole set of development environment, which facilitates customers to use and develop large model applications easily.","sidebar":"integrations"},"integrations/llms/banana":{"id":"integrations/llms/banana","title":"Banana","description":"Banana is focused on building the machine learning infrastructure.","sidebar":"integrations"},"integrations/llms/baseten":{"id":"integrations/llms/baseten","title":"Baseten","description":"Baseten is a Provider in the LangChain ecosystem that implements the LLMs component.","sidebar":"integrations"},"integrations/llms/beam":{"id":"integrations/llms/beam","title":"Beam","description":"Calls the Beam API wrapper to deploy and make subsequent calls to an instance of the gpt2 LLM in a cloud deployment. Requires installation of the Beam library and registration of Beam Client ID and Client Secret. By calling the wrapper an instance of the model is created and run, with returned text relating to the prompt. Additional calls can then be made by directly calling the Beam API.","sidebar":"integrations"},"integrations/llms/bedrock":{"id":"integrations/llms/bedrock","title":"Bedrock","description":"You are currently on a page documenting the use of Amazon Bedrock models as text completion models. Many popular models available on Bedrock are chat completion models.","sidebar":"integrations"},"integrations/llms/bittensor":{"id":"integrations/llms/bittensor","title":"Bittensor","description":"Bittensor is a mining network, similar to Bitcoin, that includes built-in incentives designed to encourage miners to contribute compute + knowledge.","sidebar":"integrations"},"integrations/llms/cerebriumai":{"id":"integrations/llms/cerebriumai","title":"CerebriumAI","description":"Cerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.","sidebar":"integrations"},"integrations/llms/chatglm":{"id":"integrations/llms/chatglm","title":"ChatGLM","description":"ChatGLM-6B is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).","sidebar":"integrations"},"integrations/llms/clarifai":{"id":"integrations/llms/clarifai","title":"Clarifai","description":"Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference.","sidebar":"integrations"},"integrations/llms/cloudflare_workersai":{"id":"integrations/llms/cloudflare_workersai","title":"Cloudflare Workers AI","description":"Cloudflare AI documentation listed all generative text models available.","sidebar":"integrations"},"integrations/llms/cohere":{"id":"integrations/llms/cohere","title":"Cohere","description":"You are currently on a page documenting the use of Cohere models as text completion models. Many popular Cohere models are chat completion models.","sidebar":"integrations"},"integrations/llms/ctransformers":{"id":"integrations/llms/ctransformers","title":"C Transformers","description":"The C Transformers library provides Python bindings for GGML models.","sidebar":"integrations"},"integrations/llms/ctranslate2":{"id":"integrations/llms/ctranslate2","title":"CTranslate2","description":"CTranslate2 is a C++ and Python library for efficient inference with Transformer models.","sidebar":"integrations"},"integrations/llms/databricks":{"id":"integrations/llms/databricks","title":"Databricks","description":"Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.","sidebar":"integrations"},"integrations/llms/deepinfra":{"id":"integrations/llms/deepinfra","title":"DeepInfra","description":"DeepInfra is a serverless inference as a service that provides access to a variety of LLMs and embeddings models. This notebook goes over how to use LangChain with DeepInfra for language models.","sidebar":"integrations"},"integrations/llms/deepsparse":{"id":"integrations/llms/deepsparse","title":"DeepSparse","description":"This page covers how to use the DeepSparse inference runtime within LangChain.","sidebar":"integrations"},"integrations/llms/edenai":{"id":"integrations/llms/edenai","title":"Eden AI","description":"Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)","sidebar":"integrations"},"integrations/llms/exllamav2":{"id":"integrations/llms/exllamav2","title":"ExLlamaV2","description":"ExLlamav2 is a fast inference library for running LLMs locally on modern consumer-class GPUs.","sidebar":"integrations"},"integrations/llms/fireworks":{"id":"integrations/llms/fireworks","title":"Fireworks","description":"You are currently on a page documenting the use of Fireworks models as text completion models. Many popular Fireworks models are chat completion models.","sidebar":"integrations"},"integrations/llms/forefrontai":{"id":"integrations/llms/forefrontai","title":"ForefrontAI","description":"The Forefront platform gives you the ability to fine-tune and use open-source large language models.","sidebar":"integrations"},"integrations/llms/friendli":{"id":"integrations/llms/friendli","title":"Friendli","description":"Friendli enhances AI application performance and optimizes cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads.","sidebar":"integrations"},"integrations/llms/gigachat":{"id":"integrations/llms/gigachat","title":"GigaChat","description":"This notebook shows how to use LangChain with GigaChat.","sidebar":"integrations"},"integrations/llms/google_ai":{"id":"integrations/llms/google_ai","title":"Google AI","description":"You are currently on a page documenting the use of Google models as text completion models. Many popular Google models are chat completion models.","sidebar":"integrations"},"integrations/llms/google_vertex_ai_palm":{"id":"integrations/llms/google_vertex_ai_palm","title":"Google Cloud Vertex AI","description":"You are currently on a page documenting the use of Google Vertex text completion models. Many Google models are chat completion models.","sidebar":"integrations"},"integrations/llms/gooseai":{"id":"integrations/llms/gooseai","title":"GooseAI","description":"GooseAI is a fully managed NLP-as-a-Service, delivered via API. GooseAI provides access to these models.","sidebar":"integrations"},"integrations/llms/gpt4all":{"id":"integrations/llms/gpt4all","title":"GPT4All","description":"GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue.","sidebar":"integrations"},"integrations/llms/gradient":{"id":"integrations/llms/gradient","title":"Gradient","description":"Gradient allows to fine tune and get completions on LLMs with a simple web API.","sidebar":"integrations"},"integrations/llms/huggingface_endpoint":{"id":"integrations/llms/huggingface_endpoint","title":"Huggingface Endpoints","description":"The Hugging Face Hub is a platform with over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.","sidebar":"integrations"},"integrations/llms/huggingface_pipelines":{"id":"integrations/llms/huggingface_pipelines","title":"Hugging Face Local Pipelines","description":"Hugging Face models can be run locally through the HuggingFacePipeline class.","sidebar":"integrations"},"integrations/llms/ibm_watsonx":{"id":"integrations/llms/ibm_watsonx","title":"IBM watsonx.ai","description":"WatsonxLLM is a wrapper for IBM watsonx.ai foundation models.","sidebar":"integrations"},"integrations/llms/index":{"id":"integrations/llms/index","title":"LLMs","description":"You are currently on a page documenting the use of text completion models. Many of the latest and most popular models are chat completion models.","sidebar":"integrations"},"integrations/llms/ipex_llm":{"id":"integrations/llms/ipex_llm","title":"IPEX-LLM","description":"IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latency.","sidebar":"integrations"},"integrations/llms/javelin":{"id":"integrations/llms/javelin","title":"Javelin AI Gateway Tutorial","description":"This Jupyter Notebook will explore how to interact with the Javelin AI Gateway using the Python SDK.","sidebar":"integrations"},"integrations/llms/jsonformer_experimental":{"id":"integrations/llms/jsonformer_experimental","title":"JSONFormer","description":"JSONFormer is a library that wraps local Hugging Face pipeline models for structured decoding of a subset of the JSON Schema.","sidebar":"integrations"},"integrations/llms/koboldai":{"id":"integrations/llms/koboldai","title":"KoboldAI API","description":"KoboldAI is a \\"a browser-based front-end for AI-assisted writing with multiple local & remote AI models...\\". It has a public and local API that is able to be used in langchain.","sidebar":"integrations"},"integrations/llms/konko":{"id":"integrations/llms/konko","title":"Konko","description":"Konko API is a fully managed Web API designed to help application developers:","sidebar":"integrations"},"integrations/llms/layerup_security":{"id":"integrations/llms/layerup_security","title":"Layerup Security","description":"The Layerup Security integration allows you to secure your calls to any LangChain LLM, LLM chain or LLM agent. The LLM object wraps around any existing LLM object, allowing for a secure layer between your users and your LLMs.","sidebar":"integrations"},"integrations/llms/llamacpp":{"id":"integrations/llms/llamacpp","title":"Llama.cpp","description":"llama-cpp-python is a Python binding for llama.cpp.","sidebar":"integrations"},"integrations/llms/llamafile":{"id":"integrations/llms/llamafile","title":"Llamafile","description":"Llamafile lets you distribute and run LLMs with a single file.","sidebar":"integrations"},"integrations/llms/lmformatenforcer_experimental":{"id":"integrations/llms/lmformatenforcer_experimental","title":"LM Format Enforcer","description":"LM Format Enforcer is a library that enforces the output format of language models by filtering tokens.","sidebar":"integrations"},"integrations/llms/manifest":{"id":"integrations/llms/manifest","title":"Manifest","description":"This notebook goes over how to use Manifest and LangChain.","sidebar":"integrations"},"integrations/llms/minimax":{"id":"integrations/llms/minimax","title":"Minimax","description":"Minimax is a Chinese startup that provides natural language processing models for companies and individuals.","sidebar":"integrations"},"integrations/llms/mlx_pipelines":{"id":"integrations/llms/mlx_pipelines","title":"MLX Local Pipelines","description":"MLX models can be run locally through the MLXPipeline class.","sidebar":"integrations"},"integrations/llms/modal":{"id":"integrations/llms/modal","title":"Modal","description":"The Modal cloud platform provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer.","sidebar":"integrations"},"integrations/llms/modelscope_endpoint":{"id":"integrations/llms/modelscope_endpoint","title":"ModelScopeEndpoint","description":"ModelScope (Home | GitHub) is built upon the notion of \u201cModel-as-a-Service\u201d (MaaS). It seeks to bring together most advanced machine learning models from the AI community, and streamlines the process of leveraging AI models in real-world applications. The core ModelScope library open-sourced in this repository provides the interfaces and implementations that allow developers to perform model inference, training and evaluation. This will help you get started with ModelScope completion models (LLMs) using LangChain.","sidebar":"integrations"},"integrations/llms/moonshot":{"id":"integrations/llms/moonshot","title":"MoonshotChat","description":"Moonshot is a Chinese startup that provides LLM service for companies and individuals.","sidebar":"integrations"},"integrations/llms/mosaicml":{"id":"integrations/llms/mosaicml","title":"MosaicML","description":"MosaicML offers a managed inference service. You can either use a variety of open-source models, or deploy your own.","sidebar":"integrations"},"integrations/llms/nlpcloud":{"id":"integrations/llms/nlpcloud","title":"NLP Cloud","description":"The NLP Cloud serves high performance pre-trained or custom models for NER, sentiment-analysis, classification, summarization, paraphrasing, grammar and spelling correction, keywords and keyphrases extraction, chatbot, product description and ad generation, intent classification, text generation, image generation, blog post generation, code generation, question answering, automatic speech recognition, machine translation, language detection, semantic search, semantic similarity, tokenization, POS tagging, embeddings, and dependency parsing. It is ready for production, served through a REST API.","sidebar":"integrations"},"integrations/llms/nvidia_ai_endpoints":{"id":"integrations/llms/nvidia_ai_endpoints","title":"NVIDIA","description":"This will help you getting started with NVIDIA models. For detailed documentation of all NVIDIA features and configurations head to the API reference.","sidebar":"integrations"},"integrations/llms/oci_generative_ai":{"id":"integrations/llms/oci_generative_ai","title":"oci_generative_ai","description":"Oracle Cloud Infrastructure Generative AI","sidebar":"integrations"},"integrations/llms/oci_model_deployment_endpoint":{"id":"integrations/llms/oci_model_deployment_endpoint","title":"OCI Data Science Model Deployment Endpoint","description":"OCI Data Science is a fully managed and serverless platform for data science teams to build, train, and manage machine learning models in the Oracle Cloud Infrastructure.","sidebar":"integrations"},"integrations/llms/octoai":{"id":"integrations/llms/octoai","title":"OctoAI","description":"OctoAI offers easy access to efficient compute and enables users to integrate their choice of AI models into applications. The OctoAI compute service helps you run, tune, and scale AI applications easily.","sidebar":"integrations"},"integrations/llms/ollama":{"id":"integrations/llms/ollama","title":"OllamaLLM","description":"You are currently on a page documenting the use of Ollama models as text completion models. Many popular Ollama models are chat completion models.","sidebar":"integrations"},"integrations/llms/opaqueprompts":{"id":"integrations/llms/opaqueprompts","title":"OpaquePrompts","description":"OpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.","sidebar":"integrations"},"integrations/llms/openai":{"id":"integrations/llms/openai","title":"OpenAI","description":"You are currently on a page documenting the use of OpenAI text completion models. The latest and most popular OpenAI models are chat completion models.","sidebar":"integrations"},"integrations/llms/openllm":{"id":"integrations/llms/openllm","title":"OpenLLM","description":"\ud83e\uddbe OpenLLM lets developers run any open-source LLMs as OpenAI-compatible API endpoints with a single command.","sidebar":"integrations"},"integrations/llms/openlm":{"id":"integrations/llms/openlm","title":"OpenLM","description":"OpenLM is a zero-dependency OpenAI-compatible LLM provider that can call different inference endpoints directly via HTTP.","sidebar":"integrations"},"integrations/llms/openvino":{"id":"integrations/llms/openvino","title":"OpenVINO","description":"OpenVINO\u2122 is an open-source toolkit for optimizing and deploying AI inference. OpenVINO\u2122 Runtime can enable running the same model optimized across various hardware devices. Accelerate your deep learning performance across use cases like: language + LLMs, computer vision, automatic speech recognition, and more.","sidebar":"integrations"},"integrations/llms/outlines":{"id":"integrations/llms/outlines","title":"Outlines","description":"This will help you getting started with Outlines LLM. For detailed documentation of all Outlines features and configurations head to the API reference.","sidebar":"integrations"},"integrations/llms/petals":{"id":"integrations/llms/petals","title":"Petals","description":"Petals runs 100B+ language models at home, BitTorrent-style.","sidebar":"integrations"},"integrations/llms/pipelineai":{"id":"integrations/llms/pipelineai","title":"PipelineAI","description":"PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.","sidebar":"integrations"},"integrations/llms/pipeshift":{"id":"integrations/llms/pipeshift","title":"Pipeshift","description":"This will help you get started with Pipeshift completion models (LLMs) using LangChain. For detailed documentation on Pipeshift features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/llms/predibase":{"id":"integrations/llms/predibase","title":"Predibase","description":"Predibase allows you to train, fine-tune, and deploy any ML model\u2014from linear regression to large language model.","sidebar":"integrations"},"integrations/llms/predictionguard":{"id":"integrations/llms/predictionguard","title":"PredictionGuard","description":"Prediction Guard is a secure, scalable GenAI platform that safeguards sensitive data, prevents common AI malfunctions, and runs on affordable hardware.","sidebar":"integrations"},"integrations/llms/promptlayer_openai":{"id":"integrations/llms/promptlayer_openai","title":"PromptLayer OpenAI","description":"PromptLayer is the first platform that allows you to track, manage, and share your GPT prompt engineering. PromptLayer acts a middleware between your code and OpenAI\u2019s python library.","sidebar":"integrations"},"integrations/llms/rellm_experimental":{"id":"integrations/llms/rellm_experimental","title":"RELLM","description":"RELLM is a library that wraps local Hugging Face pipeline models for structured decoding.","sidebar":"integrations"},"integrations/llms/replicate":{"id":"integrations/llms/replicate","title":"Replicate","description":"Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you\'re building your own machine learning models, Replicate makes it easy to deploy them at scale.","sidebar":"integrations"},"integrations/llms/runhouse":{"id":"integrations/llms/runhouse","title":"Runhouse","description":"Runhouse allows remote compute and data across environments and users. See the Runhouse docs.","sidebar":"integrations"},"integrations/llms/sagemaker":{"id":"integrations/llms/sagemaker","title":"SageMakerEndpoint","description":"Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.","sidebar":"integrations"},"integrations/llms/sambanovacloud":{"id":"integrations/llms/sambanovacloud","title":"SambaNovaCloud","description":"SambaNova\'s SambaNova Cloud is a platform for performing inference with open-source models","sidebar":"integrations"},"integrations/llms/sambastudio":{"id":"integrations/llms/sambastudio","title":"SambaStudio","description":"SambaNova\'s Sambastudio is a platform that allows you to train, run batch inference jobs, and deploy online inference endpoints to run open source models that you fine tuned yourself.","sidebar":"integrations"},"integrations/llms/solar":{"id":"integrations/llms/solar","title":"Solar","description":"This community integration is deprecated. You should use ChatUpstage instead to access Solar LLM via the chat model connector.","sidebar":"integrations"},"integrations/llms/sparkllm":{"id":"integrations/llms/sparkllm","title":"SparkLLM","description":"SparkLLM is a large-scale cognitive model independently developed by iFLYTEK.","sidebar":"integrations"},"integrations/llms/stochasticai":{"id":"integrations/llms/stochasticai","title":"StochasticAI","description":"Stochastic Acceleration Platform aims to simplify the life cycle of a Deep Learning model. From uploading and versioning the model, through training, compression and acceleration to putting it into production.","sidebar":"integrations"},"integrations/llms/symblai_nebula":{"id":"integrations/llms/symblai_nebula","title":"Nebula (Symbl.ai)","description":"Nebula is a large language model (LLM) built by Symbl.ai. It is trained to perform generative tasks on human conversations. Nebula excels at modeling the nuanced details of a conversation and performing tasks on the conversation.","sidebar":"integrations"},"integrations/llms/textgen":{"id":"integrations/llms/textgen","title":"TextGen","description":"GitHub:oobabooga/text-generation-webui A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.","sidebar":"integrations"},"integrations/llms/titan_takeoff":{"id":"integrations/llms/titan_takeoff","title":"Titan Takeoff","description":"TitanML helps businesses build and deploy better, smaller, cheaper, and faster NLP models through our training, compression, and inference optimization platform.","sidebar":"integrations"},"integrations/llms/together":{"id":"integrations/llms/together","title":"Together AI","description":"You are currently on a page documenting the use of Together AI models as text completion models. Many popular Together AI models are chat completion models.","sidebar":"integrations"},"integrations/llms/tongyi":{"id":"integrations/llms/tongyi","title":"Tongyi Qwen","description":"Tongyi Qwen is a large-scale language model developed by Alibaba\'s Damo Academy. It is capable of understanding user intent through natural language understanding and semantic analysis, based on user input in natural language. It provides services and assistance to users in different domains and tasks. By providing clear and detailed instructions, you can obtain results that better align with your expectations.","sidebar":"integrations"},"integrations/llms/vllm":{"id":"integrations/llms/vllm","title":"vLLM","description":"vLLM is a fast and easy-to-use library for LLM inference and serving, offering:","sidebar":"integrations"},"integrations/llms/volcengine_maas":{"id":"integrations/llms/volcengine_maas","title":"Volc Engine Maas","description":"This notebook provides you with a guide on how to get started with Volc Engine\'s MaaS llm models.","sidebar":"integrations"},"integrations/llms/weight_only_quantization":{"id":"integrations/llms/weight_only_quantization","title":"Intel Weight-Only Quantization","description":"Weight-Only Quantization for Huggingface Models with Intel Extension for Transformers Pipelines","sidebar":"integrations"},"integrations/llms/writer":{"id":"integrations/llms/writer","title":"Writer LLM","description":"Writer is a platform to generate different language content.","sidebar":"integrations"},"integrations/llms/xinference":{"id":"integrations/llms/xinference","title":"Xorbits Inference (Xinference)","description":"Xinference is a powerful and versatile library designed to serve LLMs,","sidebar":"integrations"},"integrations/llms/yandex":{"id":"integrations/llms/yandex","title":"YandexGPT","description":"This notebook goes over how to use Langchain with YandexGPT.","sidebar":"integrations"},"integrations/llms/yi":{"id":"integrations/llms/yi","title":"Yi","description":"01.AI, founded by Dr. Kai-Fu Lee, is a global company at the forefront of AI 2.0. They offer cutting-edge large language models, including the Yi series, which range from 6B to hundreds of billions of parameters. 01.AI also provides multimodal models, an open API platform, and open-source options like Yi-34B/9B/6B and Yi-VL.","sidebar":"integrations"},"integrations/llms/yuan2":{"id":"integrations/llms/yuan2","title":"Yuan2.0","description":"Yuan2.0 is a new generation Fundamental Large Language Model developed by IEIT System. We have published all three models, Yuan 2.0-102B, Yuan 2.0-51B, and Yuan 2.0-2B. And we provide relevant scripts for pretraining, fine-tuning, and inference services for other developers. Yuan2.0 is based on Yuan1.0, utilizing a wider range of high-quality pre training data and instruction fine-tuning datasets to enhance the model\'s understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects.","sidebar":"integrations"},"integrations/memory/astradb_chat_message_history":{"id":"integrations/memory/astradb_chat_message_history","title":"Astra DB","description":"DataStax Astra DB is a serverless vector-capable database built on Cassandra and made conveniently available through an easy-to-use JSON API.","sidebar":"integrations"},"integrations/memory/aws_dynamodb":{"id":"integrations/memory/aws_dynamodb","title":"AWS DynamoDB","description":"Amazon AWS DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability.","sidebar":"integrations"},"integrations/memory/cassandra_chat_message_history":{"id":"integrations/memory/cassandra_chat_message_history","title":"Cassandra","description":"Apache Cassandra\xae is a NoSQL, row-oriented, highly scalable and highly available database, well suited for storing large amounts of data.","sidebar":"integrations"},"integrations/memory/couchbase_chat_message_history":{"id":"integrations/memory/couchbase_chat_message_history","title":"Couchbase","description":"Couchbase is an award-winning distributed NoSQL cloud database that delivers unmatched versatility, performance, scalability, and financial value for all of your cloud, mobile, AI, and edge computing applications. Couchbase embraces AI with coding assistance for developers and vector search for their applications.","sidebar":"integrations"},"integrations/memory/elasticsearch_chat_message_history":{"id":"integrations/memory/elasticsearch_chat_message_history","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library.","sidebar":"integrations"},"integrations/memory/falkordb_chat_message_history":{"id":"integrations/memory/falkordb_chat_message_history","title":"FalkorDB","description":"FalkorDB is an open-source graph database management system, renowned for its efficient management of highly connected data. Unlike traditional databases that store data in tables, FalkorDB uses a graph structure with nodes, edges, and properties to represent and store data. This design allows for high-performance queries on complex data relationships.","sidebar":"integrations"},"integrations/memory/google_alloydb":{"id":"integrations/memory/google_alloydb","title":"Google AlloyDB for PostgreSQL","description":"Google Cloud AlloyDB for PostgreSQL is a fully managed PostgreSQL compatible database service for your most demanding enterprise workloads. AlloyDB combines the best of Google Cloud with PostgreSQL, for superior performance, scale, and availability. Extend your database application to build AI-powered experiences leveraging AlloyDB Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_bigtable":{"id":"integrations/memory/google_bigtable","title":"Google Bigtable","description":"Google Cloud Bigtable is a key-value and wide-column store, ideal for fast access to structured, semi-structured, or unstructured data. Extend your database application to build AI-powered experiences leveraging Bigtable\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_el_carro":{"id":"integrations/memory/google_el_carro","title":"Google El Carro Oracle","description":"Google Cloud El Carro Oracle offers a way to run Oracle databases in Kubernetes as a portable, open source, community-driven, no vendor lock-in container orchestration system. El Carro provides a powerful declarative API for comprehensive and consistent configuration and deployment as well as for real-time operations and monitoring. Extend your Oracle database\'s capabilities to build AI-powered experiences by leveraging the El Carro Langchain integration.","sidebar":"integrations"},"integrations/memory/google_firestore":{"id":"integrations/memory/google_firestore","title":"Google Firestore (Native Mode)","description":"Google Cloud Firestore is a serverless document-oriented database that scales to meet any demand. Extend your database application to build AI-powered experiences leveraging Firestore\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_firestore_datastore":{"id":"integrations/memory/google_firestore_datastore","title":"Google Firestore (Datastore Mode)","description":"Google Cloud Firestore in Datastore is a serverless document-oriented database that scales to meet any demand. Extend your database application to build AI-powered experiences leveraging Datastore\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_memorystore_redis":{"id":"integrations/memory/google_memorystore_redis","title":"Google Memorystore for Redis","description":"Google Cloud Memorystore for Redis is a fully-managed service that is powered by the Redis in-memory data store to build application caches that provide sub-millisecond data access. Extend your database application to build AI-powered experiences leveraging Memorystore for Redis\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_spanner":{"id":"integrations/memory/google_spanner","title":"Google Spanner","description":"Google Cloud Spanner is a highly scalable database that combines unlimited scalability with relational semantics, such as secondary indexes, strong consistency, schemas, and SQL providing 99.999% availability in one easy solution.","sidebar":"integrations"},"integrations/memory/google_sql_mssql":{"id":"integrations/memory/google_sql_mssql","title":"Google SQL for SQL Server","description":"Google Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers MySQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_sql_mysql":{"id":"integrations/memory/google_sql_mysql","title":"Google SQL for MySQL","description":"Cloud Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers MySQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/google_sql_pg":{"id":"integrations/memory/google_sql_pg","title":"Google SQL for PostgreSQL","description":"Google Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers MySQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/memory/kafka_chat_message_history":{"id":"integrations/memory/kafka_chat_message_history","title":"Kafka","description":"Kafka is a distributed messaging system that is used to publish and subscribe to streams of records.","sidebar":"integrations"},"integrations/memory/momento_chat_message_history":{"id":"integrations/memory/momento_chat_message_history","title":"Momento Cache","description":"Momento Cache is the world\'s first truly serverless caching service. It provides instant elasticity, scale-to-zero","sidebar":"integrations"},"integrations/memory/mongodb_chat_message_history":{"id":"integrations/memory/mongodb_chat_message_history","title":"MongoDB","description":"MongoDB is a source-available cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with optional schemas.","sidebar":"integrations"},"integrations/memory/motorhead_memory":{"id":"integrations/memory/motorhead_memory","title":"Mot\xf6rhead","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.","sidebar":"integrations"},"integrations/memory/neo4j_chat_message_history":{"id":"integrations/memory/neo4j_chat_message_history","title":"Neo4j","description":"Neo4j is an open-source graph database management system, renowned for its efficient management of highly connected data. Unlike traditional databases that store data in tables, Neo4j uses a graph structure with nodes, edges, and properties to represent and store data. This design allows for high-performance queries on complex data relationships.","sidebar":"integrations"},"integrations/memory/postgres_chat_message_history":{"id":"integrations/memory/postgres_chat_message_history","title":"Postgres","description":"PostgreSQL also known as Postgres, is a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.","sidebar":"integrations"},"integrations/memory/redis_chat_message_history":{"id":"integrations/memory/redis_chat_message_history","title":"Redis Chat Message History","description":"Redis (Remote Dictionary Server) is an open-source in-memory storage, used as a distributed, in-memory key\u2013value database, cache and message broker, with optional durability. Redis offers low-latency reads and writes. Redis is the most popular NoSQL database, and one of the most popular databases overall.","sidebar":"integrations"},"integrations/memory/remembrall":{"id":"integrations/memory/remembrall","title":"Remembrall","description":"This page covers how to use the Remembrall ecosystem within LangChain.","sidebar":"integrations"},"integrations/memory/rockset_chat_message_history":{"id":"integrations/memory/rockset_chat_message_history","title":"Rockset","description":"Rockset is a real-time analytics database service for serving low latency, high concurrency analytical queries at scale. It builds a Converged Index\u2122 on structured and semi-structured data with an efficient store for vector embeddings. Its support for running SQL on schemaless data makes it a perfect choice for running vector search with metadata filters.","sidebar":"integrations"},"integrations/memory/singlestoredb_chat_message_history":{"id":"integrations/memory/singlestoredb_chat_message_history","title":"SingleStoreDB","description":"This notebook goes over how to use SingleStoreDB to store chat message history.","sidebar":"integrations"},"integrations/memory/sql_chat_message_history":{"id":"integrations/memory/sql_chat_message_history","title":"SQL (SQLAlchemy)","description":"Structured Query Language (SQL) is a domain-specific language used in programming and designed for managing data held in a relational database management system (RDBMS), or for stream processing in a relational data stream management system (RDSMS). It is particularly useful in handling structured data, i.e., data incorporating relations among entities and variables.","sidebar":"integrations"},"integrations/memory/sqlite":{"id":"integrations/memory/sqlite","title":"SQLite","description":"SQLite is a database engine written in the C programming language. It is not a standalone app; rather, it is a library that software developers embed in their apps. As such, it belongs to the family of embedded databases. It is the most widely deployed database engine, as it is used by several of the top web browsers, operating systems, mobile phones, and other embedded systems.","sidebar":"integrations"},"integrations/memory/streamlit_chat_message_history":{"id":"integrations/memory/streamlit_chat_message_history","title":"Streamlit","description":"Streamlit is an open-source Python library that makes it easy to create and share beautiful,","sidebar":"integrations"},"integrations/memory/tidb_chat_message_history":{"id":"integrations/memory/tidb_chat_message_history","title":"TiDB","description":"TiDB Cloud, is a comprehensive Database-as-a-Service (DBaaS) solution, that provides dedicated and serverless options. TiDB Serverless is now integrating a built-in vector search into the MySQL landscape. With this enhancement, you can seamlessly develop AI applications using TiDB Serverless without the need for a new database or additional technical stacks. Create a free TiDB Serverless cluster and start using the vector search feature at https://pingcap.com/ai.","sidebar":"integrations"},"integrations/memory/upstash_redis_chat_message_history":{"id":"integrations/memory/upstash_redis_chat_message_history","title":"Upstash Redis","description":"Upstash is a provider of the serverless Redis, Kafka, and QStash APIs.","sidebar":"integrations"},"integrations/memory/xata_chat_message_history":{"id":"integrations/memory/xata_chat_message_history","title":"Xata","description":"Xata is a serverless data platform, based on PostgreSQL and Elasticsearch. It provides a Python SDK for interacting with your database, and a UI for managing your data. With the XataChatMessageHistory class, you can use Xata databases for longer-term persistence of chat sessions.","sidebar":"integrations"},"integrations/memory/zep_cloud_chat_message_history":{"id":"integrations/memory/zep_cloud_chat_message_history","title":"ZepCloudChatMessageHistory","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences.","sidebar":"integrations"},"integrations/memory/zep_memory":{"id":"integrations/memory/zep_memory","title":"Zep Open Source Memory","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences.","sidebar":"integrations"},"integrations/memory/zep_memory_cloud":{"id":"integrations/memory/zep_memory_cloud","title":"Zep Cloud Memory","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences.","sidebar":"integrations"},"integrations/providers/abso":{"id":"integrations/providers/abso","title":"Abso","description":"Abso is an open-source LLM proxy that automatically routes requests between fast and slow models based on prompt complexity. It uses various heuristics to chose the proper model. It\'s very fast and has low latency.","sidebar":"integrations"},"integrations/providers/acreom":{"id":"integrations/providers/acreom","title":"Acreom","description":"acreom is a dev-first knowledge base with tasks running on local markdown files.","sidebar":"integrations"},"integrations/providers/activeloop_deeplake":{"id":"integrations/providers/activeloop_deeplake","title":"Activeloop Deep Lake","description":"Activeloop Deep Lake is a data lake for Deep Learning applications, allowing you to use it","sidebar":"integrations"},"integrations/providers/ads4gpts":{"id":"integrations/providers/ads4gpts","title":"ADS4GPTs","description":"ADS4GPTs is building the open monetization backbone of the AI-Native internet. It helps AI applications monetize through advertising with a UX and Privacy first approach.","sidebar":"integrations"},"integrations/providers/aerospike":{"id":"integrations/providers/aerospike","title":"Aerospike","description":"Aerospike is a high-performance, distributed database known for its speed and scalability, now with support for vector storage and search, enabling retrieval and search of embedding vectors for machine learning and AI applications.","sidebar":"integrations"},"integrations/providers/agentql":{"id":"integrations/providers/agentql","title":"AgentQL","description":"AgentQL provides web interaction and structured data extraction from any web page using an AgentQL query or a Natural Language prompt. AgentQL can be used across multiple languages and web pages without breaking over time and change.","sidebar":"integrations"},"integrations/providers/ai21":{"id":"integrations/providers/ai21","title":"AI21 Labs","description":"AI21 Labs is a company specializing in Natural","sidebar":"integrations"},"integrations/providers/aim_tracking":{"id":"integrations/providers/aim_tracking","title":"Aim","description":"Aim makes it super easy to visualize and debug LangChain executions. Aim tracks inputs and outputs of LLMs and tools, as well as actions of agents.","sidebar":"integrations"},"integrations/providers/ainetwork":{"id":"integrations/providers/ainetwork","title":"AINetwork","description":"AI Network is a layer 1 blockchain designed to accommodate","sidebar":"integrations"},"integrations/providers/airbyte":{"id":"integrations/providers/airbyte","title":"Airbyte","description":"Airbyte is a data integration platform for ELT pipelines from APIs,","sidebar":"integrations"},"integrations/providers/airtable":{"id":"integrations/providers/airtable","title":"Airtable","description":"Airtable is a cloud collaboration service.","sidebar":"integrations"},"integrations/providers/alchemy":{"id":"integrations/providers/alchemy","title":"Alchemy","description":"Alchemy is the platform to build blockchain applications.","sidebar":"integrations"},"integrations/providers/aleph_alpha":{"id":"integrations/providers/aleph_alpha","title":"Aleph Alpha","description":"Aleph Alpha was founded in 2019 with the mission to research and build the foundational technology for an era of strong AI. The team of international scientists, engineers, and innovators researches, develops, and deploys transformative AI like large language and multimodal models and runs the fastest European commercial AI cluster.","sidebar":"integrations"},"integrations/providers/alibaba_cloud":{"id":"integrations/providers/alibaba_cloud","title":"Alibaba Cloud","description":"Alibaba Group Holding Limited (Wikipedia), or Alibaba","sidebar":"integrations"},"integrations/providers/analyticdb":{"id":"integrations/providers/analyticdb","title":"AnalyticDB","description":"AnalyticDB for PostgreSQL","sidebar":"integrations"},"integrations/providers/annoy":{"id":"integrations/providers/annoy","title":"Annoy","description":"Annoy (Approximate Nearest Neighbors Oh Yeah)","sidebar":"integrations"},"integrations/providers/anthropic":{"id":"integrations/providers/anthropic","title":"Anthropic","description":"Anthropic is an AI safety and research company, and is the creator of Claude.","sidebar":"integrations"},"integrations/providers/anyscale":{"id":"integrations/providers/anyscale","title":"Anyscale","description":"Anyscale is a platform to run, fine tune and scale LLMs via production-ready APIs.","sidebar":"integrations"},"integrations/providers/apache":{"id":"integrations/providers/apache","title":"Apache Software Foundation","description":"The Apache Software Foundation (Wikipedia)","sidebar":"integrations"},"integrations/providers/apache_doris":{"id":"integrations/providers/apache_doris","title":"Apache Doris","description":"Apache Doris is a modern data warehouse for real-time analytics.","sidebar":"integrations"},"integrations/providers/apify":{"id":"integrations/providers/apify","title":"Apify","description":"Apify is a cloud platform for web scraping and data extraction,","sidebar":"integrations"},"integrations/providers/apple":{"id":"integrations/providers/apple","title":"Apple","description":"Apple Inc. (Wikipedia) is an American","sidebar":"integrations"},"integrations/providers/arangodb":{"id":"integrations/providers/arangodb","title":"ArangoDB","description":"ArangoDB is a scalable graph database system to","sidebar":"integrations"},"integrations/providers/arcee":{"id":"integrations/providers/arcee","title":"Arcee","description":"Arcee enables the development and advancement","sidebar":"integrations"},"integrations/providers/arcgis":{"id":"integrations/providers/arcgis","title":"ArcGIS","description":"ArcGIS is a family of client,","sidebar":"integrations"},"integrations/providers/argilla":{"id":"integrations/providers/argilla","title":"Argilla","description":"Argilla is an open-source data curation platform for LLMs.","sidebar":"integrations"},"integrations/providers/arize":{"id":"integrations/providers/arize","title":"Arize","description":"Arize is an AI observability and LLM evaluation platform that offers","sidebar":"integrations"},"integrations/providers/arthur_tracking":{"id":"integrations/providers/arthur_tracking","title":"Arthur","description":"Arthur is a model monitoring and observability platform.","sidebar":"integrations"},"integrations/providers/arxiv":{"id":"integrations/providers/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics,","sidebar":"integrations"},"integrations/providers/ascend":{"id":"integrations/providers/ascend","title":"Ascend","description":"Ascend is Natural Process Unit provide by Huawei","sidebar":"integrations"},"integrations/providers/asknews":{"id":"integrations/providers/asknews","title":"AskNews","description":"AskNews enhances language models with up-to-date global or historical news","sidebar":"integrations"},"integrations/providers/assemblyai":{"id":"integrations/providers/assemblyai","title":"AssemblyAI","description":"AssemblyAI builds Speech AI models for tasks like","sidebar":"integrations"},"integrations/providers/astradb":{"id":"integrations/providers/astradb","title":"Astra DB","description":"DataStax Astra DB is a serverless","sidebar":"integrations"},"integrations/providers/atlas":{"id":"integrations/providers/atlas","title":"Atlas","description":"Nomic Atlas is a platform for interacting with both","sidebar":"integrations"},"integrations/providers/awadb":{"id":"integrations/providers/awadb","title":"AwaDB","description":"AwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.","sidebar":"integrations"},"integrations/providers/aws":{"id":"integrations/providers/aws","title":"AWS","description":"The LangChain integrations related to Amazon AWS platform.","sidebar":"integrations"},"integrations/providers/azlyrics":{"id":"integrations/providers/azlyrics","title":"AZLyrics","description":"AZLyrics is a large, legal, every day growing collection of lyrics.","sidebar":"integrations"},"integrations/providers/azure_ai":{"id":"integrations/providers/azure_ai","title":"Azure AI","description":"All functionality related to Azure AI Foundry and its related projects.","sidebar":"integrations"},"integrations/providers/baai":{"id":"integrations/providers/baai","title":"BAAI","description":"Beijing Academy of Artificial Intelligence (BAAI) (Wikipedia),","sidebar":"integrations"},"integrations/providers/bagel":{"id":"integrations/providers/bagel","title":"Bagel","description":"Bagel (Open Vector Database for AI), is like GitHub for AI data.","sidebar":"integrations"},"integrations/providers/bageldb":{"id":"integrations/providers/bageldb","title":"BagelDB","description":"BagelDB (Open Vector Database for AI), is like GitHub for AI data.","sidebar":"integrations"},"integrations/providers/baichuan":{"id":"integrations/providers/baichuan","title":"Baichuan","description":"Baichuan Inc. is a Chinese startup in the era of AGI,","sidebar":"integrations"},"integrations/providers/baidu":{"id":"integrations/providers/baidu","title":"Baidu","description":"Baidu Cloud is a cloud service provided by Baidu, Inc.,","sidebar":"integrations"},"integrations/providers/bananadev":{"id":"integrations/providers/bananadev","title":"Banana","description":"Banana provided serverless GPU inference for AI models,","sidebar":"integrations"},"integrations/providers/baseten":{"id":"integrations/providers/baseten","title":"Baseten","description":"Baseten is a provider of all the infrastructure you need to deploy and serve","sidebar":"integrations"},"integrations/providers/beam":{"id":"integrations/providers/beam","title":"Beam","description":"Beam is a cloud computing platform that allows you to run your code","sidebar":"integrations"},"integrations/providers/beautiful_soup":{"id":"integrations/providers/beautiful_soup","title":"Beautiful Soup","description":"Beautiful Soup is a Python package for parsing","sidebar":"integrations"},"integrations/providers/bibtex":{"id":"integrations/providers/bibtex","title":"BibTeX","description":"BibTeX is a file format and reference management system commonly used in conjunction with LaTeX typesetting. It serves as a way to organize and store bibliographic information for academic and research documents.","sidebar":"integrations"},"integrations/providers/bilibili":{"id":"integrations/providers/bilibili","title":"BiliBili","description":"Bilibili is one of the most beloved long-form video sites in China.","sidebar":"integrations"},"integrations/providers/bittensor":{"id":"integrations/providers/bittensor","title":"Bittensor","description":"Neural Internet Bittensor network, an open source protocol","sidebar":"integrations"},"integrations/providers/blackboard":{"id":"integrations/providers/blackboard","title":"Blackboard","description":"Blackboard Learn (previously the Blackboard Learning Management System)","sidebar":"integrations"},"integrations/providers/bookendai":{"id":"integrations/providers/bookendai","title":"bookend.ai","description":"LangChain implements an integration with embeddings provided by bookend.ai.","sidebar":"integrations"},"integrations/providers/box":{"id":"integrations/providers/box","title":"Box","description":"Box is the Intelligent Content Cloud, a single platform that enables","sidebar":"integrations"},"integrations/providers/brave_search":{"id":"integrations/providers/brave_search","title":"Brave Search","description":"Brave Search is a search engine developed by Brave Software.","sidebar":"integrations"},"integrations/providers/breebs":{"id":"integrations/providers/breebs","title":"Breebs (Open Knowledge)","description":"Breebs is an open collaborative knowledge platform.","sidebar":"integrations"},"integrations/providers/browserbase":{"id":"integrations/providers/browserbase","title":"Browserbase","description":"Browserbase is a developer platform to reliably run, manage, and monitor headless browsers.","sidebar":"integrations"},"integrations/providers/browserless":{"id":"integrations/providers/browserless","title":"Browserless","description":"Browserless is a service that allows you to","sidebar":"integrations"},"integrations/providers/byte_dance":{"id":"integrations/providers/byte_dance","title":"ByteDance","description":"ByteDance is a Chinese internet technology company.","sidebar":"integrations"},"integrations/providers/cassandra":{"id":"integrations/providers/cassandra","title":"Cassandra","description":"Apache Cassandra\xae is a NoSQL, row-oriented, highly scalable and highly available database.","sidebar":"integrations"},"integrations/providers/cerebras":{"id":"integrations/providers/cerebras","title":"Cerebras","description":"At Cerebras, we\'ve developed the world\'s largest and fastest AI processor, the Wafer-Scale Engine-3 (WSE-3). The Cerebras CS-3 system, powered by the WSE-3, represents a new class of AI supercomputer that sets the standard for generative AI training and inference with unparalleled performance and scalability.","sidebar":"integrations"},"integrations/providers/cerebriumai":{"id":"integrations/providers/cerebriumai","title":"CerebriumAI","description":"Cerebrium  is a serverless GPU infrastructure provider.","sidebar":"integrations"},"integrations/providers/chaindesk":{"id":"integrations/providers/chaindesk","title":"Chaindesk","description":"Chaindesk is an open-source document retrieval platform that helps to connect your personal data with Large Language Models.","sidebar":"integrations"},"integrations/providers/chroma":{"id":"integrations/providers/chroma","title":"Chroma","description":"Chroma is a database for building AI applications with embeddings.","sidebar":"integrations"},"integrations/providers/clarifai":{"id":"integrations/providers/clarifai","title":"Clarifai","description":"Clarifai is one of first deep learning platforms having been founded in 2013. Clarifai provides an AI platform with the full AI lifecycle for data exploration, data labeling, model training, evaluation and inference around images, video, text and audio data. In the LangChain ecosystem, as far as we\'re aware, Clarifai is the only provider that supports LLMs, embeddings and a vector store in one production scale platform, making it an excellent choice to operationalize your LangChain implementations.","sidebar":"integrations"},"integrations/providers/clearml_tracking":{"id":"integrations/providers/clearml_tracking","title":"ClearML","description":"ClearML is a ML/DL development and production suite, it contains 5 main modules:","sidebar":"integrations"},"integrations/providers/clickhouse":{"id":"integrations/providers/clickhouse","title":"ClickHouse","description":"ClickHouse is the fast and resource efficient open-source database for real-time","sidebar":"integrations"},"integrations/providers/clickup":{"id":"integrations/providers/clickup","title":"ClickUp","description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","sidebar":"integrations"},"integrations/providers/cloudflare":{"id":"integrations/providers/cloudflare","title":"Cloudflare","description":"Cloudflare, Inc. (Wikipedia) is an American company that provides","sidebar":"integrations"},"integrations/providers/clova":{"id":"integrations/providers/clova","title":"Clova","description":"CLOVA Studio is a service","sidebar":"integrations"},"integrations/providers/cnosdb":{"id":"integrations/providers/cnosdb","title":"CnosDB","description":"CnosDB is an open-source distributed time series database with high performance, high compression rate and high ease of use.","sidebar":"integrations"},"integrations/providers/cognee":{"id":"integrations/providers/cognee","title":"Cognee","description":"Cognee implements scalable, modular ECL (Extract, Cognify, Load) pipelines that allow","sidebar":"integrations"},"integrations/providers/cogniswitch":{"id":"integrations/providers/cogniswitch","title":"CogniSwitch","description":"CogniSwitch is an API based data platform that","sidebar":"integrations"},"integrations/providers/cohere":{"id":"integrations/providers/cohere","title":"Cohere","description":"Cohere is a Canadian startup that provides natural language processing models","sidebar":"integrations"},"integrations/providers/college_confidential":{"id":"integrations/providers/college_confidential","title":"College Confidential","description":"College Confidential gives information on 3,800+ colleges and universities.","sidebar":"integrations"},"integrations/providers/comet_tracking":{"id":"integrations/providers/comet_tracking","title":"Comet","description":"Comet machine learning platform integrates with your existing infrastructure","sidebar":"integrations"},"integrations/providers/confident":{"id":"integrations/providers/confident","title":"Confident AI","description":"Confident AI is a creator of the DeepEval.","sidebar":"integrations"},"integrations/providers/confluence":{"id":"integrations/providers/confluence","title":"Confluence","description":"Confluence is a wiki collaboration platform that saves and organizes all of the project-related material. Confluence is a knowledge base that primarily handles content management activities.","sidebar":"integrations"},"integrations/providers/connery":{"id":"integrations/providers/connery","title":"Connery","description":"Connery SDK is an NPM package that","sidebar":"integrations"},"integrations/providers/context":{"id":"integrations/providers/context","title":"Context","description":"Context provides user analytics for LLM-powered products and features.","sidebar":"integrations"},"integrations/providers/contextual":{"id":"integrations/providers/contextual","title":"Contextual AI","description":"Contextual AI provides state-of-the-art RAG components designed specifically for accurate and reliable enterprise AI applications. Our LangChain integration exposes standalone API endpoints for our specialized models:","sidebar":"integrations"},"integrations/providers/couchbase":{"id":"integrations/providers/couchbase","title":"Couchbase","description":"Couchbase is an award-winning distributed NoSQL cloud database","sidebar":"integrations"},"integrations/providers/coze":{"id":"integrations/providers/coze","title":"Coze","description":"Coze is an AI chatbot development platform that enables","sidebar":"integrations"},"integrations/providers/cratedb":{"id":"integrations/providers/cratedb","title":"CrateDB","description":"[CrateDB] is a distributed and scalable SQL database for storing and","sidebar":"integrations"},"integrations/providers/ctransformers":{"id":"integrations/providers/ctransformers","title":"C Transformers","description":"This page covers how to use the C Transformers library within LangChain.","sidebar":"integrations"},"integrations/providers/ctranslate2":{"id":"integrations/providers/ctranslate2","title":"CTranslate2","description":"CTranslate2 is a C++ and Python library","sidebar":"integrations"},"integrations/providers/cube":{"id":"integrations/providers/cube","title":"Cube","description":"Cube is the Semantic Layer for building data apps. It helps","sidebar":"integrations"},"integrations/providers/dappier":{"id":"integrations/providers/dappier","title":"Dappier","description":"Dappier connects any LLM or your Agentic AI to","sidebar":"integrations"},"integrations/providers/dashvector":{"id":"integrations/providers/dashvector","title":"DashVector","description":"DashVector is a fully-managed vectorDB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.","sidebar":"integrations"},"integrations/providers/databricks":{"id":"integrations/providers/databricks","title":"Databricks","description":"Databricks Intelligence Platform is the world\'s first data intelligence platform powered by generative AI. Infuse AI into every facet of your business.","sidebar":"integrations"},"integrations/providers/datadog":{"id":"integrations/providers/datadog","title":"Datadog Tracing","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","sidebar":"integrations"},"integrations/providers/datadog_logs":{"id":"integrations/providers/datadog_logs","title":"Datadog Logs","description":"Datadog is a monitoring and analytics platform for cloud-scale applications.","sidebar":"integrations"},"integrations/providers/dataforseo":{"id":"integrations/providers/dataforseo","title":"DataForSEO","description":"DataForSeo provides comprehensive SEO and digital marketing data solutions via API.","sidebar":"integrations"},"integrations/providers/dataherald":{"id":"integrations/providers/dataherald","title":"Dataherald","description":"Dataherald is a natural language-to-SQL.","sidebar":"integrations"},"integrations/providers/dedoc":{"id":"integrations/providers/dedoc","title":"Dedoc","description":"Dedoc is an open-source","sidebar":"integrations"},"integrations/providers/deepinfra":{"id":"integrations/providers/deepinfra","title":"DeepInfra","description":"DeepInfra allows us to run the","sidebar":"integrations"},"integrations/providers/deeplake":{"id":"integrations/providers/deeplake","title":"Deeplake","description":"Deeplake is a database optimized for AI and deep learning","sidebar":"integrations"},"integrations/providers/deepseek":{"id":"integrations/providers/deepseek","title":"DeepSeek","description":"DeepSeek is a Chinese artificial intelligence company that develops LLMs.","sidebar":"integrations"},"integrations/providers/deepsparse":{"id":"integrations/providers/deepsparse","title":"DeepSparse","description":"This page covers how to use the DeepSparse inference runtime within LangChain.","sidebar":"integrations"},"integrations/providers/dell":{"id":"integrations/providers/dell","title":"Dell","description":"Dell is a global technology company that provides a range of hardware, software, and","sidebar":"integrations"},"integrations/providers/diffbot":{"id":"integrations/providers/diffbot","title":"Diffbot","description":"Diffbot is a suite of ML-based products that make it easy to structure and integrate web data.","sidebar":"integrations"},"integrations/providers/dingo":{"id":"integrations/providers/dingo","title":"DingoDB","description":"DingoDB is a distributed multi-modal vector","sidebar":"integrations"},"integrations/providers/discord":{"id":"integrations/providers/discord","title":"Discord (community loader)","description":"Discord is a VoIP and instant messaging social platform. Users have the ability to communicate","sidebar":"integrations"},"integrations/providers/discord-shikenso":{"id":"integrations/providers/discord-shikenso","title":"Discord","description":"Discord is an instant messaging, voice, and video communication platform widely used by communities of all types.","sidebar":"integrations"},"integrations/providers/docarray":{"id":"integrations/providers/docarray","title":"DocArray","description":"DocArray is a library for nested, unstructured, multimodal data in transit,","sidebar":"integrations"},"integrations/providers/docling":{"id":"integrations/providers/docling","title":"Docling","description":"Docling parses PDF, DOCX, PPTX, HTML, and other formats into a rich unified representation including document layout, tables etc., making them ready for generative AI workflows like RAG.","sidebar":"integrations"},"integrations/providers/doctran":{"id":"integrations/providers/doctran","title":"Doctran","description":"Doctran is a python package. It uses LLMs and open-source","sidebar":"integrations"},"integrations/providers/docugami":{"id":"integrations/providers/docugami","title":"Docugami","description":"Docugami converts business documents into a Document XML Knowledge Graph, generating forests","sidebar":"integrations"},"integrations/providers/docusaurus":{"id":"integrations/providers/docusaurus","title":"Docusaurus","description":"Docusaurus is a static-site generator which provides","sidebar":"integrations"},"integrations/providers/dria":{"id":"integrations/providers/dria","title":"Dria","description":"Dria is a hub of public RAG models for developers to","sidebar":"integrations"},"integrations/providers/dropbox":{"id":"integrations/providers/dropbox","title":"Dropbox","description":"Dropbox is a file hosting service that brings everything-traditional","sidebar":"integrations"},"integrations/providers/dspy":{"id":"integrations/providers/dspy","title":"DSPy","description":"DSPy is a fantastic framework for LLMs that introduces an automatic compiler that teaches LMs how to conduct the declarative steps in your program. Specifically, the DSPy compiler will internally trace your program and then craft high-quality prompts for large LMs (or train automatic finetunes for small LMs) to teach them the steps of your task.","sidebar":"integrations"},"integrations/providers/duckdb":{"id":"integrations/providers/duckdb","title":"DuckDB","description":"DuckDB is an in-process SQL OLAP database management system.","sidebar":"integrations"},"integrations/providers/duckduckgo_search":{"id":"integrations/providers/duckduckgo_search","title":"DuckDuckGo Search","description":"DuckDuckGo Search is a package that","sidebar":"integrations"},"integrations/providers/e2b":{"id":"integrations/providers/e2b","title":"E2B","description":"E2B provides open-source secure sandboxes","sidebar":"integrations"},"integrations/providers/edenai":{"id":"integrations/providers/edenai","title":"Eden AI","description":"Eden AI user interface (UI)","sidebar":"integrations"},"integrations/providers/elasticsearch":{"id":"integrations/providers/elasticsearch","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine.","sidebar":"integrations"},"integrations/providers/elevenlabs":{"id":"integrations/providers/elevenlabs","title":"ElevenLabs","description":"ElevenLabs is a voice AI research & deployment company","sidebar":"integrations"},"integrations/providers/embedchain":{"id":"integrations/providers/embedchain","title":"Embedchain","description":"Embedchain is a RAG framework to create","sidebar":"integrations"},"integrations/providers/epsilla":{"id":"integrations/providers/epsilla","title":"Epsilla","description":"This page covers how to use Epsilla within LangChain.","sidebar":"integrations"},"integrations/providers/etherscan":{"id":"integrations/providers/etherscan","title":"Etherscan","description":"Etherscan is the leading blockchain explorer,","sidebar":"integrations"},"integrations/providers/everlyai":{"id":"integrations/providers/everlyai","title":"Everly AI","description":"Everly AI allows you to run your ML models at scale in the cloud.","sidebar":"integrations"},"integrations/providers/evernote":{"id":"integrations/providers/evernote","title":"EverNote","description":"EverNote is intended for archiving and creating notes in which photos, audio and saved web content can be embedded. Notes are stored in virtual \\"notebooks\\" and can be tagged, annotated, edited, searched, and exported.","sidebar":"integrations"},"integrations/providers/exa_search":{"id":"integrations/providers/exa_search","title":"Exa","description":"Exa is a knowledge API for AI and developers.","sidebar":"integrations"},"integrations/providers/facebook":{"id":"integrations/providers/facebook","title":"Facebook - Meta","description":"Meta Platforms, Inc., doing business as Meta, formerly","sidebar":"integrations"},"integrations/providers/falkordb":{"id":"integrations/providers/falkordb","title":"FalkorDB","description":"What is FalkorDB?","sidebar":"integrations"},"integrations/providers/fauna":{"id":"integrations/providers/fauna","title":"Fauna","description":"Fauna is a distributed document-relational database","sidebar":"integrations"},"integrations/providers/fiddler":{"id":"integrations/providers/fiddler","title":"Fiddler","description":"Fiddler provides a unified platform to monitor, explain, analyze,","sidebar":"integrations"},"integrations/providers/figma":{"id":"integrations/providers/figma","title":"Figma","description":"Figma is a collaborative web application for interface design.","sidebar":"integrations"},"integrations/providers/firecrawl":{"id":"integrations/providers/firecrawl","title":"FireCrawl","description":"FireCrawl crawls and converts any website into LLM-ready data.","sidebar":"integrations"},"integrations/providers/fireworks":{"id":"integrations/providers/fireworks","title":"Fireworks AI","description":"Fireworks AI is a generative AI inference platform to run and","sidebar":"integrations"},"integrations/providers/flyte":{"id":"integrations/providers/flyte","title":"Flyte","description":"Flyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines.","sidebar":"integrations"},"integrations/providers/fmp-data":{"id":"integrations/providers/fmp-data","title":"FMP Data (Financial Data Prep)","description":"FMP-Data is a python package for connecting to","sidebar":"integrations"},"integrations/providers/forefrontai":{"id":"integrations/providers/forefrontai","title":"Forefront AI","description":"Forefront AI is a platform enabling you to","sidebar":"integrations"},"integrations/providers/friendli":{"id":"integrations/providers/friendli","title":"Friendli AI","description":"FriendliAI enhances AI application performance and optimizes","sidebar":"integrations"},"integrations/providers/geopandas":{"id":"integrations/providers/geopandas","title":"Geopandas","description":"GeoPandas is an open source project to make working","sidebar":"integrations"},"integrations/providers/git":{"id":"integrations/providers/git","title":"Git","description":"Git is a distributed version control system that tracks changes in any set of computer files, usually used for coordinating work among programmers collaboratively developing source code during software development.","sidebar":"integrations"},"integrations/providers/gitbook":{"id":"integrations/providers/gitbook","title":"GitBook","description":"GitBook is a modern documentation platform where teams can document everything from products to internal knowledge bases and APIs.","sidebar":"integrations"},"integrations/providers/github":{"id":"integrations/providers/github","title":"GitHub","description":"GitHub is a developer platform that allows developers to create,","sidebar":"integrations"},"integrations/providers/gitlab":{"id":"integrations/providers/gitlab","title":"GitLab","description":"GitLab Inc. is an open-core company","sidebar":"integrations"},"integrations/providers/golden":{"id":"integrations/providers/golden","title":"Golden","description":"Golden provides a set of natural language APIs for querying and enrichment using the Golden Knowledge Graph e.g. queries such as: Products from OpenAI, Generative ai companies with series a funding, and rappers who invest can be used to retrieve structured data about relevant entities.","sidebar":"integrations"},"integrations/providers/goodfire":{"id":"integrations/providers/goodfire","title":"Goodfire","description":"Goodfire is a research lab focused on AI safety and","sidebar":"integrations"},"integrations/providers/google":{"id":"integrations/providers/google","title":"Google","description":"All functionality related to Google Cloud Platform and other Google products.","sidebar":"integrations"},"integrations/providers/google_serper":{"id":"integrations/providers/google_serper","title":"Serper - Google Search API","description":"This page covers how to use the Serper Google Search API within LangChain. Serper is a low-cost Google Search API that can be used to add answer box, knowledge graph, and organic results data from Google Search.","sidebar":"integrations"},"integrations/providers/gooseai":{"id":"integrations/providers/gooseai","title":"GooseAI","description":"GooseAI makes deploying NLP services easier and more accessible.","sidebar":"integrations"},"integrations/providers/gpt4all":{"id":"integrations/providers/gpt4all","title":"GPT4All","description":"This page covers how to use the GPT4All wrapper within LangChain. The tutorial is divided into two parts: installation and setup, followed by usage with an example.","sidebar":"integrations"},"integrations/providers/gradient":{"id":"integrations/providers/gradient","title":"Gradient","description":"Gradient allows to fine tune and get completions on LLMs with a simple web API.","sidebar":"integrations"},"integrations/providers/graph_rag":{"id":"integrations/providers/graph_rag","title":"Graph RAG","description":"Overview","sidebar":"integrations"},"integrations/providers/graphsignal":{"id":"integrations/providers/graphsignal","title":"Graphsignal","description":"This page covers how to use Graphsignal to trace and monitor LangChain. Graphsignal enables full visibility into your application. It provides latency breakdowns by chains and tools, exceptions with full context, data monitoring, compute/GPU utilization, OpenAI cost analytics, and more.","sidebar":"integrations"},"integrations/providers/grobid":{"id":"integrations/providers/grobid","title":"Grobid","description":"GROBID is a machine learning library for extracting, parsing, and re-structuring raw documents.","sidebar":"integrations"},"integrations/providers/groq":{"id":"integrations/providers/groq","title":"Groq","description":"Groqdeveloped the world\'s first Language Processing Unit\u2122, or LPU.","sidebar":"integrations"},"integrations/providers/gutenberg":{"id":"integrations/providers/gutenberg","title":"Gutenberg","description":"Project Gutenberg is an online library of free eBooks.","sidebar":"integrations"},"integrations/providers/hacker_news":{"id":"integrations/providers/hacker_news","title":"Hacker News","description":"Hacker News (sometimes abbreviated as HN) is a social news","sidebar":"integrations"},"integrations/providers/hazy_research":{"id":"integrations/providers/hazy_research","title":"Hazy Research","description":"This page covers how to use the Hazy Research ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/helicone":{"id":"integrations/providers/helicone","title":"Helicone","description":"This page covers how to use the Helicone ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/hologres":{"id":"integrations/providers/hologres","title":"Hologres","description":"Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.","sidebar":"integrations"},"integrations/providers/html2text":{"id":"integrations/providers/html2text","title":"HTML to text","description":"html2text is a Python package that converts a page of HTML into clean, easy-to-read plain ASCII text.","sidebar":"integrations"},"integrations/providers/huawei":{"id":"integrations/providers/huawei","title":"Huawei","description":"Huawei Technologies Co., Ltd. is a Chinese multinational","sidebar":"integrations"},"integrations/providers/huggingface":{"id":"integrations/providers/huggingface","title":"Hugging Face","description":"All functionality related to the Hugging Face Platform.","sidebar":"integrations"},"integrations/providers/hyperbrowser":{"id":"integrations/providers/hyperbrowser","title":"Hyperbrowser","description":"Hyperbrowser is a platform for running and scaling headless browsers. It lets you launch and manage browser sessions at scale and provides easy to use solutions for any webscraping needs, such as scraping a single page or crawling an entire site.","sidebar":"integrations"},"integrations/providers/ibm":{"id":"integrations/providers/ibm","title":"IBM","description":"The LangChain integrations related to IBM watsonx.ai platform.","sidebar":"integrations"},"integrations/providers/ieit_systems":{"id":"integrations/providers/ieit_systems","title":"IEIT Systems","description":"IEIT Systems is a Chinese information technology company","sidebar":"integrations"},"integrations/providers/ifixit":{"id":"integrations/providers/ifixit","title":"iFixit","description":"iFixit is the largest, open repair community on the web. The site contains nearly 100k","sidebar":"integrations"},"integrations/providers/iflytek":{"id":"integrations/providers/iflytek","title":"iFlytek","description":"iFlytek is a Chinese information technology company","sidebar":"integrations"},"integrations/providers/imsdb":{"id":"integrations/providers/imsdb","title":"IMSDb","description":"IMSDb is the Internet Movie Script Database.","sidebar":"integrations"},"integrations/providers/index":{"id":"integrations/providers/index","title":"Providers","description":"If you\'d like to write your own integration, see Extending LangChain.","sidebar":"integrations"},"integrations/providers/infinispanvs":{"id":"integrations/providers/infinispanvs","title":"Infinispan VS","description":"Infinispan Infinispan is an open-source in-memory data grid that provides","sidebar":"integrations"},"integrations/providers/infinity":{"id":"integrations/providers/infinity","title":"Infinity","description":"Infinity allows the creation of text embeddings.","sidebar":"integrations"},"integrations/providers/infino":{"id":"integrations/providers/infino","title":"Infino","description":"Infino is an open-source observability platform that stores both metrics and application logs together.","sidebar":"integrations"},"integrations/providers/intel":{"id":"integrations/providers/intel","title":"Intel","description":"Optimum Intel is the interface between the \ud83e\udd17 Transformers and Diffusers libraries and the different tools and libraries provided by Intel to accelerate end-to-end pipelines on Intel architectures.","sidebar":"integrations"},"integrations/providers/iugu":{"id":"integrations/providers/iugu","title":"Iugu","description":"Iugu is a Brazilian services and software as a service (SaaS)","sidebar":"integrations"},"integrations/providers/jaguar":{"id":"integrations/providers/jaguar","title":"Jaguar","description":"This page describes how to use Jaguar vector database within LangChain.","sidebar":"integrations"},"integrations/providers/javelin_ai_gateway":{"id":"integrations/providers/javelin_ai_gateway","title":"Javelin AI Gateway","description":"The Javelin AI Gateway service is a high-performance, enterprise grade API Gateway for AI applications.","sidebar":"integrations"},"integrations/providers/jenkins":{"id":"integrations/providers/jenkins","title":"Jenkins","description":"Jenkins is an open-source automation platform that enables","sidebar":"integrations"},"integrations/providers/jina":{"id":"integrations/providers/jina","title":"Jina AI","description":"Jina AI is a search AI company. Jina helps businesses and developers unlock multimodal data with a better search.","sidebar":"integrations"},"integrations/providers/johnsnowlabs":{"id":"integrations/providers/johnsnowlabs","title":"Johnsnowlabs","description":"Gain access to the johnsnowlabs ecosystem of enterprise NLP libraries","sidebar":"integrations"},"integrations/providers/joplin":{"id":"integrations/providers/joplin","title":"Joplin","description":"Joplin is an open-source note-taking app. It captures your thoughts","sidebar":"integrations"},"integrations/providers/kdbai":{"id":"integrations/providers/kdbai","title":"KDB.AI","description":"KDB.AI is a powerful knowledge-based vector database and search engine that allows you to build scalable, reliable AI applications, using real-time data, by providing advanced search, recommendation and personalization.","sidebar":"integrations"},"integrations/providers/kinetica":{"id":"integrations/providers/kinetica","title":"Kinetica","description":"Kinetica is a real-time database purpose built for enabling","sidebar":"integrations"},"integrations/providers/koboldai":{"id":"integrations/providers/koboldai","title":"KoboldAI","description":"KoboldAI is a free, open-source project that allows users to run AI models locally","sidebar":"integrations"},"integrations/providers/konko":{"id":"integrations/providers/konko","title":"Konko","description":"All functionality related to Konko","sidebar":"integrations"},"integrations/providers/konlpy":{"id":"integrations/providers/konlpy","title":"KoNLPY","description":"KoNLPy is a Python package for natural language processing (NLP)","sidebar":"integrations"},"integrations/providers/kuzu":{"id":"integrations/providers/kuzu","title":"K\xf9zu","description":"K\xf9zu is an embeddable, scalable, extremely fast graph database.","sidebar":"integrations"},"integrations/providers/labelstudio":{"id":"integrations/providers/labelstudio","title":"Label Studio","description":"Label Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.","sidebar":"integrations"},"integrations/providers/lakefs":{"id":"integrations/providers/lakefs","title":"lakeFS","description":"lakeFS provides scalable version control over","sidebar":"integrations"},"integrations/providers/lancedb":{"id":"integrations/providers/lancedb","title":"LanceDB","description":"This page covers how to use LanceDB within LangChain.","sidebar":"integrations"},"integrations/providers/langchain_decorators":{"id":"integrations/providers/langchain_decorators","title":"LangChain Decorators \u2728","description":"~~~","sidebar":"integrations"},"integrations/providers/langfair":{"id":"integrations/providers/langfair","title":"LangFair: Use-Case Level LLM Bias and Fairness Assessments","description":"LangFair is a comprehensive Python library designed for conducting bias and fairness assessments of large language model (LLM) use cases. The LangFair repository includes a comprehensive framework for choosing bias and fairness metrics, along with demo notebooks and a technical playbook that discusses LLM bias and fairness risks, evaluation metrics, and best practices.","sidebar":"integrations"},"integrations/providers/lantern":{"id":"integrations/providers/lantern","title":"Lantern","description":"This page covers how to use the Lantern within LangChain","sidebar":"integrations"},"integrations/providers/lindorm":{"id":"integrations/providers/lindorm","title":"Lindorm","description":"Lindorm is a cloud-native multimodal database from Alibaba-Cloud, It supports unified access and integrated processing of various types of data, including wide tables, time-series, text, objects, streams, and spatial data. It is compatible with multiple standard interfaces such as SQL, HBase/Cassandra/S3, TSDB, HDFS, Solr, and Kafka, and seamlessly integrates with third-party ecosystem tools. This makes it suitable for scenarios such as logging, monitoring, billing, advertising, social networking, travel, and risk control. Lindorm is also one of the databases that support Alibaba\'s core businesses.","sidebar":"integrations"},"integrations/providers/linkup":{"id":"integrations/providers/linkup","title":"Linkup","description":"Linkup provides an API to connect LLMs to the web and the Linkup Premium Partner sources.","sidebar":"integrations"},"integrations/providers/littlellm":{"id":"integrations/providers/littlellm","title":"LiteLLM","description":"LiteLLM is a library that simplifies calling Anthropic,","sidebar":"integrations"},"integrations/providers/llama_index":{"id":"integrations/providers/llama_index","title":"LlamaIndex","description":"LlamaIndex is the leading data framework for building LLM applications","sidebar":"integrations"},"integrations/providers/llamacpp":{"id":"integrations/providers/llamacpp","title":"Llama.cpp","description":"llama.cpp python library is a simple Python bindings for @ggerganov","sidebar":"integrations"},"integrations/providers/llamaedge":{"id":"integrations/providers/llamaedge","title":"LlamaEdge","description":"LlamaEdge is the easiest & fastest way to run customized","sidebar":"integrations"},"integrations/providers/llamafile":{"id":"integrations/providers/llamafile","title":"llamafile","description":"llamafile lets you distribute and run LLMs","sidebar":"integrations"},"integrations/providers/llmonitor":{"id":"integrations/providers/llmonitor","title":"LLMonitor","description":"LLMonitor is an open-source observability platform that provides cost and usage analytics, user tracking, tracing and evaluation tools.","sidebar":"integrations"},"integrations/providers/localai":{"id":"integrations/providers/localai","title":"LocalAI","description":"LocalAI is the free, Open Source OpenAI alternative.","sidebar":"integrations"},"integrations/providers/log10":{"id":"integrations/providers/log10","title":"Log10","description":"This page covers how to use the Log10 within LangChain.","sidebar":"integrations"},"integrations/providers/maritalk":{"id":"integrations/providers/maritalk","title":"MariTalk","description":"MariTalk is an LLM-based chatbot trained to meet the needs of Brazil.","sidebar":"integrations"},"integrations/providers/marqo":{"id":"integrations/providers/marqo","title":"Marqo","description":"This page covers how to use the Marqo ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/mediawikidump":{"id":"integrations/providers/mediawikidump","title":"MediaWikiDump","description":"MediaWiki XML Dumps contain the content of a wiki","sidebar":"integrations"},"integrations/providers/meilisearch":{"id":"integrations/providers/meilisearch","title":"Meilisearch","description":"Meilisearch is an open-source, lightning-fast, and hyper","sidebar":"integrations"},"integrations/providers/memcached":{"id":"integrations/providers/memcached","title":"Memcached","description":"Memcached is a free & open source, high-performance, distributed memory object caching system,","sidebar":"integrations"},"integrations/providers/metal":{"id":"integrations/providers/metal","title":"Metal","description":"This page covers how to use Metal within LangChain.","sidebar":"integrations"},"integrations/providers/microsoft":{"id":"integrations/providers/microsoft","title":"Microsoft","description":"All functionality related to Microsoft Azure and other Microsoft products.","sidebar":"integrations"},"integrations/providers/milvus":{"id":"integrations/providers/milvus","title":"Milvus","description":"Milvus is a database that stores, indexes, and manages","sidebar":"integrations"},"integrations/providers/mindsdb":{"id":"integrations/providers/mindsdb","title":"MindsDB","description":"MindsDB is the platform for customizing AI from enterprise data. With MindsDB and it\'s nearly 200 integrations to data sources and AI/ML frameworks, any developer can use their enterprise data to customize AI for their purpose, faster and more securely.","sidebar":"integrations"},"integrations/providers/minimax":{"id":"integrations/providers/minimax","title":"Minimax","description":"Minimax is a Chinese startup that provides natural language processing models","sidebar":"integrations"},"integrations/providers/mistralai":{"id":"integrations/providers/mistralai","title":"MistralAI","description":"Mistral AI is a platform that offers hosting for their powerful open source models.","sidebar":"integrations"},"integrations/providers/mlflow":{"id":"integrations/providers/mlflow","title":"MLflow AI Gateway for LLMs","description":"The MLflow AI Gateway for LLMs is a powerful tool designed to streamline the usage and management of various large","sidebar":"integrations"},"integrations/providers/mlflow_tracking":{"id":"integrations/providers/mlflow_tracking","title":"MLflow","description":"MLflow is a versatile, open-source platform for managing workflows and artifacts across the machine learning and generative AI lifecycle. It has built-in integrations with many popular AI and ML libraries, but can be used with any library, algorithm, or deployment tool.","sidebar":"integrations"},"integrations/providers/mlx":{"id":"integrations/providers/mlx","title":"MLX","description":"MLX is a NumPy-like array framework","sidebar":"integrations"},"integrations/providers/modal":{"id":"integrations/providers/modal","title":"Modal","description":"This page covers how to use the Modal ecosystem to run LangChain custom LLMs.","sidebar":"integrations"},"integrations/providers/modelscope":{"id":"integrations/providers/modelscope","title":"ModelScope","description":"ModelScope is a big repository of the models and datasets.","sidebar":"integrations"},"integrations/providers/modern_treasury":{"id":"integrations/providers/modern_treasury","title":"Modern Treasury","description":"Modern Treasury simplifies complex payment operations. It is a unified platform to power products and processes that move money.","sidebar":"integrations"},"integrations/providers/momento":{"id":"integrations/providers/momento","title":"Momento","description":"Momento Cache is the world\'s first truly serverless caching service, offering instant elasticity, scale-to-zero","sidebar":"integrations"},"integrations/providers/mongodb":{"id":"integrations/providers/mongodb","title":"MongoDB","description":"MongoDB is a NoSQL, document-oriented","sidebar":"integrations"},"integrations/providers/mongodb_atlas":{"id":"integrations/providers/mongodb_atlas","title":"MongoDB Atlas","description":"MongoDB Atlas is a fully-managed cloud","sidebar":"integrations"},"integrations/providers/motherduck":{"id":"integrations/providers/motherduck","title":"Motherduck","description":"Motherduck is a managed DuckDB-in-the-cloud service.","sidebar":"integrations"},"integrations/providers/motorhead":{"id":"integrations/providers/motorhead","title":"Mot\xf6rhead","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.","sidebar":"integrations"},"integrations/providers/myscale":{"id":"integrations/providers/myscale","title":"MyScale","description":"This page covers how to use MyScale vector database within LangChain.","sidebar":"integrations"},"integrations/providers/naver":{"id":"integrations/providers/naver","title":"NAVER","description":"All functionality related to Naver, including HyperCLOVA X models, particularly those accessible through Naver Cloud CLOVA Studio.","sidebar":"integrations"},"integrations/providers/neo4j":{"id":"integrations/providers/neo4j","title":"Neo4j","description":"What is Neo4j?","sidebar":"integrations"},"integrations/providers/nimble":{"id":"integrations/providers/nimble","title":"Nimble","description":"Nimble is the first business external data platform, making data decision-making easier than ever, with our award-winning AI-powered data structuring technology Nimble connects business users with the public web knowledge.","sidebar":"integrations"},"integrations/providers/nlpcloud":{"id":"integrations/providers/nlpcloud","title":"NLPCloud","description":"NLP Cloud is an artificial intelligence platform that allows you to use the most advanced AI engines, and even train your own engines with your own data.","sidebar":"integrations"},"integrations/providers/nomic":{"id":"integrations/providers/nomic","title":"Nomic","description":"Nomic builds tools that enable everyone to interact with AI scale datasets and run AI models on consumer computers.","sidebar":"integrations"},"integrations/providers/notion":{"id":"integrations/providers/notion","title":"Notion DB","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban","sidebar":"integrations"},"integrations/providers/nuclia":{"id":"integrations/providers/nuclia","title":"Nuclia","description":"Nuclia automatically indexes your unstructured data from any internal","sidebar":"integrations"},"integrations/providers/nvidia":{"id":"integrations/providers/nvidia","title":"NVIDIA","description":"The langchain-nvidia-ai-endpoints package contains LangChain integrations building applications with models on","sidebar":"integrations"},"integrations/providers/obsidian":{"id":"integrations/providers/obsidian","title":"Obsidian","description":"Obsidian is a powerful and extensible knowledge base","sidebar":"integrations"},"integrations/providers/oceanbase":{"id":"integrations/providers/oceanbase","title":"OceanBase","description":"OceanBase Database is a distributed relational database.","sidebar":"integrations"},"integrations/providers/oci":{"id":"integrations/providers/oci","title":"Oracle Cloud Infrastructure (OCI)","description":"The LangChain integrations related to Oracle Cloud Infrastructure.","sidebar":"integrations"},"integrations/providers/octoai":{"id":"integrations/providers/octoai","title":"OctoAI","description":"OctoAI offers easy access to efficient compute","sidebar":"integrations"},"integrations/providers/ollama":{"id":"integrations/providers/ollama","title":"Ollama","description":"Ollama allows you to run open-source large language models,","sidebar":"integrations"},"integrations/providers/ontotext_graphdb":{"id":"integrations/providers/ontotext_graphdb","title":"Ontotext GraphDB","description":"Ontotext GraphDB is a graph database and knowledge discovery tool compliant with RDF and SPARQL.","sidebar":"integrations"},"integrations/providers/openai":{"id":"integrations/providers/openai","title":"OpenAI","description":"All functionality related to OpenAI","sidebar":"integrations"},"integrations/providers/opengradient":{"id":"integrations/providers/opengradient","title":"OpenGradient","description":"OpenGradient is a decentralized AI computing network enabling globally accessible, permissionless, and verifiable ML model inference.","sidebar":"integrations"},"integrations/providers/openllm":{"id":"integrations/providers/openllm","title":"OpenLLM","description":"OpenLLM lets developers run any open-source LLMs as OpenAI-compatible API endpoints with a single command.","sidebar":"integrations"},"integrations/providers/opensearch":{"id":"integrations/providers/opensearch","title":"OpenSearch","description":"This page covers how to use the OpenSearch ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/openweathermap":{"id":"integrations/providers/openweathermap","title":"OpenWeatherMap","description":"OpenWeatherMap provides all essential weather data for a specific location:","sidebar":"integrations"},"integrations/providers/oracleai":{"id":"integrations/providers/oracleai","title":"OracleAI Vector Search","description":"Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads that allows you to query data based on semantics, rather than keywords.","sidebar":"integrations"},"integrations/providers/outline":{"id":"integrations/providers/outline","title":"Outline","description":"Outline is an open-source collaborative knowledge base platform designed for team information sharing.","sidebar":"integrations"},"integrations/providers/outlines":{"id":"integrations/providers/outlines","title":"Outlines","description":"Outlines is a Python library for constrained language generation. It provides a unified interface to various language models and allows for structured generation using techniques like regex matching, type constraints, JSON schemas, and context-free grammars.","sidebar":"integrations"},"integrations/providers/pandas":{"id":"integrations/providers/pandas","title":"Pandas","description":"pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,","sidebar":"integrations"},"integrations/providers/payman-tool":{"id":"integrations/providers/payman-tool","title":"PaymanAI","description":"PaymanAI provides functionality to send and receive payments (fiat and crypto) on behalf of an AI Agent. To get started:","sidebar":"integrations"},"integrations/providers/pebblo/index":{"id":"integrations/providers/pebblo/index","title":"Pebblo","description":"Pebblo enables developers to safely load and retrieve data to promote their Gen AI app to deployment without","sidebar":"integrations"},"integrations/providers/pebblo/pebblo_retrieval_qa":{"id":"integrations/providers/pebblo/pebblo_retrieval_qa","title":"Identity-enabled RAG using PebbloRetrievalQA","description":"PebbloRetrievalQA is a Retrieval chain with Identity & Semantic Enforcement for question-answering","sidebar":"integrations"},"integrations/providers/permit":{"id":"integrations/providers/permit","title":"Permit","description":"Permit.io offers fine-grained access control and policy","sidebar":"integrations"},"integrations/providers/perplexity":{"id":"integrations/providers/perplexity","title":"Perplexity","description":"Perplexity is the most powerful way to search","sidebar":"integrations"},"integrations/providers/petals":{"id":"integrations/providers/petals","title":"Petals","description":"This page covers how to use the Petals ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/pg_embedding":{"id":"integrations/providers/pg_embedding","title":"Postgres Embedding","description":"pgembedding is an open-source package for","sidebar":"integrations"},"integrations/providers/pgvector":{"id":"integrations/providers/pgvector","title":"PGVector","description":"This page covers how to use the Postgres PGVector ecosystem within LangChain","sidebar":"integrations"},"integrations/providers/pinecone":{"id":"integrations/providers/pinecone","title":"Pinecone","description":"Pinecone is a vector database with broad functionality.","sidebar":"integrations"},"integrations/providers/pipelineai":{"id":"integrations/providers/pipelineai","title":"PipelineAI","description":"This page covers how to use the PipelineAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/pipeshift":{"id":"integrations/providers/pipeshift","title":"Pipeshift","description":"Pipeshift is a fine-tuning and inference platform for open-source LLMs","sidebar":"integrations"},"integrations/providers/portkey/index":{"id":"integrations/providers/portkey/index","title":"Portkey","description":"Portkey is the Control Panel for AI apps. With it\'s popular AI Gateway and Observability Suite, hundreds of teams ship reliable, cost-efficient, and fast apps.","sidebar":"integrations"},"integrations/providers/portkey/logging_tracing_portkey":{"id":"integrations/providers/portkey/logging_tracing_portkey","title":"Log, Trace, and Monitor","description":"When building apps or agents using Langchain, you end up making multiple API calls to fulfill a single user request. However, these requests are not chained when you want to analyse them. With Portkey, all the embeddings, completions, and other requests from a single user request will get logged and traced to a common ID, enabling you to gain full visibility of user interactions.","sidebar":"integrations"},"integrations/providers/predibase":{"id":"integrations/providers/predibase","title":"Predibase","description":"Learn how to use LangChain with models on Predibase.","sidebar":"integrations"},"integrations/providers/predictionguard":{"id":"integrations/providers/predictionguard","title":"Prediction Guard","description":"This page covers how to use the Prediction Guard ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/premai":{"id":"integrations/providers/premai","title":"PremAI","description":"PremAI is an all-in-one platform that simplifies the creation of robust, production-ready applications powered by Generative AI. By streamlining the development process, PremAI allows you to concentrate on enhancing user experience and driving overall growth for your application. You can quickly start using our platform here.","sidebar":"integrations"},"integrations/providers/prolog":{"id":"integrations/providers/prolog","title":"SWI-Prolog","description":"SWI-Prolog offers a comprehensive free Prolog environment.","sidebar":"integrations"},"integrations/providers/promptlayer":{"id":"integrations/providers/promptlayer","title":"PromptLayer","description":"PromptLayer is a platform for prompt engineering.","sidebar":"integrations"},"integrations/providers/psychic":{"id":"integrations/providers/psychic","title":"Psychic","description":"This provider is no longer maintained, and may not work. Use with caution.","sidebar":"integrations"},"integrations/providers/pubmed":{"id":"integrations/providers/pubmed","title":"PubMed","description":"PubMed\xae by The National Center for Biotechnology Information, National Library of Medicine","sidebar":"integrations"},"integrations/providers/pull-md":{"id":"integrations/providers/pull-md","title":"PullMd Loader","description":"PullMd is a service that converts web pages into Markdown format. The langchain-pull-md package utilizes this service to convert URLs, especially those rendered with JavaScript frameworks like React, Angular, or Vue.js, into Markdown without the need for local rendering.","sidebar":"integrations"},"integrations/providers/pygmalionai":{"id":"integrations/providers/pygmalionai","title":"PygmalionAI","description":"PygmalionAI is a company supporting the","sidebar":"integrations"},"integrations/providers/pymupdf4llm":{"id":"integrations/providers/pymupdf4llm","title":"PyMuPDF4LLM","description":"PyMuPDF4LLM is aimed to make it easier to extract PDF content in Markdown format, needed for LLM & RAG applications.","sidebar":"integrations"},"integrations/providers/qdrant":{"id":"integrations/providers/qdrant","title":"Qdrant","description":"Qdrant (read: quadrant) is a vector similarity search engine.","sidebar":"integrations"},"integrations/providers/ragatouille":{"id":"integrations/providers/ragatouille","title":"RAGatouille","description":"RAGatouille makes it as simple as can be to use ColBERT! ColBERT is a fast and accurate retrieval model, enabling scalable BERT-based search over large text collections in tens of milliseconds.","sidebar":"integrations"},"integrations/providers/rank_bm25":{"id":"integrations/providers/rank_bm25","title":"rank_bm25","description":"rankbm25 is an open-source collection of algorithms","sidebar":"integrations"},"integrations/providers/ray_serve":{"id":"integrations/providers/ray_serve","title":"Ray Serve","description":"Ray Serve is a scalable model serving library for building online inference APIs. Serve is particularly well suited for system composition, enabling you to build a complex inference service consisting of multiple chains and business logic all in Python code.","sidebar":"integrations"},"integrations/providers/rebuff":{"id":"integrations/providers/rebuff","title":"Rebuff","description":"Rebuff is a self-hardening prompt injection detector.","sidebar":"integrations"},"integrations/providers/reddit":{"id":"integrations/providers/reddit","title":"Reddit","description":"Reddit is an American social news aggregation, content rating, and discussion website.","sidebar":"integrations"},"integrations/providers/redis":{"id":"integrations/providers/redis","title":"Redis","description":"Redis (Remote Dictionary Server) is an open-source in-memory storage,","sidebar":"integrations"},"integrations/providers/remembrall":{"id":"integrations/providers/remembrall","title":"Remembrall","description":"Remembrall is a platform that gives a language model","sidebar":"integrations"},"integrations/providers/replicate":{"id":"integrations/providers/replicate","title":"Replicate","description":"This page covers how to run models on Replicate within LangChain.","sidebar":"integrations"},"integrations/providers/roam":{"id":"integrations/providers/roam","title":"Roam","description":"ROAM is a note-taking tool for networked thought, designed to create a personal knowledge base.","sidebar":"integrations"},"integrations/providers/robocorp":{"id":"integrations/providers/robocorp","title":"Sema4 (fka Robocorp)","description":"Robocorp helps build and operate Python workers that run seamlessly anywhere at any scale","sidebar":"integrations"},"integrations/providers/rockset":{"id":"integrations/providers/rockset","title":"Rockset","description":"Rockset is a real-time analytics database service for serving low latency, high concurrency analytical queries at scale. It builds a Converged Index\u2122 on structured and semi-structured data with an efficient store for vector embeddings. Its support for running SQL on schemaless data makes it a perfect choice for running vector search with metadata filters.","sidebar":"integrations"},"integrations/providers/runhouse":{"id":"integrations/providers/runhouse","title":"Runhouse","description":"This page covers how to use the Runhouse ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/rwkv":{"id":"integrations/providers/rwkv","title":"RWKV-4","description":"This page covers how to use the RWKV-4 wrapper within LangChain.","sidebar":"integrations"},"integrations/providers/salesforce":{"id":"integrations/providers/salesforce","title":"Salesforce","description":"Salesforce is a cloud-based software company that","sidebar":"integrations"},"integrations/providers/salute_devices":{"id":"integrations/providers/salute_devices","title":"Salute Devices","description":"Salute Devices provides GigaChat LLM\'s models.","sidebar":"integrations"},"integrations/providers/sambanova":{"id":"integrations/providers/sambanova","title":"SambaNova","description":"Customers are turning to SambaNova to quickly deploy state-of-the-art AI capabilities to gain competitive advantage. Our purpose-built enterprise-scale AI platform is the technology backbone for the next generation of AI computing. We power the foundation models that unlock the valuable business insights trapped in data.","sidebar":"integrations"},"integrations/providers/sap":{"id":"integrations/providers/sap","title":"SAP","description":"SAP SE(Wikipedia) is a German multinational","sidebar":"integrations"},"integrations/providers/scrapegraph":{"id":"integrations/providers/scrapegraph","title":"ScrapeGraph AI","description":"ScrapeGraph AI is a service that provides AI-powered web scraping capabilities.","sidebar":"integrations"},"integrations/providers/searchapi":{"id":"integrations/providers/searchapi","title":"SearchApi","description":"This page covers how to use the SearchApi Google Search API within LangChain. SearchApi is a real-time SERP API for easy SERP scraping.","sidebar":"integrations"},"integrations/providers/searx":{"id":"integrations/providers/searx","title":"SearxNG Search API","description":"This page covers how to use the SearxNG search API within LangChain.","sidebar":"integrations"},"integrations/providers/semadb":{"id":"integrations/providers/semadb","title":"SemaDB","description":"SemaDB is a no fuss vector similarity search engine. It provides a low-cost cloud hosted version to help you build AI applications with ease.","sidebar":"integrations"},"integrations/providers/serpapi":{"id":"integrations/providers/serpapi","title":"SerpAPI","description":"This page covers how to use the SerpAPI search APIs within LangChain.","sidebar":"integrations"},"integrations/providers/shaleprotocol":{"id":"integrations/providers/shaleprotocol","title":"Shale Protocol","description":"Shale Protocol provides production-ready inference APIs for open LLMs. It\'s a Plug & Play API as it\'s hosted on a highly scalable GPU cloud infrastructure.","sidebar":"integrations"},"integrations/providers/singlestoredb":{"id":"integrations/providers/singlestoredb","title":"SingleStoreDB","description":"SingleStoreDB is a high-performance distributed SQL database that supports deployment both in the cloud and on-premises. It provides vector storage, and vector functions including dotproduct and euclideandistance, thereby supporting AI applications that require text similarity matching.","sidebar":"integrations"},"integrations/providers/sklearn":{"id":"integrations/providers/sklearn","title":"scikit-learn","description":"scikit-learn is an open-source collection of machine learning algorithms,","sidebar":"integrations"},"integrations/providers/slack":{"id":"integrations/providers/slack","title":"Slack","description":"Slack is an instant messaging program.","sidebar":"integrations"},"integrations/providers/snowflake":{"id":"integrations/providers/snowflake","title":"Snowflake","description":"Snowflake is a cloud-based data-warehousing platform","sidebar":"integrations"},"integrations/providers/spacy":{"id":"integrations/providers/spacy","title":"spaCy","description":"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.","sidebar":"integrations"},"integrations/providers/spark":{"id":"integrations/providers/spark","title":"Spark","description":"Apache Spark is a unified analytics engine for","sidebar":"integrations"},"integrations/providers/sparkllm":{"id":"integrations/providers/sparkllm","title":"SparkLLM","description":"SparkLLM is a large-scale cognitive model independently developed by iFLYTEK.","sidebar":"integrations"},"integrations/providers/spreedly":{"id":"integrations/providers/spreedly","title":"Spreedly","description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","sidebar":"integrations"},"integrations/providers/sqlite":{"id":"integrations/providers/sqlite","title":"SQLite","description":"SQLite is a database engine written in the","sidebar":"integrations"},"integrations/providers/stackexchange":{"id":"integrations/providers/stackexchange","title":"Stack Exchange","description":"Stack Exchange is a network of","sidebar":"integrations"},"integrations/providers/starrocks":{"id":"integrations/providers/starrocks","title":"StarRocks","description":"StarRocks is a High-Performance Analytical Database.","sidebar":"integrations"},"integrations/providers/stochasticai":{"id":"integrations/providers/stochasticai","title":"StochasticAI","description":"This page covers how to use the StochasticAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/streamlit":{"id":"integrations/providers/streamlit","title":"Streamlit","description":"Streamlit is a faster way to build and share data apps.","sidebar":"integrations"},"integrations/providers/stripe":{"id":"integrations/providers/stripe","title":"Stripe","description":"Stripe is an Irish-American financial services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"integrations"},"integrations/providers/supabase":{"id":"integrations/providers/supabase","title":"Supabase (Postgres)","description":"Supabase is an open-source Firebase alternative.","sidebar":"integrations"},"integrations/providers/symblai_nebula":{"id":"integrations/providers/symblai_nebula","title":"Nebula","description":"This page covers how to use Nebula, Symbl.ai\'s LLM, ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/tableau":{"id":"integrations/providers/tableau","title":"Tableau","description":"Tableau is an analytics platform that enables anyone to","sidebar":"integrations"},"integrations/providers/taiga":{"id":"integrations/providers/taiga","title":"Taiga","description":"Taiga is an open-source project management platform designed for agile teams, offering features like Kanban, Scrum, and issue tracking.","sidebar":"integrations"},"integrations/providers/tair":{"id":"integrations/providers/tair","title":"Tair","description":"Alibaba Cloud Tair is a cloud native in-memory database service","sidebar":"integrations"},"integrations/providers/tavily":{"id":"integrations/providers/tavily","title":"Tavily","description":"Tavily is a search engine, specifically designed for AI agents.","sidebar":"integrations"},"integrations/providers/telegram":{"id":"integrations/providers/telegram","title":"Telegram","description":"Telegram Messenger is a globally accessible freemium, cross-platform, encrypted, cloud-based and centralized instant messaging service. The application also provides optional end-to-end encrypted chats and video calling, VoIP, file sharing and several other features.","sidebar":"integrations"},"integrations/providers/tencent":{"id":"integrations/providers/tencent","title":"Tencent","description":"Tencent Holdings Ltd. (Wikipedia) (Chinese T\xe9ngx\xf9n)","sidebar":"integrations"},"integrations/providers/tensorflow_datasets":{"id":"integrations/providers/tensorflow_datasets","title":"TensorFlow Datasets","description":"TensorFlow Datasets is a collection of datasets ready to use,","sidebar":"integrations"},"integrations/providers/tidb":{"id":"integrations/providers/tidb","title":"TiDB","description":"TiDB Cloud, is a comprehensive Database-as-a-Service (DBaaS) solution,","sidebar":"integrations"},"integrations/providers/tigergraph":{"id":"integrations/providers/tigergraph","title":"TigerGraph","description":"TigerGraph is a natively distributed and high-performance graph database.","sidebar":"integrations"},"integrations/providers/tigris":{"id":"integrations/providers/tigris","title":"Tigris","description":"Tigris is an open-source Serverless NoSQL Database and Search Platform designed to simplify building high-performance vector search applications.","sidebar":"integrations"},"integrations/providers/tilores":{"id":"integrations/providers/tilores","title":"Tilores","description":"Tilores is a platform that provides advanced entity resolution solutions for data integration and management. Using cutting-edge algorithms, machine learning, and a user-friendly interfaces, Tilores helps organizations match, resolve, and consolidate data from disparate sources, ensuring high-quality, consistent information.","sidebar":"integrations"},"integrations/providers/together":{"id":"integrations/providers/together","title":"Together AI","description":"Together AI offers an API to query 50+ leading open-source models in a couple lines of code.","sidebar":"integrations"},"integrations/providers/tomarkdown":{"id":"integrations/providers/tomarkdown","title":"2Markdown","description":"2markdown service transforms website content into structured markdown files.","sidebar":"integrations"},"integrations/providers/transwarp":{"id":"integrations/providers/transwarp","title":"Transwarp","description":"Transwarp aims to build","sidebar":"integrations"},"integrations/providers/trello":{"id":"integrations/providers/trello","title":"Trello","description":"Trello is a web-based project management and collaboration tool that allows individuals and teams to organize and track their tasks and projects. It provides a visual interface known as a \\"board\\" where users can create lists and cards to represent their tasks and activities.","sidebar":"integrations"},"integrations/providers/trubrics":{"id":"integrations/providers/trubrics","title":"Trubrics","description":"Trubrics is an LLM user analytics platform that lets you collect, analyse and manage user","sidebar":"integrations"},"integrations/providers/trulens":{"id":"integrations/providers/trulens","title":"TruLens","description":"TruLens is an open-source package that provides instrumentation and evaluation tools for large language model (LLM) based applications.","sidebar":"integrations"},"integrations/providers/twitter":{"id":"integrations/providers/twitter","title":"Twitter","description":"Twitter is an online social media and social networking service.","sidebar":"integrations"},"integrations/providers/typesense":{"id":"integrations/providers/typesense","title":"Typesense","description":"Typesense is an open-source, in-memory search engine, that you can either","sidebar":"integrations"},"integrations/providers/unstructured":{"id":"integrations/providers/unstructured","title":"Unstructured","description":"The unstructured package from","sidebar":"integrations"},"integrations/providers/upstage":{"id":"integrations/providers/upstage","title":"Upstage","description":"Upstage is a leading artificial intelligence (AI) company specializing in delivering above-human-grade performance LLM components.","sidebar":"integrations"},"integrations/providers/upstash":{"id":"integrations/providers/upstash","title":"upstash","description":"Upstash offers developers serverless databases and messaging","sidebar":"integrations"},"integrations/providers/uptrain":{"id":"integrations/providers/uptrain","title":"UpTrain","description":"UpTrain is an open-source unified platform to evaluate and","sidebar":"integrations"},"integrations/providers/usearch":{"id":"integrations/providers/usearch","title":"USearch","description":"USearch is a Smaller & Faster Single-File Vector Search Engine.","sidebar":"integrations"},"integrations/providers/valthera":{"id":"integrations/providers/valthera","title":"Valthera","description":"Valthera is an open-source framework that empowers LLM Agents to drive meaningful, context-aware user engagement. It evaluates user motivation and ability in real time, ensuring that notifications and actions are triggered only when users are most receptive.","sidebar":"integrations"},"integrations/providers/vdms":{"id":"integrations/providers/vdms","title":"VDMS","description":"VDMS is a storage solution for efficient access","sidebar":"integrations"},"integrations/providers/vearch":{"id":"integrations/providers/vearch","title":"Vearch","description":"Vearch is a scalable distributed system for efficient similarity search of deep learning vectors.","sidebar":"integrations"},"integrations/providers/vectara/index":{"id":"integrations/providers/vectara/index","title":"Vectara","description":"Vectara provides a Trusted Generative AI platform, allowing organizations to rapidly create a ChatGPT-like experience (an AI assistant)","sidebar":"integrations"},"integrations/providers/vectara/vectara_chat":{"id":"integrations/providers/vectara/vectara_chat","title":"Vectara Chat","description":"Vectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.","sidebar":"integrations"},"integrations/providers/vespa":{"id":"integrations/providers/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database.","sidebar":"integrations"},"integrations/providers/vlite":{"id":"integrations/providers/vlite","title":"vlite","description":"This page covers how to use vlite within LangChain. vlite is a simple and fast vector database for storing and retrieving embeddings.","sidebar":"integrations"},"integrations/providers/voyageai":{"id":"integrations/providers/voyageai","title":"VoyageAI","description":"All functionality related to VoyageAI","sidebar":"integrations"},"integrations/providers/wandb":{"id":"integrations/providers/wandb","title":"Weights & Biases","description":"Weights & Biases is provider of the AI developer platform to train and","sidebar":"integrations"},"integrations/providers/wandb_tracing":{"id":"integrations/providers/wandb_tracing","title":"Weights & Biases tracing","description":"There are two recommended ways to trace your LangChains:","sidebar":"integrations"},"integrations/providers/wandb_tracking":{"id":"integrations/providers/wandb_tracking","title":"Weights & Biases tracking","description":"This notebook goes over how to track your LangChain experiments into one centralized Weights and Biases dashboard.","sidebar":"integrations"},"integrations/providers/weather":{"id":"integrations/providers/weather","title":"Weather","description":"OpenWeatherMap is an open-source weather service provider.","sidebar":"integrations"},"integrations/providers/weaviate":{"id":"integrations/providers/weaviate","title":"Weaviate","description":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from","sidebar":"integrations"},"integrations/providers/whatsapp":{"id":"integrations/providers/whatsapp","title":"WhatsApp","description":"WhatsApp (also called WhatsApp Messenger) is a freeware, cross-platform, centralized instant messaging (IM) and voice-over-IP (VoIP) service. It allows users to send text and voice messages, make voice and video calls, and share images, documents, user locations, and other content.","sidebar":"integrations"},"integrations/providers/whylabs_profiling":{"id":"integrations/providers/whylabs_profiling","title":"WhyLabs","description":"WhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:","sidebar":"integrations"},"integrations/providers/wikipedia":{"id":"integrations/providers/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/providers/wolfram_alpha":{"id":"integrations/providers/wolfram_alpha","title":"Wolfram Alpha","description":"WolframAlpha is an answer engine developed by Wolfram Research.","sidebar":"integrations"},"integrations/providers/writer":{"id":"integrations/providers/writer","title":"Writer, Inc.","description":"All functionality related to Writer","sidebar":"integrations"},"integrations/providers/xai":{"id":"integrations/providers/xai","title":"xAI","description":"xAI offers an API to interact with Grok models.","sidebar":"integrations"},"integrations/providers/xata":{"id":"integrations/providers/xata","title":"Xata","description":"Xata is a serverless data platform, based on PostgreSQL.","sidebar":"integrations"},"integrations/providers/xinference":{"id":"integrations/providers/xinference","title":"Xorbits Inference (Xinference)","description":"This page demonstrates how to use Xinference","sidebar":"integrations"},"integrations/providers/yahoo":{"id":"integrations/providers/yahoo","title":"Yahoo","description":"Yahoo (Wikipedia) is an American web services provider.","sidebar":"integrations"},"integrations/providers/yandex":{"id":"integrations/providers/yandex","title":"Yandex","description":"All functionality related to Yandex Cloud","sidebar":"integrations"},"integrations/providers/yeagerai":{"id":"integrations/providers/yeagerai","title":"Yeager.ai","description":"This page covers how to use Yeager.ai to generate LangChain tools and agents.","sidebar":"integrations"},"integrations/providers/yellowbrick":{"id":"integrations/providers/yellowbrick","title":"Yellowbrick","description":"Yellowbrick is a provider of","sidebar":"integrations"},"integrations/providers/yi":{"id":"integrations/providers/yi","title":"01.AI","description":"01.AI, founded by Dr. Kai-Fu Lee, is a global company at the forefront of AI 2.0. They offer cutting-edge large language models, including the Yi series, which range from 6B to hundreds of billions of parameters. 01.AI also provides multimodal models, an open API platform, and open-source options like Yi-34B/9B/6B and Yi-VL.","sidebar":"integrations"},"integrations/providers/you":{"id":"integrations/providers/you","title":"You","description":"You company provides an AI productivity platform.","sidebar":"integrations"},"integrations/providers/youtube":{"id":"integrations/providers/youtube","title":"YouTube","description":"YouTube is an online video sharing and social media platform by Google.","sidebar":"integrations"},"integrations/providers/zep":{"id":"integrations/providers/zep","title":"Zep","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences.","sidebar":"integrations"},"integrations/providers/zhipuai":{"id":"integrations/providers/zhipuai","title":"Zhipu AI","description":"Zhipu AI, originating from the technological","sidebar":"integrations"},"integrations/providers/zilliz":{"id":"integrations/providers/zilliz","title":"Zilliz","description":"Zilliz Cloud is a fully managed service on cloud for LF AI Milvus\xae,","sidebar":"integrations"},"integrations/providers/zotero":{"id":"integrations/providers/zotero","title":"Zotero","description":"Zotero is an open source reference management system intended for managing bibliographic data and related research materials. You can connect to your personal library, as well as shared group libraries, via the API. This retriever implementation utilizes PyZotero to access libraries.","sidebar":"integrations"},"integrations/retrievers/activeloop":{"id":"integrations/retrievers/activeloop","title":"Activeloop Deep Memory","description":"Activeloop Deep Memory is a suite of tools that enables you to optimize your Vector Store for your use-case and achieve higher accuracy in your LLM apps.","sidebar":"integrations"},"integrations/retrievers/amazon_kendra_retriever":{"id":"integrations/retrievers/amazon_kendra_retriever","title":"Amazon Kendra","description":"Amazon Kendra is an intelligent search service provided by Amazon Web Services (AWS). It utilizes advanced natural language processing (NLP) and machine learning algorithms to enable powerful search capabilities across various data sources within an organization. Kendra is designed to help users find the information they need quickly and accurately, improving productivity and decision-making.","sidebar":"integrations"},"integrations/retrievers/arcee":{"id":"integrations/retrievers/arcee","title":"Arcee","description":"Arcee helps with the development of the SLMs\u2014small, specialized, secure, and scalable language models.","sidebar":"integrations"},"integrations/retrievers/arxiv":{"id":"integrations/retrievers/arxiv","title":"ArxivRetriever","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.","sidebar":"integrations"},"integrations/retrievers/asknews":{"id":"integrations/retrievers/asknews","title":"AskNews","description":"AskNews infuses any LLM with the latest global news (or historical news), using a single natural language query. Specifically, AskNews is enriching over 300k articles per day by translating, summarizing, extracting entities, and indexing them into hot and cold vector databases. AskNews puts these vector databases on a low-latency endpoint for you. When you query AskNews, you get back a prompt-optimized string that contains all the most pertinent enrichments (e.g. entities, classifications, translation, summarization). This means that you do not need to manage your own news RAG, and you do not need to worry about how to properly convey news information in a condensed way to your LLM.","sidebar":"integrations"},"integrations/retrievers/azure_ai_search":{"id":"integrations/retrievers/azure_ai_search","title":"AzureAISearchRetriever","description":"Azure AI Search (formerly known as Azure Cognitive Search) is a Microsoft cloud search service that gives developers infrastructure, APIs, and tools for information retrieval of vector, keyword, and hybrid queries at scale.","sidebar":"integrations"},"integrations/retrievers/bedrock":{"id":"integrations/retrievers/bedrock","title":"Bedrock (Knowledge Bases) Retriever","description":"This guide will help you getting started with the AWS Knowledge Bases retriever.","sidebar":"integrations"},"integrations/retrievers/bm25":{"id":"integrations/retrievers/bm25","title":"BM25","description":"BM25 (Wikipedia) also known as the Okapi BM25, is a ranking function used in information retrieval systems to estimate the relevance of documents to a given search query.","sidebar":"integrations"},"integrations/retrievers/box":{"id":"integrations/retrievers/box","title":"BoxRetriever","description":"This will help you getting started with the Box retriever. For detailed documentation of all BoxRetriever features and configurations head to the API reference.","sidebar":"integrations"},"integrations/retrievers/breebs":{"id":"integrations/retrievers/breebs","title":"BREEBS (Open Knowledge)","description":"BREEBS is an open collaborative knowledge platform.","sidebar":"integrations"},"integrations/retrievers/chaindesk":{"id":"integrations/retrievers/chaindesk","title":"Chaindesk","description":"Chaindesk platform brings data from anywhere (Datsources: Text, PDF, Word, PowerPpoint, Excel, Notion, Airtable, Google Sheets, etc..) into Datastores (container of multiple Datasources).","sidebar":"integrations"},"integrations/retrievers/chatgpt-plugin":{"id":"integrations/retrievers/chatgpt-plugin","title":"ChatGPT plugin","description":"OpenAI plugins connect ChatGPT to third-party applications. These plugins enable ChatGPT to interact with APIs defined by developers, enhancing ChatGPT\'s capabilities and allowing it to perform a wide range of actions.","sidebar":"integrations"},"integrations/retrievers/cognee":{"id":"integrations/retrievers/cognee","title":"CogneeRetriever","description":"This will help you getting started with the Cognee retriever. For detailed documentation of all CogneeRetriever features and configurations head to the API reference.","sidebar":"integrations"},"integrations/retrievers/cohere":{"id":"integrations/retrievers/cohere","title":"Cohere RAG","description":"Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.","sidebar":"integrations"},"integrations/retrievers/cohere-reranker":{"id":"integrations/retrievers/cohere-reranker","title":"Cohere reranker","description":"Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.","sidebar":"integrations"},"integrations/retrievers/contextual":{"id":"integrations/retrievers/contextual","title":"Contextual AI Reranker","description":"Contextual AI\'s Instruction-Following Reranker is the world\'s first reranker designed to follow custom instructions about how to prioritize documents based on specific criteria like recency, source, and metadata. With superior performance on the BEIR benchmark (scoring 61.2 and outperforming competitors by significant margins), it delivers unprecedented control and accuracy for enterprise RAG applications.","sidebar":"integrations"},"integrations/retrievers/dappier":{"id":"integrations/retrievers/dappier","title":"Dappier","description":"Dappier connects any LLM or your Agentic AI to real-time, rights-cleared, proprietary data from trusted sources, making your AI an expert in anything. Our specialized models include Real-Time Web Search, News, Sports, Financial Stock Market Data, Crypto Data, and exclusive content from premium publishers. Explore a wide range of data models in our marketplace at marketplace.dappier.com.","sidebar":"integrations"},"integrations/retrievers/docarray_retriever":{"id":"integrations/retrievers/docarray_retriever","title":"DocArray","description":"DocArray is a versatile, open-source tool for managing your multi-modal data. It lets you shape your data however you want, and offers the flexibility to store and search it using various document index backends. Plus, it gets even better - you can utilize your DocArray document index to create a DocArrayRetriever, and build awesome Langchain apps!","sidebar":"integrations"},"integrations/retrievers/dria_index":{"id":"integrations/retrievers/dria_index","title":"Dria","description":"Dria is a hub of public RAG models for developers to both contribute and utilize a shared embedding lake. This notebook demonstrates how to use the Dria API for data retrieval tasks.","sidebar":"integrations"},"integrations/retrievers/elastic_search_bm25":{"id":"integrations/retrievers/elastic_search_bm25","title":"ElasticSearch BM25","description":"Elasticsearch is a distributed, RESTful search and analytics engine. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.","sidebar":"integrations"},"integrations/retrievers/elasticsearch_retriever":{"id":"integrations/retrievers/elasticsearch_retriever","title":"ElasticsearchRetriever","description":"Elasticsearch is a distributed, RESTful search and analytics engine. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents. It supports keyword search, vector search, hybrid search and complex filtering.","sidebar":"integrations"},"integrations/retrievers/embedchain":{"id":"integrations/retrievers/embedchain","title":"Embedchain","description":"Embedchain is a RAG framework to create data pipelines. It loads, indexes, retrieves and syncs all the data.","sidebar":"integrations"},"integrations/retrievers/flashrank-reranker":{"id":"integrations/retrievers/flashrank-reranker","title":"FlashRank reranker","description":"FlashRank is the Ultra-lite & Super-fast Python library to add re-ranking to your existing search & retrieval pipelines. It is based on SoTA cross-encoders, with gratitude to all the model owners.","sidebar":"integrations"},"integrations/retrievers/fleet_context":{"id":"integrations/retrievers/fleet_context","title":"Fleet AI Context","description":"Fleet AI Context is a dataset of high-quality embeddings of the top 1200 most popular & permissive Python Libraries & their documentation.","sidebar":"integrations"},"integrations/retrievers/google_drive":{"id":"integrations/retrievers/google_drive","title":"Google Drive","description":"This notebook covers how to retrieve documents from Google Drive.","sidebar":"integrations"},"integrations/retrievers/google_vertex_ai_search":{"id":"integrations/retrievers/google_vertex_ai_search","title":"Google Vertex AI Search","description":"Google Vertex AI Search (formerly known as Enterprise Search on Generative AI App Builder) is a part of the Vertex AI machine learning platform offered by Google Cloud.","sidebar":"integrations"},"integrations/retrievers/graph_rag":{"id":"integrations/retrievers/graph_rag","title":"Graph RAG","description":"Graph traversal over any Vector Store using document metadata.","sidebar":"integrations"},"integrations/retrievers/ibm_watsonx_ranker":{"id":"integrations/retrievers/ibm_watsonx_ranker","title":"WatsonxRerank","description":"WatsonxRerank is a wrapper for IBM watsonx.ai foundation models.","sidebar":"integrations"},"integrations/retrievers/index":{"id":"integrations/retrievers/index","title":"Retrievers","description":"A retriever is an interface that returns documents given an unstructured query.","sidebar":"integrations"},"integrations/retrievers/jaguar":{"id":"integrations/retrievers/jaguar","title":"JaguarDB Vector Database","description":"[JaguarDB Vector Database](http://www.jaguardb.com/windex.html","sidebar":"integrations"},"integrations/retrievers/kay":{"id":"integrations/retrievers/kay","title":"Kay.ai","description":"Kai Data API built for RAG \ud83d\udd75\ufe0f We are curating the world\'s largest datasets as high-quality embeddings so your AI agents can retrieve context on the fly. Latest models, fast retrieval, and zero infra.","sidebar":"integrations"},"integrations/retrievers/kinetica":{"id":"integrations/retrievers/kinetica","title":"Kinetica Vectorstore based Retriever","description":"Kinetica is a database with integrated support for vector similarity search","sidebar":"integrations"},"integrations/retrievers/knn":{"id":"integrations/retrievers/knn","title":"kNN","description":"In statistics, the k-nearest neighbours algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover. It is used for classification and regression.","sidebar":"integrations"},"integrations/retrievers/linkup_search":{"id":"integrations/retrievers/linkup_search","title":"LinkupSearchRetriever","description":"Linkup provides an API to connect LLMs to the web and the Linkup Premium Partner sources.","sidebar":"integrations"},"integrations/retrievers/llmlingua":{"id":"integrations/retrievers/llmlingua","title":"LLMLingua Document Compressor","description":"LLMLingua utilizes a compact, well-trained language model (e.g., GPT2-small, LLaMA-7B) to identify and remove non-essential tokens in prompts. This approach enables efficient inference with large language models (LLMs), achieving up to 20x compression with minimal performance loss.","sidebar":"integrations"},"integrations/retrievers/merger_retriever":{"id":"integrations/retrievers/merger_retriever","title":"LOTR (Merger Retriever)","description":"Lord of the Retrievers (LOTR), also known as MergerRetriever, takes a list of retrievers as input and merges the results of their getrelevantdocuments() methods into a single list. The merged results will be a list of documents that are relevant to the query and that have been ranked by the different retrievers.","sidebar":"integrations"},"integrations/retrievers/metal":{"id":"integrations/retrievers/metal","title":"Metal","description":"Metal is a managed service for ML Embeddings.","sidebar":"integrations"},"integrations/retrievers/milvus_hybrid_search":{"id":"integrations/retrievers/milvus_hybrid_search","title":"Milvus Hybrid Search Retriever","description":"Milvus is an open-source vector database built to power embedding similarity search and AI applications. Milvus makes unstructured data search more accessible, and provides a consistent user experience regardless of the deployment environment.","sidebar":"integrations"},"integrations/retrievers/nanopq":{"id":"integrations/retrievers/nanopq","title":"NanoPQ (Product Quantization)","description":"Product Quantization algorithm (k-NN) in brief is a quantization algorithm that helps in compression of database vectors which helps in semantic search when large datasets are involved. In a nutshell, the embedding is split into M subspaces which further goes through clustering. Upon clustering the vectors the centroid vector gets mapped to the vectors present in the each of the clusters of the subspace.","sidebar":"integrations"},"integrations/retrievers/needle":{"id":"integrations/retrievers/needle","title":"needle","description":"Needle Retriever","sidebar":"integrations"},"integrations/retrievers/nimble":{"id":"integrations/retrievers/nimble","title":"NimbleSearchRetriever","description":"NimbleSearchRetriever enables developers to build RAG applications and AI Agents that can search, access, and retrieve online information from anywhere on the web.","sidebar":"integrations"},"integrations/retrievers/outline":{"id":"integrations/retrievers/outline","title":"Outline","description":"Outline is an open-source collaborative knowledge base platform designed for team information sharing.","sidebar":"integrations"},"integrations/retrievers/permit":{"id":"integrations/retrievers/permit","title":"PermitRetriever","description":"Permit is an access control platform that provides fine-grained, real-time permission management using various models such as RBAC, ABAC, and ReBAC. It enables organizations to enforce dynamic policies across their applications, ensuring that only authorized users can access specific resources.","sidebar":"integrations"},"integrations/retrievers/pinecone_hybrid_search":{"id":"integrations/retrievers/pinecone_hybrid_search","title":"Pinecone Hybrid Search","description":"Pinecone is a vector database with broad functionality.","sidebar":"integrations"},"integrations/retrievers/pubmed":{"id":"integrations/retrievers/pubmed","title":"PubMed","description":"PubMed\xae by The National Center for Biotechnology Information, National Library of Medicine comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full text content from PubMed Central and publisher web sites.","sidebar":"integrations"},"integrations/retrievers/qdrant-sparse":{"id":"integrations/retrievers/qdrant-sparse","title":"Qdrant Sparse Vector","description":"Qdrant is an open-source, high-performance vector search engine/database.","sidebar":"integrations"},"integrations/retrievers/ragatouille":{"id":"integrations/retrievers/ragatouille","title":"RAGatouille","description":"RAGatouille makes it as simple as can be to use ColBERT!","sidebar":"integrations"},"integrations/retrievers/re_phrase":{"id":"integrations/retrievers/re_phrase","title":"RePhraseQuery","description":"RePhraseQuery is a simple retriever that applies an LLM between the user input and the query passed by the retriever.","sidebar":"integrations"},"integrations/retrievers/rememberizer":{"id":"integrations/retrievers/rememberizer","title":"Rememberizer","description":"Rememberizer is a knowledge enhancement service for AI applications created by  SkyDeck AI Inc.","sidebar":"integrations"},"integrations/retrievers/sec_filings":{"id":"integrations/retrievers/sec_filings","title":"SEC filing","description":"SEC filing is a financial statement or other formal document submitted to the U.S. Securities and Exchange Commission (SEC). Public companies, certain insiders, and broker-dealers are required to make regular SEC filings. Investors and financial professionals rely on these filings for information about companies they are evaluating for investment purposes.","sidebar":"integrations"},"integrations/retrievers/self_query/activeloop_deeplake_self_query":{"id":"integrations/retrievers/self_query/activeloop_deeplake_self_query","title":"Deep Lake","description":"Deep Lake is a multimodal database for building AI applications","sidebar":"integrations"},"integrations/retrievers/self_query/astradb":{"id":"integrations/retrievers/self_query/astradb","title":"Astra DB (Cassandra)","description":"DataStax Astra DB is a serverless vector-capable database built on Cassandra and made conveniently available through an easy-to-use JSON API.","sidebar":"integrations"},"integrations/retrievers/self_query/chroma_self_query":{"id":"integrations/retrievers/self_query/chroma_self_query","title":"Chroma","description":"Chroma is a vector database for building AI applications with embeddings.","sidebar":"integrations"},"integrations/retrievers/self_query/dashvector":{"id":"integrations/retrievers/self_query/dashvector","title":"DashVector","description":"DashVector is a fully managed vector DB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.","sidebar":"integrations"},"integrations/retrievers/self_query/databricks_vector_search":{"id":"integrations/retrievers/self_query/databricks_vector_search","title":"Databricks Vector Search","description":"Databricks Vector Search is a serverless similarity search engine that allows you to store a vector representation of your data, including metadata, in a vector database. With Vector Search, you can create auto-updating vector search indexes from Delta tables managed by Unity Catalog and query them with a simple API to return the most similar vectors.","sidebar":"integrations"},"integrations/retrievers/self_query/dingo":{"id":"integrations/retrievers/self_query/dingo","title":"DingoDB","description":"DingoDB is a distributed multi-mode vector database, which combines the characteristics of data lakes and vector databases, and can store data of any type and size (Key-Value, PDF, audio, video, etc.). It has real-time low-latency processing capabilities to achieve rapid insight and response, and can efficiently conduct instant analysis and process multi-modal data.","sidebar":"integrations"},"integrations/retrievers/self_query/elasticsearch_self_query":{"id":"integrations/retrievers/self_query/elasticsearch_self_query","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine.","sidebar":"integrations"},"integrations/retrievers/self_query/hanavector_self_query":{"id":"integrations/retrievers/self_query/hanavector_self_query","title":"SAP HANA Cloud Vector Engine","description":"For more information on how to setup the SAP HANA vetor store, take a look at the documentation.","sidebar":"integrations"},"integrations/retrievers/self_query/index":{"id":"integrations/retrievers/self_query/index","title":"Self-querying retrievers","description":"Learn about how the self-querying retriever works here.","sidebar":"integrations"},"integrations/retrievers/self_query/milvus_self_query":{"id":"integrations/retrievers/self_query/milvus_self_query","title":"Milvus","description":"Milvus is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.","sidebar":"integrations"},"integrations/retrievers/self_query/mongodb_atlas":{"id":"integrations/retrievers/self_query/mongodb_atlas","title":"MongoDB Atlas","description":"MongoDB Atlas is a document database that can be","sidebar":"integrations"},"integrations/retrievers/self_query/myscale_self_query":{"id":"integrations/retrievers/self_query/myscale_self_query","title":"MyScale","description":"MyScale is an integrated vector database. You can access your database in SQL and also from here, LangChain.","sidebar":"integrations"},"integrations/retrievers/self_query/neo4j_self_query":{"id":"integrations/retrievers/self_query/neo4j_self_query","title":"Neo4j","description":"Neo4j is a graph database that stores nodes and relationships, that also supports native vector search.","sidebar":"integrations"},"integrations/retrievers/self_query/opensearch_self_query":{"id":"integrations/retrievers/self_query/opensearch_self_query","title":"OpenSearch","description":"OpenSearch is a scalable, flexible, and extensible open-source software suite for search, analytics, and observability applications licensed under Apache 2.0. OpenSearch is a distributed search and analytics engine based on Apache Lucene.","sidebar":"integrations"},"integrations/retrievers/self_query/pgvector_self_query":{"id":"integrations/retrievers/self_query/pgvector_self_query","title":"PGVector (Postgres)","description":"PGVector is a vector similarity search package for Postgres data base.","sidebar":"integrations"},"integrations/retrievers/self_query/pinecone":{"id":"integrations/retrievers/self_query/pinecone","title":"Pinecone","description":"Pinecone is a vector database with broad functionality.","sidebar":"integrations"},"integrations/retrievers/self_query/qdrant_self_query":{"id":"integrations/retrievers/self_query/qdrant_self_query","title":"Qdrant","description":"Qdrant (read: quadrant) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support.","sidebar":"integrations"},"integrations/retrievers/self_query/redis_self_query":{"id":"integrations/retrievers/self_query/redis_self_query","title":"Redis","description":"Redis is an open-source key-value store that can be used as a cache, message broker, database, vector database and more.","sidebar":"integrations"},"integrations/retrievers/self_query/supabase_self_query":{"id":"integrations/retrievers/self_query/supabase_self_query","title":"Supabase (Postgres)","description":"Supabase is an open-source Firebase alternative.","sidebar":"integrations"},"integrations/retrievers/self_query/tencentvectordb":{"id":"integrations/retrievers/self_query/tencentvectordb","title":"Tencent Cloud VectorDB","description":"Tencent Cloud VectorDB is a fully managed, self-developed, enterprise-level distributed database    service designed for storing, retrieving, and analyzing multi-dimensional vector data.","sidebar":"integrations"},"integrations/retrievers/self_query/timescalevector_self_query":{"id":"integrations/retrievers/self_query/timescalevector_self_query","title":"Timescale Vector (Postgres)","description":"Timescale Vector is PostgreSQL++ for AI applications. It enables you to efficiently store and query billions of vector embeddings in PostgreSQL.","sidebar":"integrations"},"integrations/retrievers/self_query/vectara_self_query":{"id":"integrations/retrievers/self_query/vectara_self_query","title":"Vectara self-querying","description":"Vectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.","sidebar":"integrations"},"integrations/retrievers/self_query/weaviate_self_query":{"id":"integrations/retrievers/self_query/weaviate_self_query","title":"Weaviate","description":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from","sidebar":"integrations"},"integrations/retrievers/singlestoredb":{"id":"integrations/retrievers/singlestoredb","title":"SingleStoreDB","description":"SingleStoreDB is a high-performance distributed SQL database that supports deployment both in the cloud and on-premises. It provides vector storage, and vector functions including dotproduct and euclideandistance, thereby supporting AI applications that require text similarity matching.","sidebar":"integrations"},"integrations/retrievers/svm":{"id":"integrations/retrievers/svm","title":"SVM","description":"Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.","sidebar":"integrations"},"integrations/retrievers/tavily":{"id":"integrations/retrievers/tavily","title":"TavilySearchAPIRetriever","description":"Tavily\'s Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.","sidebar":"integrations"},"integrations/retrievers/tf_idf":{"id":"integrations/retrievers/tf_idf","title":"TF-IDF","description":"TF-IDF means term-frequency times inverse document-frequency.","sidebar":"integrations"},"integrations/retrievers/thirdai_neuraldb":{"id":"integrations/retrievers/thirdai_neuraldb","title":"**NeuralDB**","description":"NeuralDB is a CPU-friendly and fine-tunable retrieval engine developed by ThirdAI.","sidebar":"integrations"},"integrations/retrievers/vespa":{"id":"integrations/retrievers/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database. It supports vector search (ANN), lexical search, and search in structured data, all in the same query.","sidebar":"integrations"},"integrations/retrievers/wikipedia":{"id":"integrations/retrievers/wikipedia","title":"WikipediaRetriever","description":"Overview","sidebar":"integrations"},"integrations/retrievers/you-retriever":{"id":"integrations/retrievers/you-retriever","title":"You.com","description":"you.com API is a suite of tools designed to help developers ground the output of LLMs in the most recent, most accurate, most relevant information that may not have been included in their training dataset.","sidebar":"integrations"},"integrations/retrievers/zep_cloud_memorystore":{"id":"integrations/retrievers/zep_cloud_memorystore","title":"Zep Cloud","description":"Retriever Example for Zep Cloud","sidebar":"integrations"},"integrations/retrievers/zep_memorystore":{"id":"integrations/retrievers/zep_memorystore","title":"Zep Open Source","description":"Retriever Example for Zep","sidebar":"integrations"},"integrations/retrievers/zilliz_cloud_pipeline":{"id":"integrations/retrievers/zilliz_cloud_pipeline","title":"Zilliz Cloud Pipeline","description":"Zilliz Cloud Pipelines transform your unstructured data to a searchable vector collection, chaining up the embedding, ingestion, search, and deletion of your data.","sidebar":"integrations"},"integrations/retrievers/zotero":{"id":"integrations/retrievers/zotero","title":"ZoteroRetriever","description":"This will help you getting started with the Zotero retriever. For detailed documentation of all ZoteroRetriever features and configurations head to the Github page.","sidebar":"integrations"},"integrations/splitters/writer_text_splitter":{"id":"integrations/splitters/writer_text_splitter","title":"Writer Text Splitter","description":"This notebook provides a quick overview for getting started with Writer\'s text splitter."},"integrations/stores/astradb":{"id":"integrations/stores/astradb","title":"AstraDBByteStore","description":"This will help you get started with Astra DB key-value stores. For detailed documentation of all AstraDBByteStore features and configurations head to the API reference.","sidebar":"integrations"},"integrations/stores/cassandra":{"id":"integrations/stores/cassandra","title":"CassandraByteStore","description":"This will help you get started with Cassandra key-value stores. For detailed documentation of all CassandraByteStore features and configurations head to the API reference.","sidebar":"integrations"},"integrations/stores/elasticsearch":{"id":"integrations/stores/elasticsearch","title":"ElasticsearchEmbeddingsCache","description":"This will help you get started with Elasticsearch key-value stores. For detailed documentation of all ElasticsearchEmbeddingsCache features and configurations head to the API reference.","sidebar":"integrations"},"integrations/stores/file_system":{"id":"integrations/stores/file_system","title":"LocalFileStore","description":"This will help you get started with local filesystem key-value stores. For detailed documentation of all LocalFileStore features and configurations head to the API reference.","sidebar":"integrations"},"integrations/stores/in_memory":{"id":"integrations/stores/in_memory","title":"InMemoryByteStore","description":"This guide will help you get started with in-memory key-value stores. For detailed documentation of all InMemoryByteStore features and configurations head to the API reference.","sidebar":"integrations"},"integrations/stores/index":{"id":"integrations/stores/index","title":"Key-value stores","description":"Key-value stores are used by other LangChain components to store and retrieve data.","sidebar":"integrations"},"integrations/stores/redis":{"id":"integrations/stores/redis","title":"RedisStore","description":"This will help you get started with Redis key-value stores. For detailed documentation of all RedisStore features and configurations head to the API reference.","sidebar":"integrations"},"integrations/stores/upstash_redis":{"id":"integrations/stores/upstash_redis","title":"UpstashRedisByteStore","description":"This will help you get started with Upstash redis key-value stores. For detailed documentation of all UpstashRedisByteStore features and configurations head to the API reference.","sidebar":"integrations"},"integrations/text_embedding/ai21":{"id":"integrations/text_embedding/ai21","title":"AI21Embeddings","description":"This will help you get started with AI21 embedding models using LangChain. For detailed documentation on AI21Embeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/aleph_alpha":{"id":"integrations/text_embedding/aleph_alpha","title":"Aleph Alpha","description":"There are two possible ways to use Aleph Alpha\'s semantic embeddings. If you have texts with a dissimilar structure (e.g. a Document and a Query) you would want to use asymmetric embeddings. Conversely, for texts with comparable structures, symmetric embeddings are the suggested approach.","sidebar":"integrations"},"integrations/text_embedding/anyscale":{"id":"integrations/text_embedding/anyscale","title":"Anyscale","description":"Let\'s load the Anyscale Embedding class.","sidebar":"integrations"},"integrations/text_embedding/ascend":{"id":"integrations/text_embedding/ascend","title":"ascend","description":"[[-0.00348254  0.03098977 -0.00203087 ...  0.08492374  0.03970494","sidebar":"integrations"},"integrations/text_embedding/awadb":{"id":"integrations/text_embedding/awadb","title":"AwaDB","description":"AwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.","sidebar":"integrations"},"integrations/text_embedding/azureopenai":{"id":"integrations/text_embedding/azureopenai","title":"AzureOpenAIEmbeddings","description":"This will help you get started with AzureOpenAI embedding models using LangChain. For detailed documentation on AzureOpenAIEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/baichuan":{"id":"integrations/text_embedding/baichuan","title":"Baichuan Text Embeddings","description":"As of today (Jan 25th, 2024) BaichuanTextEmbeddings ranks #1 in C-MTEB (Chinese Multi-Task Embedding Benchmark) leaderboard.","sidebar":"integrations"},"integrations/text_embedding/baidu_qianfan_endpoint":{"id":"integrations/text_embedding/baidu_qianfan_endpoint","title":"Baidu Qianfan","description":"Baidu AI Cloud Qianfan Platform is a one-stop large model development and service operation platform for enterprise developers. Qianfan not only provides including the model of Wenxin Yiyan (ERNIE-Bot) and the third-party open-source models, but also provides various AI development tools and the whole set of development environment, which facilitates customers to use and develop large model applications easily.","sidebar":"integrations"},"integrations/text_embedding/bedrock":{"id":"integrations/text_embedding/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that offers a choice of","sidebar":"integrations"},"integrations/text_embedding/bge_huggingface":{"id":"integrations/text_embedding/bge_huggingface","title":"BGE on Hugging Face","description":"BGE models on the HuggingFace are one of the best open-source embedding models.","sidebar":"integrations"},"integrations/text_embedding/bookend":{"id":"integrations/text_embedding/bookend","title":"Bookend AI","description":"Let\'s load the Bookend AI Embeddings class.","sidebar":"integrations"},"integrations/text_embedding/clarifai":{"id":"integrations/text_embedding/clarifai","title":"Clarifai","description":"Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference.","sidebar":"integrations"},"integrations/text_embedding/cloudflare_workersai":{"id":"integrations/text_embedding/cloudflare_workersai","title":"Cloudflare Workers AI","description":"Cloudflare, Inc. (Wikipedia) is an American company that provides content delivery network services, cloud cybersecurity, DDoS mitigation, and ICANN-accredited domain registration services.","sidebar":"integrations"},"integrations/text_embedding/clova":{"id":"integrations/text_embedding/clova","title":"Clova Embeddings","description":"Clova offers an embeddings service","sidebar":"integrations"},"integrations/text_embedding/cohere":{"id":"integrations/text_embedding/cohere","title":"CohereEmbeddings","description":"This will help you get started with Cohere embedding models using LangChain. For detailed documentation on CohereEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/dashscope":{"id":"integrations/text_embedding/dashscope","title":"DashScope","description":"Let\'s load the DashScope Embedding class.","sidebar":"integrations"},"integrations/text_embedding/databricks":{"id":"integrations/text_embedding/databricks","title":"DatabricksEmbeddings","description":"Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.","sidebar":"integrations"},"integrations/text_embedding/deepinfra":{"id":"integrations/text_embedding/deepinfra","title":"DeepInfra","description":"DeepInfra is a serverless inference as a service that provides access to a variety of LLMs and embeddings models. This notebook goes over how to use LangChain with DeepInfra for text embeddings.","sidebar":"integrations"},"integrations/text_embedding/edenai":{"id":"integrations/text_embedding/edenai","title":"EDEN AI","description":"Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)","sidebar":"integrations"},"integrations/text_embedding/elasticsearch":{"id":"integrations/text_embedding/elasticsearch","title":"Elasticsearch","description":"Walkthrough of how to generate embeddings using a hosted embedding model in Elasticsearch","sidebar":"integrations"},"integrations/text_embedding/embaas":{"id":"integrations/text_embedding/embaas","title":"Embaas","description":"embaas is a fully managed NLP API service that offers features like embedding generation, document text extraction, document to embeddings and more. You can choose a variety of pre-trained models.","sidebar":"integrations"},"integrations/text_embedding/ernie":{"id":"integrations/text_embedding/ernie","title":"ERNIE","description":"ERNIE Embedding-V1 is a text representation model based on Baidu Wenxin large-scale model technology,","sidebar":"integrations"},"integrations/text_embedding/fake":{"id":"integrations/text_embedding/fake","title":"Fake Embeddings","description":"LangChain also provides a fake embedding class. You can use this to test your pipelines.","sidebar":"integrations"},"integrations/text_embedding/fastembed":{"id":"integrations/text_embedding/fastembed","title":"FastEmbed by Qdrant","description":"FastEmbed from Qdrant is a lightweight, fast, Python library built for embedding generation.","sidebar":"integrations"},"integrations/text_embedding/fireworks":{"id":"integrations/text_embedding/fireworks","title":"FireworksEmbeddings","description":"This will help you get started with Fireworks embedding models using LangChain. For detailed documentation on FireworksEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/gigachat":{"id":"integrations/text_embedding/gigachat","title":"GigaChat","description":"This notebook shows how to use LangChain with GigaChat embeddings.","sidebar":"integrations"},"integrations/text_embedding/google_generative_ai":{"id":"integrations/text_embedding/google_generative_ai","title":"Google Generative AI Embeddings","description":"Connect to Google\'s generative AI embeddings service using the GoogleGenerativeAIEmbeddings class, found in the langchain-google-genai package.","sidebar":"integrations"},"integrations/text_embedding/google_vertex_ai_palm":{"id":"integrations/text_embedding/google_vertex_ai_palm","title":"Google Vertex AI Embeddings","description":"This will help you get started with Google Vertex AI Embeddings models using LangChain. For detailed documentation on Google Vertex AI Embeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/gpt4all":{"id":"integrations/text_embedding/gpt4all","title":"GPT4All","description":"GPT4All is a free-to-use, locally running, privacy-aware chatbot. There is no GPU or internet required. It features popular models and its own models such as GPT4All Falcon, Wizard, etc.","sidebar":"integrations"},"integrations/text_embedding/gradient":{"id":"integrations/text_embedding/gradient","title":"Gradient","description":"Gradient allows to create Embeddings as well fine tune and get completions on LLMs with a simple web API.","sidebar":"integrations"},"integrations/text_embedding/huggingfacehub":{"id":"integrations/text_embedding/huggingfacehub","title":"Hugging Face","description":"Let\'s load the Hugging Face Embedding class.","sidebar":"integrations"},"integrations/text_embedding/ibm_watsonx":{"id":"integrations/text_embedding/ibm_watsonx","title":"IBM watsonx.ai","description":"WatsonxEmbeddings is a wrapper for IBM watsonx.ai foundation models.","sidebar":"integrations"},"integrations/text_embedding/index":{"id":"integrations/text_embedding/index","title":"Embedding models","description":"Embedding models create a vector representation of a piece of text.","sidebar":"integrations"},"integrations/text_embedding/infinity":{"id":"integrations/text_embedding/infinity","title":"Infinity","description":"Infinity allows to create Embeddings using a MIT-licensed Embedding Server.","sidebar":"integrations"},"integrations/text_embedding/instruct_embeddings":{"id":"integrations/text_embedding/instruct_embeddings","title":"Instruct Embeddings on Hugging Face","description":"Hugging Face sentence-transformers is a Python framework for state-of-the-art sentence, text and image embeddings.","sidebar":"integrations"},"integrations/text_embedding/ipex_llm":{"id":"integrations/text_embedding/ipex_llm","title":"IPEX-LLM: Local BGE Embeddings on Intel CPU","description":"IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latency.","sidebar":"integrations"},"integrations/text_embedding/ipex_llm_gpu":{"id":"integrations/text_embedding/ipex_llm_gpu","title":"IPEX-LLM: Local BGE Embeddings on Intel GPU","description":"IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latency.","sidebar":"integrations"},"integrations/text_embedding/itrex":{"id":"integrations/text_embedding/itrex","title":"Intel\xae Extension for Transformers Quantized Text Embeddings","description":"Load quantized BGE embedding models generated by Intel\xae Extension for Transformers (ITREX) and use ITREX Neural Engine, a high-performance NLP backend, to accelerate the inference of models without compromising accuracy.","sidebar":"integrations"},"integrations/text_embedding/jina":{"id":"integrations/text_embedding/jina","title":"Jina","description":"You can check the list of available models from here.","sidebar":"integrations"},"integrations/text_embedding/johnsnowlabs_embedding":{"id":"integrations/text_embedding/johnsnowlabs_embedding","title":"John Snow Labs","description":"John Snow Labs NLP & LLM ecosystem includes software libraries for state-of-the-art AI at scale, Responsible AI, No-Code AI, and access to over 20,000 models for Healthcare, Legal, Finance, etc.","sidebar":"integrations"},"integrations/text_embedding/laser":{"id":"integrations/text_embedding/laser","title":"LASER Language-Agnostic SEntence Representations Embeddings by Meta AI","description":"LASER is a Python library developed by the Meta AI Research team and used for creating multilingual sentence embeddings for over 147 languages as of 2/25/2024","sidebar":"integrations"},"integrations/text_embedding/lindorm":{"id":"integrations/text_embedding/lindorm","title":"LindormAIEmbeddings","description":"This will help you get started with Lindorm embedding models using LangChain.","sidebar":"integrations"},"integrations/text_embedding/llamacpp":{"id":"integrations/text_embedding/llamacpp","title":"Llama.cpp","description":"llama.cpp python library is a simple Python bindings for @ggerganov","sidebar":"integrations"},"integrations/text_embedding/llamafile":{"id":"integrations/text_embedding/llamafile","title":"llamafile","description":"Let\'s load the llamafile Embeddings class.","sidebar":"integrations"},"integrations/text_embedding/llm_rails":{"id":"integrations/text_embedding/llm_rails","title":"LLMRails","description":"Let\'s load the LLMRails Embeddings class.","sidebar":"integrations"},"integrations/text_embedding/localai":{"id":"integrations/text_embedding/localai","title":"LocalAI","description":"langchain-localai is a 3rd party integration package for LocalAI. It provides a simple way to use LocalAI services in Langchain.","sidebar":"integrations"},"integrations/text_embedding/minimax":{"id":"integrations/text_embedding/minimax","title":"MiniMax","description":"MiniMax offers an embeddings service.","sidebar":"integrations"},"integrations/text_embedding/mistralai":{"id":"integrations/text_embedding/mistralai","title":"MistralAIEmbeddings","description":"This will help you get started with MistralAI embedding models using LangChain. For detailed documentation on MistralAIEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/model2vec":{"id":"integrations/text_embedding/model2vec","title":"model2vec","description":"Overview","sidebar":"integrations"},"integrations/text_embedding/modelscope_embedding":{"id":"integrations/text_embedding/modelscope_embedding","title":"ModelScopeEmbeddings","description":"ModelScope (Home | GitHub) is built upon the notion of \u201cModel-as-a-Service\u201d (MaaS). It seeks to bring together most advanced machine learning models from the AI community, and streamlines the process of leveraging AI models in real-world applications. The core ModelScope library open-sourced in this repository provides the interfaces and implementations that allow developers to perform model inference, training and evaluation.","sidebar":"integrations"},"integrations/text_embedding/mosaicml":{"id":"integrations/text_embedding/mosaicml","title":"MosaicML","description":"MosaicML offers a managed inference service. You can either use a variety of open-source models, or deploy your own.","sidebar":"integrations"},"integrations/text_embedding/naver":{"id":"integrations/text_embedding/naver","title":"ClovaXEmbeddings","description":"This notebook covers how to get started with embedding models provided by CLOVA Studio. For detailed documentation on ClovaXEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/nlp_cloud":{"id":"integrations/text_embedding/nlp_cloud","title":"NLP Cloud","description":"NLP Cloud is an artificial intelligence platform that allows you to use the most advanced AI engines, and even train your own engines with your own data.","sidebar":"integrations"},"integrations/text_embedding/nomic":{"id":"integrations/text_embedding/nomic","title":"NomicEmbeddings","description":"This will help you get started with Nomic embedding models using LangChain. For detailed documentation on NomicEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/nvidia_ai_endpoints":{"id":"integrations/text_embedding/nvidia_ai_endpoints","title":"NVIDIA NIMs","description":"The langchain-nvidia-ai-endpoints package contains LangChain integrations building applications with models on","sidebar":"integrations"},"integrations/text_embedding/oci_generative_ai":{"id":"integrations/text_embedding/oci_generative_ai","title":"Oracle Cloud Infrastructure Generative AI","description":"Oracle Cloud Infrastructure (OCI) Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs), that cover a wide range of use cases, and which are available through a single API.","sidebar":"integrations"},"integrations/text_embedding/ollama":{"id":"integrations/text_embedding/ollama","title":"OllamaEmbeddings","description":"This will help you get started with Ollama embedding models using LangChain. For detailed documentation on OllamaEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/open_clip":{"id":"integrations/text_embedding/open_clip","title":"OpenClip","description":"OpenClip is an source implementation of OpenAI\'s CLIP.","sidebar":"integrations"},"integrations/text_embedding/openai":{"id":"integrations/text_embedding/openai","title":"OpenAIEmbeddings","description":"This will help you get started with OpenAI embedding models using LangChain. For detailed documentation on OpenAIEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/openvino":{"id":"integrations/text_embedding/openvino","title":"OpenVINO","description":"OpenVINO\u2122 is an open-source toolkit for optimizing and deploying AI inference. The OpenVINO\u2122 Runtime supports various hardware devices including x86 and ARM CPUs, and Intel GPUs. It can help to boost deep learning performance in Computer Vision, Automatic Speech Recognition, Natural Language Processing and other common tasks.","sidebar":"integrations"},"integrations/text_embedding/optimum_intel":{"id":"integrations/text_embedding/optimum_intel","title":"Embedding Documents using Optimized and Quantized Embedders","description":"Embedding all documents using Quantized Embedders.","sidebar":"integrations"},"integrations/text_embedding/oracleai":{"id":"integrations/text_embedding/oracleai","title":"Oracle AI Vector Search: Generate Embeddings","description":"Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads that allows you to query data based on semantics, rather than keywords.","sidebar":"integrations"},"integrations/text_embedding/ovhcloud":{"id":"integrations/text_embedding/ovhcloud","title":"OVHcloud","description":"In order to use this model you need to create a new token on the AI Endpoints website//endpoints.ai.cloud.ovh.net/.","sidebar":"integrations"},"integrations/text_embedding/pinecone":{"id":"integrations/text_embedding/pinecone","title":"Pinecone Embeddings","description":"Pinecone\'s inference API can be accessed via PineconeEmbeddings. Providing text embeddings via the Pinecone service. We start by installing prerequisite libraries:","sidebar":"integrations"},"integrations/text_embedding/predictionguard":{"id":"integrations/text_embedding/predictionguard","title":"PredictionGuardEmbeddings","description":"Prediction Guard is a secure, scalable GenAI platform that safeguards sensitive data, prevents common AI malfunctions, and runs on affordable hardware.","sidebar":"integrations"},"integrations/text_embedding/premai":{"id":"integrations/text_embedding/premai","title":"PremAI","description":"PremAI is an all-in-one platform that simplifies the creation of robust, production-ready applications powered by Generative AI. By streamlining the development process, PremAI allows you to concentrate on enhancing user experience and driving overall growth for your application. You can quickly start using our platform here.","sidebar":"integrations"},"integrations/text_embedding/sagemaker-endpoint":{"id":"integrations/text_embedding/sagemaker-endpoint","title":"SageMaker","description":"Let\'s load the SageMaker Endpoints Embeddings class. The class can be used if you host, e.g. your own Hugging Face model on SageMaker.","sidebar":"integrations"},"integrations/text_embedding/sambanova":{"id":"integrations/text_embedding/sambanova","title":"SambaStudioEmbeddings","description":"This will help you get started with SambaNova\'s SambaStudio embedding models using LangChain. For detailed documentation on SambaStudioEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/self-hosted":{"id":"integrations/text_embedding/self-hosted","title":"Self Hosted","description":"Let\'s load the SelfHostedEmbeddings, SelfHostedHuggingFaceEmbeddings, and SelfHostedHuggingFaceInstructEmbeddings classes.","sidebar":"integrations"},"integrations/text_embedding/sentence_transformers":{"id":"integrations/text_embedding/sentence_transformers","title":"Sentence Transformers on Hugging Face","description":"Hugging Face sentence-transformers is a Python framework for state-of-the-art sentence, text and image embeddings.","sidebar":"integrations"},"integrations/text_embedding/solar":{"id":"integrations/text_embedding/solar","title":"Solar","description":"Solar offers an embeddings service.","sidebar":"integrations"},"integrations/text_embedding/spacy_embedding":{"id":"integrations/text_embedding/spacy_embedding","title":"SpaCy","description":"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.","sidebar":"integrations"},"integrations/text_embedding/sparkllm":{"id":"integrations/text_embedding/sparkllm","title":"SparkLLM Text Embeddings","description":"Official Website//www.xfyun.cn/doc/spark/Embeddingnewapi.html","sidebar":"integrations"},"integrations/text_embedding/tensorflowhub":{"id":"integrations/text_embedding/tensorflowhub","title":"TensorFlow Hub","description":"TensorFlow Hub is a repository of trained machine learning models ready for fine-tuning and deployable anywhere. Reuse trained models like BERT and Faster R-CNN with just a few lines of code.","sidebar":"integrations"},"integrations/text_embedding/text_embeddings_inference":{"id":"integrations/text_embedding/text_embeddings_inference","title":"Text Embeddings Inference","description":"Hugging Face Text Embeddings Inference (TEI) is a toolkit for deploying and serving open-source","sidebar":"integrations"},"integrations/text_embedding/textembed":{"id":"integrations/text_embedding/textembed","title":"TextEmbed - Embedding Inference Server","description":"TextEmbed is a high-throughput, low-latency REST API designed for serving vector embeddings. It supports a wide range of sentence-transformer models and frameworks, making it suitable for various applications in natural language processing.","sidebar":"integrations"},"integrations/text_embedding/titan_takeoff":{"id":"integrations/text_embedding/titan_takeoff","title":"Titan Takeoff","description":"TitanML helps businesses build and deploy better, smaller, cheaper, and faster NLP models through our training, compression, and inference optimization platform.","sidebar":"integrations"},"integrations/text_embedding/together":{"id":"integrations/text_embedding/together","title":"TogetherEmbeddings","description":"This will help you get started with Together embedding models using LangChain. For detailed documentation on TogetherEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/text_embedding/upstage":{"id":"integrations/text_embedding/upstage","title":"UpstageEmbeddings","description":"This notebook covers how to get started with Upstage embedding models.","sidebar":"integrations"},"integrations/text_embedding/volcengine":{"id":"integrations/text_embedding/volcengine","title":"Volc Engine","description":"This notebook provides you with a guide on how to load the Volcano Embedding class.","sidebar":"integrations"},"integrations/text_embedding/voyageai":{"id":"integrations/text_embedding/voyageai","title":"Voyage AI","description":"Voyage AI provides cutting-edge embedding/vectorizations models.","sidebar":"integrations"},"integrations/text_embedding/xinference":{"id":"integrations/text_embedding/xinference","title":"Xorbits inference (Xinference)","description":"This notebook goes over how to use Xinference embeddings within LangChain","sidebar":"integrations"},"integrations/text_embedding/yandex":{"id":"integrations/text_embedding/yandex","title":"YandexGPT","description":"This notebook goes over how to use Langchain with YandexGPT embeddings models.","sidebar":"integrations"},"integrations/text_embedding/zhipuai":{"id":"integrations/text_embedding/zhipuai","title":"ZhipuAIEmbeddings","description":"This will help you get started with ZhipuAI embedding models using LangChain. For detailed documentation on ZhipuAIEmbeddings features and configuration options, please refer to the API reference.","sidebar":"integrations"},"integrations/tools/ads4gpts":{"id":"integrations/tools/ads4gpts","title":"ADS4GPTs","description":"Integrate AI native advertising into your Agentic application.","sidebar":"integrations"},"integrations/tools/agentql":{"id":"integrations/tools/agentql","title":"AgentQL","description":"AgentQL tools provides web interaction and structured data extraction from any web page using an AgentQL query or a Natural Language prompt. AgentQL can be used across multiple languages and web pages without breaking over time and change.","sidebar":"integrations"},"integrations/tools/ainetwork":{"id":"integrations/tools/ainetwork","title":"AINetwork Toolkit","description":"AI Network is a layer 1 blockchain designed to accommodate large-scale AI models, utilizing a decentralized GPU network powered by the $AIN token, enriching AI-driven NFTs (AINFTs).","sidebar":"integrations"},"integrations/tools/alpha_vantage":{"id":"integrations/tools/alpha_vantage","title":"Alpha Vantage","description":"Alpha Vantage Alpha Vantage provides realtime and historical financial market data through a set of powerful and developer-friendly data APIs and spreadsheets.","sidebar":"integrations"},"integrations/tools/amadeus":{"id":"integrations/tools/amadeus","title":"Amadeus Toolkit","description":"This notebook walks you through connecting LangChain to the Amadeus travel APIs.","sidebar":"integrations"},"integrations/tools/apify_actors":{"id":"integrations/tools/apify_actors","title":"Apify Actor","description":"Apify Actors are cloud programs designed for a wide range of web scraping, crawling, and data extraction tasks. These actors facilitate automated data gathering from the web, enabling users to extract, process, and store information efficiently. Actors can be used to perform tasks like scraping e-commerce sites for product details, monitoring price changes, or gathering search engine results. They integrate seamlessly with Apify Datasets, allowing the structured data collected by actors to be stored, managed, and exported in formats like JSON, CSV, or Excel for further analysis or use.","sidebar":"integrations"},"integrations/tools/arxiv":{"id":"integrations/tools/arxiv","title":"ArXiv","description":"This notebook goes over how to use the arxiv tool with an agent.","sidebar":"integrations"},"integrations/tools/asknews":{"id":"integrations/tools/asknews","title":"AskNews","description":"AskNews infuses any LLM with the latest global news (or historical news), using a single natural language query. Specifically, AskNews is enriching over 300k articles per day by translating, summarizing, extracting entities, and indexing them into hot and cold vector databases. AskNews puts these vector databases on a low-latency endpoint for you. When you query AskNews, you get back a prompt-optimized string that contains all the most pertinent enrichments (e.g. entities, classifications, translation, summarization). This means that you do not need to manage your own news RAG, and you do not need to worry about how to properly convey news information in a condensed way to your LLM.","sidebar":"integrations"},"integrations/tools/awslambda":{"id":"integrations/tools/awslambda","title":"AWS Lambda","description":"Amazon AWS Lambda is a serverless computing service provided by Amazon Web Services (AWS). It helps developers to build and run applications and services without provisioning or managing servers. This serverless architecture enables you to focus on writing and deploying code, while AWS automatically takes care of scaling, patching, and managing the infrastructure required to run your applications.","sidebar":"integrations"},"integrations/tools/azure_ai_services":{"id":"integrations/tools/azure_ai_services","title":"Azure AI Services Toolkit","description":"This toolkit is used to interact with the Azure AI Services API to achieve some multimodal capabilities.","sidebar":"integrations"},"integrations/tools/azure_cognitive_services":{"id":"integrations/tools/azure_cognitive_services","title":"Azure Cognitive Services Toolkit","description":"This toolkit is used to interact with the Azure Cognitive Services API to achieve some multimodal capabilities.","sidebar":"integrations"},"integrations/tools/azure_dynamic_sessions":{"id":"integrations/tools/azure_dynamic_sessions","title":"Azure Container Apps dynamic sessions","description":"Azure Container Apps dynamic sessions provides a secure and scalable way to run a Python code interpreter in Hyper-V isolated sandboxes. This allows your agents to run potentially untrusted code in a secure environment. The code interpreter environment includes many popular Python packages, such as NumPy, pandas, and scikit-learn. See the Azure Container App docs for more info on how sessions work.","sidebar":"integrations"},"integrations/tools/bash":{"id":"integrations/tools/bash","title":"Shell (bash)","description":"Giving agents access to the shell is powerful (though risky outside a sandboxed environment).","sidebar":"integrations"},"integrations/tools/bearly":{"id":"integrations/tools/bearly","title":"Bearly Code Interpreter","description":"Bearly Code Interpreter allows for remote execution of code. This makes it perfect for a code sandbox for agents, to allow for safe implementation of things like Code Interpreter","sidebar":"integrations"},"integrations/tools/bing_search":{"id":"integrations/tools/bing_search","title":"Bing Search","description":"Bing Search is an Azure service and enables safe, ad-free, location-aware search results, surfacing relevant information from billions of web documents. Help your users find what they\'re looking for from the world-wide-web by harnessing Bing\'s ability to comb billions of webpages, images, videos, and news with a single API call.","sidebar":"integrations"},"integrations/tools/brave_search":{"id":"integrations/tools/brave_search","title":"Brave Search","description":"This notebook goes over how to use the Brave Search tool.","sidebar":"integrations"},"integrations/tools/cassandra_database":{"id":"integrations/tools/cassandra_database","title":"Cassandra Database Toolkit","description":"Apache Cassandra\xae is a widely used database for storing transactional application data. The introduction of functions and >tooling in Large Language Models has opened up some exciting use cases for existing data in Generative AI applications.","sidebar":"integrations"},"integrations/tools/cdp_agentkit":{"id":"integrations/tools/cdp_agentkit","title":"CDP Agentkit Toolkit","description":"The CDP Agentkit toolkit contains tools that enable an LLM agent to interact with the Coinbase Developer Platform. The toolkit provides a wrapper around the CDP SDK, allowing agents to perform onchain operations like transfers, trades, and smart contract interactions.","sidebar":"integrations"},"integrations/tools/chatgpt_plugins":{"id":"integrations/tools/chatgpt_plugins","title":"ChatGPT Plugins","description":"OpenAI has deprecated plugins.","sidebar":"integrations"},"integrations/tools/clickup":{"id":"integrations/tools/clickup","title":"ClickUp Toolkit","description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","sidebar":"integrations"},"integrations/tools/cogniswitch":{"id":"integrations/tools/cogniswitch","title":"Cogniswitch Toolkit","description":"CogniSwitch is used to build production ready applications that can consume, organize and retrieve knowledge flawlessly. Using the framework of your choice, in this case Langchain, CogniSwitch helps alleviate the stress of decision making when it comes to, choosing the right storage and retrieval formats. It also eradicates reliability issues and hallucinations when it comes to responses that are generated.","sidebar":"integrations"},"integrations/tools/connery":{"id":"integrations/tools/connery","title":"Connery Toolkit and Tools","description":"Using the Connery toolkit and tools, you can integrate Connery Actions into your LangChain agent.","sidebar":"integrations"},"integrations/tools/dalle_image_generator":{"id":"integrations/tools/dalle_image_generator","title":"Dall-E Image Generator","description":"OpenAI Dall-E are text-to-image models developed by OpenAI using deep learning methodologies to generate digital images from natural language descriptions, called \\"prompts\\".","sidebar":"integrations"},"integrations/tools/dappier":{"id":"integrations/tools/dappier","title":"Dappier","description":"Dappier connects any LLM or your Agentic AI to real-time, rights-cleared, proprietary data from trusted sources, making your AI an expert in anything. Our specialized models include Real-Time Web Search, News, Sports, Financial Stock Market Data, Crypto Data, and exclusive content from premium publishers. Explore a wide range of data models in our marketplace at marketplace.dappier.com.","sidebar":"integrations"},"integrations/tools/databricks":{"id":"integrations/tools/databricks","title":"Databricks Unity Catalog (UC)","description":"This notebook shows how to use UC functions as LangChain tools, with both LangChain and LangGraph agent APIs.","sidebar":"integrations"},"integrations/tools/dataforseo":{"id":"integrations/tools/dataforseo","title":"DataForSEO","description":"DataForSeo provides comprehensive SEO and digital marketing data solutions via API.","sidebar":"integrations"},"integrations/tools/dataherald":{"id":"integrations/tools/dataherald","title":"Dataherald","description":"This notebook goes over how to use the dataherald component.","sidebar":"integrations"},"integrations/tools/ddg":{"id":"integrations/tools/ddg","title":"DuckDuckGo Search","description":"This guide shows over how to use the DuckDuckGo search component.","sidebar":"integrations"},"integrations/tools/discord":{"id":"integrations/tools/discord","title":"Discord","description":"This notebook provides a quick overview for getting started with Discord tooling in langchain_discord. For more details on each tool and configuration, see the docstrings in your repository or relevant doc pages.","sidebar":"integrations"},"integrations/tools/e2b_data_analysis":{"id":"integrations/tools/e2b_data_analysis","title":"E2B Data Analysis","description":"E2B\'s cloud environments are great runtime sandboxes for LLMs.","sidebar":"integrations"},"integrations/tools/edenai_tools":{"id":"integrations/tools/edenai_tools","title":"Eden AI","description":"This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.","sidebar":"integrations"},"integrations/tools/eleven_labs_tts":{"id":"integrations/tools/eleven_labs_tts","title":"ElevenLabs Text2Speech","description":"This notebook shows how to interact with the ElevenLabs API to achieve text-to-speech capabilities.","sidebar":"integrations"},"integrations/tools/exa_search":{"id":"integrations/tools/exa_search","title":"Exa Search","description":"Exa is a search engine fully designed for use by LLMs. Search for documents on the internet using natural language queries, then retrieve cleaned HTML content from desired documents.","sidebar":"integrations"},"integrations/tools/filesystem":{"id":"integrations/tools/filesystem","title":"File System","description":"LangChain provides tools for interacting with a local file system out of the box. This notebook walks through some of them.","sidebar":"integrations"},"integrations/tools/financial_datasets":{"id":"integrations/tools/financial_datasets","title":"FinancialDatasets Toolkit","description":"The financial datasets stock market API provides REST endpoints that let you get financial data for 16,000+ tickers spanning 30+ years.","sidebar":"integrations"},"integrations/tools/fmp-data":{"id":"integrations/tools/fmp-data","title":"FMP Data","description":"Access financial market data through natural language queries.","sidebar":"integrations"},"integrations/tools/github":{"id":"integrations/tools/github","title":"Github Toolkit","description":"The Github toolkit contains tools that enable an LLM agent to interact with a github repository.","sidebar":"integrations"},"integrations/tools/gitlab":{"id":"integrations/tools/gitlab","title":"Gitlab Toolkit","description":"The Gitlab toolkit contains tools that enable an LLM agent to interact with a gitlab repository.","sidebar":"integrations"},"integrations/tools/gmail":{"id":"integrations/tools/gmail","title":"Gmail Toolkit","description":"This will help you getting started with the GMail toolkit. This toolkit interacts with the GMail API to read messages, draft and send messages, and more. For detailed documentation of all GmailToolkit features and configurations head to the API reference.","sidebar":"integrations"},"integrations/tools/golden_query":{"id":"integrations/tools/golden_query","title":"Golden Query","description":"Golden provides a set of natural language APIs for querying and enrichment using the Golden Knowledge Graph e.g. queries such as: Products from OpenAI, Generative ai companies with series a funding, and rappers who invest can be used to retrieve structured data about relevant entities.","sidebar":"integrations"},"integrations/tools/google_books":{"id":"integrations/tools/google_books","title":"Google Books","description":"Overview","sidebar":"integrations"},"integrations/tools/google_cloud_texttospeech":{"id":"integrations/tools/google_cloud_texttospeech","title":"Google Cloud Text-to-Speech","description":"Google Cloud Text-to-Speech enables developers to synthesize natural-sounding speech with 100+ voices, available in multiple languages and variants. It applies DeepMind\u2019s groundbreaking research in WaveNet and Google\u2019s powerful neural networks to deliver the highest fidelity possible.","sidebar":"integrations"},"integrations/tools/google_drive":{"id":"integrations/tools/google_drive","title":"Google Drive","description":"This notebook walks through connecting a LangChain to the Google Drive API.","sidebar":"integrations"},"integrations/tools/google_finance":{"id":"integrations/tools/google_finance","title":"Google Finance","description":"This notebook goes over how to use the Google Finance Tool to get information from the Google Finance page","sidebar":"integrations"},"integrations/tools/google_imagen":{"id":"integrations/tools/google_imagen","title":"Google Imagen","description":"Imagen on Vertex AI brings Google\'s state of the art image generative AI capabilities to application developers. With Imagen on Vertex AI, application developers can build next-generation AI products that transform their user\'s imagination into high quality visual assets using AI generation, in seconds.","sidebar":"integrations"},"integrations/tools/google_jobs":{"id":"integrations/tools/google_jobs","title":"Google Jobs","description":"This notebook goes over how to use the Google Jobs Tool to fetch current Job postings.","sidebar":"integrations"},"integrations/tools/google_lens":{"id":"integrations/tools/google_lens","title":"Google Lens","description":"This notebook goes over how to use the Google Lens Tool to fetch information on an image.","sidebar":"integrations"},"integrations/tools/google_places":{"id":"integrations/tools/google_places","title":"Google Places","description":"This notebook goes through how to use Google Places API","sidebar":"integrations"},"integrations/tools/google_scholar":{"id":"integrations/tools/google_scholar","title":"Google Scholar","description":"This notebook goes through how to use Google Scholar Tool","sidebar":"integrations"},"integrations/tools/google_search":{"id":"integrations/tools/google_search","title":"Google Search","description":"This notebook goes over how to use the google search component.","sidebar":"integrations"},"integrations/tools/google_serper":{"id":"integrations/tools/google_serper","title":"Google Serper","description":"This notebook goes over how to use the Google Serper component to search the web. First you need to sign up for a free account at serper.dev and get your api key.","sidebar":"integrations"},"integrations/tools/google_trends":{"id":"integrations/tools/google_trends","title":"Google Trends","description":"This notebook goes over how to use the Google Trends Tool to fetch trends information.","sidebar":"integrations"},"integrations/tools/gradio_tools":{"id":"integrations/tools/gradio_tools","title":"Gradio","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM\'s fingers \ud83e\uddbe","sidebar":"integrations"},"integrations/tools/graphql":{"id":"integrations/tools/graphql","title":"GraphQL","description":"GraphQL is a query language for APIs and a runtime for executing those queries against your data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools.","sidebar":"integrations"},"integrations/tools/huggingface_tools":{"id":"integrations/tools/huggingface_tools","title":"HuggingFace Hub Tools","description":"Huggingface Tools that supporting text I/O can be","sidebar":"integrations"},"integrations/tools/human_tools":{"id":"integrations/tools/human_tools","title":"Human as a tool","description":"Human are AGI so they can certainly be used as a tool to help out AI agent","sidebar":"integrations"},"integrations/tools/ifttt":{"id":"integrations/tools/ifttt","title":"IFTTT WebHooks","description":"This notebook shows how to use IFTTT Webhooks.","sidebar":"integrations"},"integrations/tools/index":{"id":"integrations/tools/index","title":"Tools","description":"Tools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.","sidebar":"integrations"},"integrations/tools/infobip":{"id":"integrations/tools/infobip","title":"Infobip","description":"This notebook that shows how to use Infobip API wrapper to send SMS messages, emails.","sidebar":"integrations"},"integrations/tools/ionic_shopping":{"id":"integrations/tools/ionic_shopping","title":"Ionic Shopping Tool","description":"Ionic is a plug and play ecommerce marketplace for AI Assistants. By including the Ionic Tool in your agent, you are effortlessly providing your users with the ability to shop and transact directly within your agent, and you\'ll get a cut of the transaction.","sidebar":"integrations"},"integrations/tools/jenkins":{"id":"integrations/tools/jenkins","title":"Jenkins","description":"Tools for interacting with Jenkins.","sidebar":"integrations"},"integrations/tools/jina_search":{"id":"integrations/tools/jina_search","title":"Jina Search","description":"This notebook provides a quick overview for getting started with Jina tool. For detailed documentation of all Jina features and configurations head to the API reference.","sidebar":"integrations"},"integrations/tools/jira":{"id":"integrations/tools/jira","title":"Jira Toolkit","description":"This notebook goes over how to use the Jira toolkit.","sidebar":"integrations"},"integrations/tools/json":{"id":"integrations/tools/json","title":"JSON Toolkit","description":"This notebook showcases an agent interacting with large JSON/dict objects.","sidebar":"integrations"},"integrations/tools/lemonai":{"id":"integrations/tools/lemonai","title":"Lemon Agent","description":"Lemon Agent helps you build powerful AI assistants in minutes and automate workflows by allowing for accurate and reliable read and write operations in tools like Airtable, Hubspot, Discord, Notion, Slack and Github.","sidebar":"integrations"},"integrations/tools/linkup_search":{"id":"integrations/tools/linkup_search","title":"LinkupSearchTool","description":"Linkup provides an API to connect LLMs to the web and the Linkup Premium Partner sources.","sidebar":"integrations"},"integrations/tools/memorize":{"id":"integrations/tools/memorize","title":"Memorize","description":"Fine-tuning LLM itself to memorize information using unsupervised learning.","sidebar":"integrations"},"integrations/tools/mojeek_search":{"id":"integrations/tools/mojeek_search","title":"Mojeek Search","description":"The following notebook will explain how to get results using Mojeek Search. Please visit Mojeek Website to obtain an API key.","sidebar":"integrations"},"integrations/tools/multion":{"id":"integrations/tools/multion","title":"MultiOn Toolkit","description":"MultiON has built an AI Agent that can interact with a broad array of web services and applications.","sidebar":"integrations"},"integrations/tools/nasa":{"id":"integrations/tools/nasa","title":"NASA Toolkit","description":"This notebook shows how to use agents to interact with the NASA toolkit. The toolkit provides access to the NASA Image and Video Library API, with potential to expand and include other accessible NASA APIs in future iterations.","sidebar":"integrations"},"integrations/tools/naver_search":{"id":"integrations/tools/naver_search","title":"Naver Search","description":"Overview","sidebar":"integrations"},"integrations/tools/nuclia":{"id":"integrations/tools/nuclia","title":"Nuclia Understanding","description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","sidebar":"integrations"},"integrations/tools/nvidia_riva":{"id":"integrations/tools/nvidia_riva","title":"NVIDIA Riva: ASR and TTS","description":"NVIDIA Riva","sidebar":"integrations"},"integrations/tools/office365":{"id":"integrations/tools/office365","title":"Office365 Toolkit","description":"Microsoft 365 is a product family of productivity software, collaboration and cloud-based services owned by Microsoft.","sidebar":"integrations"},"integrations/tools/openapi":{"id":"integrations/tools/openapi","title":"OpenAPI Toolkit","description":"We can construct agents to consume arbitrary APIs, here APIs conformant to the OpenAPI/Swagger specification.","sidebar":"integrations"},"integrations/tools/openapi_nla":{"id":"integrations/tools/openapi_nla","title":"Natural Language API Toolkits","description":"Natural Language API Toolkits (NLAToolkits) permit LangChain Agents to efficiently plan and combine calls across endpoints.","sidebar":"integrations"},"integrations/tools/opengradient_toolkit":{"id":"integrations/tools/opengradient_toolkit","title":"OpenGradientToolkit","description":"This notebook shows how to build tools using the OpenGradient toolkit. This toolkit gives users the ability to create custom tools based on models and workflows on the OpenGradient network.","sidebar":"integrations"},"integrations/tools/openweathermap":{"id":"integrations/tools/openweathermap","title":"OpenWeatherMap","description":"This notebook goes over how to use the OpenWeatherMap component to fetch weather information.","sidebar":"integrations"},"integrations/tools/oracleai":{"id":"integrations/tools/oracleai","title":"Oracle AI Vector Search: Generate Summary","description":"Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads that allows you to query data based on semantics, rather than keywords.","sidebar":"integrations"},"integrations/tools/pandas":{"id":"integrations/tools/pandas","title":"Pandas Dataframe","description":"This notebook shows how to use agents to interact with a Pandas DataFrame. It is mostly optimized for question answering.","sidebar":"integrations"},"integrations/tools/passio_nutrition_ai":{"id":"integrations/tools/passio_nutrition_ai","title":"Passio NutritionAI","description":"To best understand how NutritionAI can give your agents super food-nutrition powers, let\'s build an agent that can find that information via Passio NutritionAI.","sidebar":"integrations"},"integrations/tools/payman-tool":{"id":"integrations/tools/payman-tool","title":"PaymanAI","description":"PaymanAI provides functionality to send and receive payments (fiat and crypto) on behalf of an AI Agent. To get started:","sidebar":"integrations"},"integrations/tools/permit":{"id":"integrations/tools/permit","title":"Permit","description":"Permit is an access control platform that provides fine-grained, real-time permission management using various models such as RBAC, ABAC, and ReBAC. It enables organizations to enforce dynamic policies across their applications, ensuring that only authorized users can access specific resources.","sidebar":"integrations"},"integrations/tools/playwright":{"id":"integrations/tools/playwright","title":"PlayWright Browser Toolkit","description":"Playwright is an open-source automation tool developed by Microsoft that allows you to programmatically control and automate web browsers. It is designed for end-to-end testing, scraping, and automating tasks across various web browsers such as Chromium, Firefox, and WebKit.","sidebar":"integrations"},"integrations/tools/polygon":{"id":"integrations/tools/polygon","title":"Polygon IO Toolkit and Tools","description":"This notebook shows how to use agents to interact with the Polygon IO toolkit. The toolkit provides access to Polygon\'s Stock Market Data API.","sidebar":"integrations"},"integrations/tools/powerbi":{"id":"integrations/tools/powerbi","title":"PowerBI Toolkit","description":"This notebook showcases an agent interacting with a Power BI Dataset. The agent is answering more general questions about a dataset, as well as recover from errors.","sidebar":"integrations"},"integrations/tools/prolog_tool":{"id":"integrations/tools/prolog_tool","title":"Prolog","description":"LangChain tools that use Prolog rules to generate answers.","sidebar":"integrations"},"integrations/tools/pubmed":{"id":"integrations/tools/pubmed","title":"PubMed","description":"PubMed\xae comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full text content from PubMed Central and publisher web sites.","sidebar":"integrations"},"integrations/tools/python":{"id":"integrations/tools/python","title":"Python REPL","description":"Sometimes, for complex calculations, rather than have an LLM generate the answer directly, it can be better to have the LLM generate code to calculate the answer, and then run that code to get the answer. In order to easily do that, we provide a simple Python REPL to execute commands in.","sidebar":"integrations"},"integrations/tools/reddit_search":{"id":"integrations/tools/reddit_search","title":"Reddit Search","description":"In this notebook, we learn how the Reddit search tool works.","sidebar":"integrations"},"integrations/tools/requests":{"id":"integrations/tools/requests","title":"Requests Toolkit","description":"We can use the Requests toolkit to construct agents that generate HTTP requests.","sidebar":"integrations"},"integrations/tools/riza":{"id":"integrations/tools/riza","title":"Riza Code Interpreter","description":"The Riza Code Interpreter is a WASM-based isolated environment for running Python or JavaScript generated by AI agents.","sidebar":"integrations"},"integrations/tools/robocorp":{"id":"integrations/tools/robocorp","title":"Robocorp Toolkit","description":"This notebook covers how to get started with Robocorp Action Server action toolkit and LangChain.","sidebar":"integrations"},"integrations/tools/salesforce":{"id":"integrations/tools/salesforce","title":"Salesforce","description":"Tools for interacting with Salesforce.","sidebar":"integrations"},"integrations/tools/sceneXplain":{"id":"integrations/tools/sceneXplain","title":"SceneXplain","description":"SceneXplain is an ImageCaptioning service accessible through the SceneXplain Tool.","sidebar":"integrations"},"integrations/tools/scrapegraph":{"id":"integrations/tools/scrapegraph","title":"ScrapeGraph","description":"This notebook provides a quick overview for getting started with ScrapeGraph tools. For detailed documentation of all ScrapeGraph features and configurations head to the API reference.","sidebar":"integrations"},"integrations/tools/searchapi":{"id":"integrations/tools/searchapi","title":"SearchApi","description":"This notebook shows examples of how to use SearchApi to search the web. Go to https://www.searchapi.io/ to sign up for a free account and get API key.","sidebar":"integrations"},"integrations/tools/searx_search":{"id":"integrations/tools/searx_search","title":"SearxNG Search","description":"This notebook goes over how to use a self hosted SearxNG search API to search the web.","sidebar":"integrations"},"integrations/tools/semanticscholar":{"id":"integrations/tools/semanticscholar","title":"Semantic Scholar API Tool","description":"This notebook demos how to use the semantic scholar tool with an agent.","sidebar":"integrations"},"integrations/tools/serpapi":{"id":"integrations/tools/serpapi","title":"SerpAPI","description":"This notebook goes over how to use the SerpAPI component to search the web.","sidebar":"integrations"},"integrations/tools/slack":{"id":"integrations/tools/slack","title":"Slack Toolkit","description":"This will help you getting started with the Slack toolkit. For detailed documentation of all SlackToolkit features and configurations head to the API reference.","sidebar":"integrations"},"integrations/tools/spark_sql":{"id":"integrations/tools/spark_sql","title":"Spark SQL Toolkit","description":"This notebook shows how to use agents to interact with Spark SQL. Similar to SQL Database Agent, it is designed to address general inquiries about Spark SQL and facilitate error recovery.","sidebar":"integrations"},"integrations/tools/sql_database":{"id":"integrations/tools/sql_database","title":"SQLDatabase Toolkit","description":"This will help you getting started with the SQL Database toolkit. For detailed documentation of all SQLDatabaseToolkit features and configurations head to the API reference.","sidebar":"integrations"},"integrations/tools/stackexchange":{"id":"integrations/tools/stackexchange","title":"StackExchange","description":"Stack Exchange is a network of question-and-answer (Q&A) websites on topics in diverse fields, each site covering a specific topic, where questions, answers, and users are subject to a reputation award process. The reputation system allows the sites to be self-moderating.","sidebar":"integrations"},"integrations/tools/steam":{"id":"integrations/tools/steam","title":"Steam Toolkit","description":"Steam (Wikipedia)) is a video game digital distribution service and storefront developed by Valve Corporation. It provides game updates automatically for Valve\'s games, and expanded to distributing third-party titles. Steam offers various features, like game server matchmaking with Valve Anti-Cheat measures, social networking, and game streaming services.","sidebar":"integrations"},"integrations/tools/stripe":{"id":"integrations/tools/stripe","title":"StripeAgentToolkit","description":"This notebook provides a quick overview for getting started with Stripe\'s agent toolkit.","sidebar":"integrations"},"integrations/tools/tableau":{"id":"integrations/tools/tableau","title":"Tableau","description":"This notebook provides a quick overview for getting started with Tableau.","sidebar":"integrations"},"integrations/tools/taiga":{"id":"integrations/tools/taiga","title":"Taiga","description":"This notebook provides a quick overview for getting started with Taiga tooling in langchain_taiga. For more details on each tool and configuration, see the docstrings in your repository or relevant doc pages.","sidebar":"integrations"},"integrations/tools/tavily_extract":{"id":"integrations/tools/tavily_extract","title":"Tavily Extract","description":"Tavily is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed. Tavily offers an Extract endpoint that can be used to extract content from a URLs.","sidebar":"integrations"},"integrations/tools/tavily_search":{"id":"integrations/tools/tavily_search","title":"Tavily Search","description":"Tavily\'s Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.","sidebar":"integrations"},"integrations/tools/tilores":{"id":"integrations/tools/tilores","title":"Tilores","description":"This notebook covers how to get started with the Tilores tools.","sidebar":"integrations"},"integrations/tools/twilio":{"id":"integrations/tools/twilio","title":"Twilio","description":"This notebook goes over how to use the Twilio API wrapper to send a message through SMS or Twilio Messaging Channels.","sidebar":"integrations"},"integrations/tools/upstage_groundedness_check":{"id":"integrations/tools/upstage_groundedness_check","title":"Upstage Groundedness Check","description":"This notebook covers how to get started with Upstage groundedness check models.","sidebar":"integrations"},"integrations/tools/valthera":{"id":"integrations/tools/valthera","title":"Valthera","description":"Enable AI agents to engage users when they\'re most likely to respond.","sidebar":"integrations"},"integrations/tools/wikidata":{"id":"integrations/tools/wikidata","title":"Wikidata","description":"Wikidata is a free and open knowledge base that can be read and edited by both humans and machines. Wikidata is one of the world\'s largest open knowledge bases.","sidebar":"integrations"},"integrations/tools/wikipedia":{"id":"integrations/tools/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/tools/wolfram_alpha":{"id":"integrations/tools/wolfram_alpha","title":"Wolfram Alpha","description":"This notebook goes over how to use the wolfram alpha component.","sidebar":"integrations"},"integrations/tools/writer":{"id":"integrations/tools/writer","title":"Writer Tools","description":"This notebook provides a quick overview for getting started with Writer tools. For detailed documentation of all Writer features and configurations head to the Writer docs.","sidebar":"integrations"},"integrations/tools/yahoo_finance_news":{"id":"integrations/tools/yahoo_finance_news","title":"Yahoo Finance News","description":"This notebook goes over how to use the yahoofinancenews tool with an agent.","sidebar":"integrations"},"integrations/tools/you":{"id":"integrations/tools/you","title":"You.com Search","description":"The you.com API is a suite of tools designed to help developers ground the output of LLMs in the most recent, most accurate, most relevant information that may not have been included in their training dataset.","sidebar":"integrations"},"integrations/tools/youtube":{"id":"integrations/tools/youtube","title":"YouTube","description":"YouTube Search package searches YouTube videos avoiding using their heavily rate-limited API.","sidebar":"integrations"},"integrations/tools/zapier":{"id":"integrations/tools/zapier","title":"Zapier Natural Language Actions","description":"Deprecated This API will be sunset on 2023-11-17//nla.zapier.com/start/","sidebar":"integrations"},"integrations/tools/zenguard":{"id":"integrations/tools/zenguard","title":"ZenGuard AI","description":"This tool lets you quickly set up ZenGuard AI in your Langchain-powered application. The ZenGuard AI provides ultrafast guardrails to protect your GenAI application from:","sidebar":"integrations"},"integrations/vectorstores/activeloop_deeplake":{"id":"integrations/vectorstores/activeloop_deeplake","title":"Activeloop Deep Lake","description":"Activeloop Deep Lake as a Multi-Modal Vector Store that stores embeddings and their metadata including text, jsons, images, audio, video, and more. It saves the data locally, in your cloud, or on Activeloop storage. It performs hybrid search including embeddings and their attributes.","sidebar":"integrations"},"integrations/vectorstores/aerospike":{"id":"integrations/vectorstores/aerospike","title":"Aerospike","description":"Aerospike Vector Search (AVS) is an","sidebar":"integrations"},"integrations/vectorstores/alibabacloud_opensearch":{"id":"integrations/vectorstores/alibabacloud_opensearch","title":"Alibaba Cloud OpenSearch","description":"Alibaba Cloud Opensearch is a one-stop platform to develop intelligent search services. OpenSearch was built on the large-scale distributed search engine developed by Alibaba. OpenSearch serves more than 500 business cases in Alibaba Group and thousands of Alibaba Cloud customers. OpenSearch helps develop search services in different search scenarios, including e-commerce, O2O, multimedia, the content industry, communities and forums, and big data query in enterprises.","sidebar":"integrations"},"integrations/vectorstores/analyticdb":{"id":"integrations/vectorstores/analyticdb","title":"AnalyticDB","description":"AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.","sidebar":"integrations"},"integrations/vectorstores/annoy":{"id":"integrations/vectorstores/annoy","title":"Annoy","description":"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mapped into memory so that many processes may share the same data.","sidebar":"integrations"},"integrations/vectorstores/apache_doris":{"id":"integrations/vectorstores/apache_doris","title":"Apache Doris","description":"Apache Doris is a modern data warehouse for real-time analytics.","sidebar":"integrations"},"integrations/vectorstores/aperturedb":{"id":"integrations/vectorstores/aperturedb","title":"ApertureDB","description":"ApertureDB is a database that stores, indexes, and manages multi-modal data like text, images, videos, bounding boxes, and embeddings, together with their associated metadata.","sidebar":"integrations"},"integrations/vectorstores/astradb":{"id":"integrations/vectorstores/astradb","title":"Astra DB Vector Store","description":"This page provides a quickstart for using Astra DB as a Vector Store.","sidebar":"integrations"},"integrations/vectorstores/atlas":{"id":"integrations/vectorstores/atlas","title":"Atlas","description":"Atlas is a platform by Nomic made for interacting with both small and internet scale unstructured datasets. It enables anyone to visualize, search, and share massive datasets in their browser.","sidebar":"integrations"},"integrations/vectorstores/awadb":{"id":"integrations/vectorstores/awadb","title":"AwaDB","description":"AwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.","sidebar":"integrations"},"integrations/vectorstores/azure_cosmos_db":{"id":"integrations/vectorstores/azure_cosmos_db","title":"Azure Cosmos DB Mongo vCore","description":"This notebook shows you how to leverage this integrated vector database to store documents in collections, create indicies and perform vector search queries using approximate nearest neighbor algorithms such as COS (cosine distance), L2 (Euclidean distance), and IP (inner product) to locate documents close to the query vectors.","sidebar":"integrations"},"integrations/vectorstores/azure_cosmos_db_no_sql":{"id":"integrations/vectorstores/azure_cosmos_db_no_sql","title":"Azure Cosmos DB No SQL","description":"This notebook shows you how to leverage this integrated vector database to store documents in collections, create indicies and perform vector search queries using approximate nearest neighbor algorithms such as COS (cosine distance), L2 (Euclidean distance), and IP (inner product) to locate documents close to the query vectors.","sidebar":"integrations"},"integrations/vectorstores/azuresearch":{"id":"integrations/vectorstores/azuresearch","title":"Azure AI Search","description":"Azure AI Search (formerly known as Azure Search and Azure Cognitive Search) is a cloud search service that gives developers infrastructure, APIs, and tools for information retrieval of vector, keyword, and hybrid queries at scale.","sidebar":"integrations"},"integrations/vectorstores/bagel":{"id":"integrations/vectorstores/bagel","title":"Bagel","description":"Bagel (Open Inference platform for AI), is like GitHub for AI data.","sidebar":"integrations"},"integrations/vectorstores/bageldb":{"id":"integrations/vectorstores/bageldb","title":"BagelDB","description":"BagelDB (Open Vector Database for AI), is like GitHub for AI data.","sidebar":"integrations"},"integrations/vectorstores/baiducloud_vector_search":{"id":"integrations/vectorstores/baiducloud_vector_search","title":"Baidu Cloud ElasticSearch VectorSearch","description":"Baidu Cloud VectorSearch is a fully managed, enterprise-level distributed search and analysis service which is 100% compatible to open source. Baidu Cloud VectorSearch provides low-cost, high-performance, and reliable retrieval and analysis platform level product services for structured/unstructured data. As a vector database , it supports multiple index types and similarity distance methods.","sidebar":"integrations"},"integrations/vectorstores/baiduvectordb":{"id":"integrations/vectorstores/baiduvectordb","title":"Baidu VectorDB","description":"Baidu VectorDB is a robust, enterprise-level distributed database service, meticulously developed and fully managed by Baidu Intelligent Cloud. It stands out for its exceptional ability to store, retrieve, and analyze multi-dimensional vector data. At its core, VectorDB operates on Baidu\'s proprietary \\"Mochow\\" vector database kernel, which ensures high performance, availability, and security, alongside remarkable scalability and user-friendliness.","sidebar":"integrations"},"integrations/vectorstores/cassandra":{"id":"integrations/vectorstores/cassandra","title":"Apache Cassandra","description":"This page provides a quickstart for using Apache Cassandra\xae as a Vector Store.","sidebar":"integrations"},"integrations/vectorstores/chroma":{"id":"integrations/vectorstores/chroma","title":"Chroma","description":"This notebook covers how to get started with the Chroma vector store.","sidebar":"integrations"},"integrations/vectorstores/clarifai":{"id":"integrations/vectorstores/clarifai","title":"Clarifai","description":"Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference. A Clarifai application can be used as a vector database after uploading inputs.","sidebar":"integrations"},"integrations/vectorstores/clickhouse":{"id":"integrations/vectorstores/clickhouse","title":"ClickHouse","description":"ClickHouse is the fastest and most resource efficient open-source database for real-time apps and analytics with full SQL support and a wide range of functions to assist users in writing analytical queries. Lately added data structures and distance search functions (like L2Distance) as well as approximate nearest neighbor search indexes enable ClickHouse to be used as a high performance and scalable vector database to store and search vectors with SQL.","sidebar":"integrations"},"integrations/vectorstores/couchbase":{"id":"integrations/vectorstores/couchbase","title":"Couchbase","description":"Couchbase is an award-winning distributed NoSQL cloud database that delivers unmatched versatility, performance, scalability, and financial value for all of your cloud, mobile, AI, and edge computing applications. Couchbase embraces AI with coding assistance for developers and vector search for their applications.","sidebar":"integrations"},"integrations/vectorstores/dashvector":{"id":"integrations/vectorstores/dashvector","title":"DashVector","description":"DashVector is a fully-managed vectorDB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.","sidebar":"integrations"},"integrations/vectorstores/databricks_vector_search":{"id":"integrations/vectorstores/databricks_vector_search","title":"DatabricksVectorSearch","description":"Databricks Vector Search is a serverless similarity search engine that allows you to store a vector representation of your data, including metadata, in a vector database. With Vector Search, you can create auto-updating vector search indexes from Delta tables managed by Unity Catalog and query them with a simple API to return the most similar vectors.","sidebar":"integrations"},"integrations/vectorstores/dingo":{"id":"integrations/vectorstores/dingo","title":"DingoDB","description":"DingoDB is a distributed multi-mode vector database, which combines the characteristics of data lakes and vector databases, and can store data of any type and size (Key-Value, PDF, audio, video, etc.). It has real-time low-latency processing capabilities to achieve rapid insight and response, and can efficiently conduct instant analysis and process multi-modal data.","sidebar":"integrations"},"integrations/vectorstores/docarray_hnsw":{"id":"integrations/vectorstores/docarray_hnsw","title":"DocArray HnswSearch","description":"DocArrayHnswSearch is a lightweight Document Index implementation provided by Docarray that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.","sidebar":"integrations"},"integrations/vectorstores/docarray_in_memory":{"id":"integrations/vectorstores/docarray_in_memory","title":"DocArray InMemorySearch","description":"DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.","sidebar":"integrations"},"integrations/vectorstores/documentdb":{"id":"integrations/vectorstores/documentdb","title":"Amazon Document DB","description":"Amazon DocumentDB (with MongoDB Compatibility) makes it easy to set up, operate, and scale MongoDB-compatible databases in the cloud.","sidebar":"integrations"},"integrations/vectorstores/duckdb":{"id":"integrations/vectorstores/duckdb","title":"DuckDB","description":"This notebook shows how to use DuckDB as a vector store.","sidebar":"integrations"},"integrations/vectorstores/ecloud_vector_search":{"id":"integrations/vectorstores/ecloud_vector_search","title":"China Mobile ECloud ElasticSearch VectorSearch","description":"China Mobile ECloud VectorSearch is a fully managed, enterprise-level distributed search and analysis service. China Mobile ECloud VectorSearch provides low-cost, high-performance, and reliable retrieval and analysis platform level product services for structured/unstructured data. As a vector database , it supports multiple index types and similarity distance methods.","sidebar":"integrations"},"integrations/vectorstores/elasticsearch":{"id":"integrations/vectorstores/elasticsearch","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library.","sidebar":"integrations"},"integrations/vectorstores/epsilla":{"id":"integrations/vectorstores/epsilla","title":"Epsilla","description":"Epsilla is an open-source vector database that leverages the advanced parallel graph traversal techniques for vector indexing. Epsilla is licensed under GPL-3.0.","sidebar":"integrations"},"integrations/vectorstores/faiss":{"id":"integrations/vectorstores/faiss","title":"Faiss","description":"Facebook AI Similarity Search (FAISS) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also includes supporting code for evaluation and parameter tuning.","sidebar":"integrations"},"integrations/vectorstores/faiss_async":{"id":"integrations/vectorstores/faiss_async","title":"Faiss (Async)","description":"Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also includes supporting code for evaluation and parameter tuning.","sidebar":"integrations"},"integrations/vectorstores/falkordbvector":{"id":"integrations/vectorstores/falkordbvector","title":"FalkorDBVectorStore","description":"FalkorDB is an open-source graph database with integrated support for vector similarity search","sidebar":"integrations"},"integrations/vectorstores/google_alloydb":{"id":"integrations/vectorstores/google_alloydb","title":"Google AlloyDB for PostgreSQL","description":"AlloyDB is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. AlloyDB is 100% compatible with PostgreSQL. Extend your database application to build AI-powered experiences leveraging AlloyDB\'s Langchain integrations.","sidebar":"integrations"},"integrations/vectorstores/google_bigquery_vector_search":{"id":"integrations/vectorstores/google_bigquery_vector_search","title":"Google BigQuery Vector Search","description":"Google Cloud BigQuery Vector Search lets you use GoogleSQL to do semantic search, using vector indexes for fast approximate results, or using brute force for exact results.","sidebar":"integrations"},"integrations/vectorstores/google_cloud_sql_mysql":{"id":"integrations/vectorstores/google_cloud_sql_mysql","title":"Google Cloud SQL for MySQL","description":"Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers PostgreSQL, MySQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s LangChain integrations.","sidebar":"integrations"},"integrations/vectorstores/google_cloud_sql_pg":{"id":"integrations/vectorstores/google_cloud_sql_pg","title":"Google Cloud SQL for PostgreSQL","description":"Cloud SQL is a fully managed relational database service that offers high performance, seamless integration, and impressive scalability. It offers PostgreSQL, PostgreSQL, and SQL Server database engines. Extend your database application to build AI-powered experiences leveraging Cloud SQL\'s Langchain integrations.","sidebar":"integrations"},"integrations/vectorstores/google_firestore":{"id":"integrations/vectorstores/google_firestore","title":"Google Firestore (Native Mode)","description":"Firestore is a serverless document-oriented database that scales to meet any demand. Extend your database application to build AI-powered experiences leveraging Firestore\'s Langchain integrations.","sidebar":"integrations"},"integrations/vectorstores/google_memorystore_redis":{"id":"integrations/vectorstores/google_memorystore_redis","title":"Google Memorystore for Redis","description":"Google Memorystore for Redis is a fully-managed service that is powered by the Redis in-memory data store to build application caches that provide sub-millisecond data access. Extend your database application to build AI-powered experiences leveraging Memorystore for Redis\'s Langchain integrations.","sidebar":"integrations"},"integrations/vectorstores/google_spanner":{"id":"integrations/vectorstores/google_spanner","title":"Google Spanner","description":"Spanner is a highly scalable database that combines unlimited scalability with relational semantics, such as secondary indexes, strong consistency, schemas, and SQL providing 99.999% availability in one easy solution.","sidebar":"integrations"},"integrations/vectorstores/google_vertex_ai_feature_store":{"id":"integrations/vectorstores/google_vertex_ai_feature_store","title":"Google Vertex AI Feature Store","description":"Google Cloud Vertex Feature Store streamlines your ML feature management and online serving processes by letting you serve at low-latency your data in Google Cloud BigQuery, including the capacity to perform approximate neighbor retrieval for embeddings","sidebar":"integrations"},"integrations/vectorstores/google_vertex_ai_vector_search":{"id":"integrations/vectorstores/google_vertex_ai_vector_search","title":"Google Vertex AI Vector Search","description":"This notebook shows how to use functionality related to the Google Cloud Vertex AI Vector Search vector database.","sidebar":"integrations"},"integrations/vectorstores/hippo":{"id":"integrations/vectorstores/hippo","title":"Hippo","description":"Transwarp Hippo is an enterprise-level cloud-native distributed vector database that supports storage, retrieval, and management of massive vector-based datasets. It efficiently solves problems such as vector similarity search and high-density vector clustering. Hippo features high availability, high performance, and easy scalability. It has many functions, such as multiple vector search indexes, data partitioning and sharding, data persistence, incremental data ingestion, vector scalar field filtering, and mixed queries. It can effectively meet the high real-time search demands of enterprises for massive vector data","sidebar":"integrations"},"integrations/vectorstores/hologres":{"id":"integrations/vectorstores/hologres","title":"Hologres","description":"Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.","sidebar":"integrations"},"integrations/vectorstores/index":{"id":"integrations/vectorstores/index","title":"Vector stores","description":"A vector store stores embedded data and performs similarity search.","sidebar":"integrations"},"integrations/vectorstores/infinispanvs":{"id":"integrations/vectorstores/infinispanvs","title":"Infinispan","description":"Infinispan is an open-source key-value data grid, it can work as single node as well as distributed.","sidebar":"integrations"},"integrations/vectorstores/jaguar":{"id":"integrations/vectorstores/jaguar","title":"Jaguar Vector Database","description":"1. It is a distributed vector database","sidebar":"integrations"},"integrations/vectorstores/kdbai":{"id":"integrations/vectorstores/kdbai","title":"KDB.AI","description":"KDB.AI is a powerful knowledge-based vector database and search engine that allows you to build scalable, reliable AI applications, using real-time data, by providing advanced search, recommendation and personalization.","sidebar":"integrations"},"integrations/vectorstores/kinetica":{"id":"integrations/vectorstores/kinetica","title":"Kinetica Vectorstore API","description":"Kinetica is a database with integrated support for vector similarity search","sidebar":"integrations"},"integrations/vectorstores/lancedb":{"id":"integrations/vectorstores/lancedb","title":"LanceDB","description":"LanceDB is an open-source database for vector-search built with persistent storage, which greatly simplifies retrevial, filtering and management of embeddings. Fully open source.","sidebar":"integrations"},"integrations/vectorstores/lantern":{"id":"integrations/vectorstores/lantern","title":"Lantern","description":"Lantern is an open-source vector similarity search for Postgres","sidebar":"integrations"},"integrations/vectorstores/lindorm":{"id":"integrations/vectorstores/lindorm","title":"LindormVectorStore","description":"This notebook covers how to get started with the Lindorm vector store.","sidebar":"integrations"},"integrations/vectorstores/llm_rails":{"id":"integrations/vectorstores/llm_rails","title":"LLMRails","description":"LLMRails is a API platform for building GenAI applications. It provides an easy-to-use API for document indexing and querying that is managed by LLMRails and is optimized for performance and accuracy.","sidebar":"integrations"},"integrations/vectorstores/manticore_search":{"id":"integrations/vectorstores/manticore_search","title":"ManticoreSearch VectorStore","description":"ManticoreSearch is an open-source search engine that offers fast, scalable, and user-friendly capabilities. Originating as a fork of Sphinx Search, it has evolved to incorporate modern search engine features and improvements. ManticoreSearch distinguishes itself with its robust performance and ease of integration into various applications.","sidebar":"integrations"},"integrations/vectorstores/marqo":{"id":"integrations/vectorstores/marqo","title":"Marqo","description":"This notebook shows how to use functionality related to the Marqo vectorstore.","sidebar":"integrations"},"integrations/vectorstores/meilisearch":{"id":"integrations/vectorstores/meilisearch","title":"Meilisearch","description":"Meilisearch is an open-source, lightning-fast, and hyper relevant search engine. It comes with great defaults to help developers build snappy search experiences.","sidebar":"integrations"},"integrations/vectorstores/memorydb":{"id":"integrations/vectorstores/memorydb","title":"Amazon MemoryDB","description":"Vector Search introduction and langchain integration guide.","sidebar":"integrations"},"integrations/vectorstores/milvus":{"id":"integrations/vectorstores/milvus","title":"Milvus","description":"Milvus is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.","sidebar":"integrations"},"integrations/vectorstores/momento_vector_index":{"id":"integrations/vectorstores/momento_vector_index","title":"Momento Vector Index (MVI)","description":"MVI: the most productive, easiest to use, serverless vector index for your data. To get started with MVI, simply sign up for an account. There\'s no need to handle infrastructure, manage servers, or be concerned about scaling. MVI is a service that scales automatically to meet your needs.","sidebar":"integrations"},"integrations/vectorstores/mongodb_atlas":{"id":"integrations/vectorstores/mongodb_atlas","title":"MongoDB Atlas","description":"This notebook covers how to MongoDB Atlas vector search in LangChain, using the langchain-mongodb package.","sidebar":"integrations"},"integrations/vectorstores/myscale":{"id":"integrations/vectorstores/myscale","title":"MyScale","description":"MyScale is a cloud-based database optimized for AI applications and solutions, built on the open-source ClickHouse.","sidebar":"integrations"},"integrations/vectorstores/neo4jvector":{"id":"integrations/vectorstores/neo4jvector","title":"Neo4j Vector Index","description":"Neo4j is an open-source graph database with integrated support for vector similarity search","sidebar":"integrations"},"integrations/vectorstores/nucliadb":{"id":"integrations/vectorstores/nucliadb","title":"NucliaDB","description":"You can use a local NucliaDB instance or use Nuclia Cloud.","sidebar":"integrations"},"integrations/vectorstores/oceanbase":{"id":"integrations/vectorstores/oceanbase","title":"OceanbaseVectorStore","description":"This notebook covers how to get started with the Oceanbase vector store.","sidebar":"integrations"},"integrations/vectorstores/opensearch":{"id":"integrations/vectorstores/opensearch","title":"OpenSearch","description":"OpenSearch is a scalable, flexible, and extensible open-source software suite for search, analytics, and observability applications licensed under Apache 2.0. OpenSearch is a distributed search and analytics engine based on Apache Lucene.","sidebar":"integrations"},"integrations/vectorstores/oracle":{"id":"integrations/vectorstores/oracle","title":"Oracle AI Vector Search: Vector Store","description":"Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads that allows you to query data based on semantics, rather than keywords.","sidebar":"integrations"},"integrations/vectorstores/pathway":{"id":"integrations/vectorstores/pathway","title":"Pathway","description":"Pathway is an open data processing framework. It allows you to easily develop data transformation pipelines and Machine Learning applications that work with live data sources and changing data.","sidebar":"integrations"},"integrations/vectorstores/pgembedding":{"id":"integrations/vectorstores/pgembedding","title":"Postgres Embedding","description":"Postgres Embedding is an open-source vector similarity search for Postgres that uses  Hierarchical Navigable Small Worlds (HNSW) for approximate nearest neighbor search.","sidebar":"integrations"},"integrations/vectorstores/pgvecto_rs":{"id":"integrations/vectorstores/pgvecto_rs","title":"PGVecto.rs","description":"This notebook shows how to use functionality related to the Postgres vector database (pgvecto.rs).","sidebar":"integrations"},"integrations/vectorstores/pgvector":{"id":"integrations/vectorstores/pgvector","title":"PGVector","description":"An implementation of LangChain vectorstore abstraction using postgres as the backend and utilizing the pgvector extension.","sidebar":"integrations"},"integrations/vectorstores/pinecone":{"id":"integrations/vectorstores/pinecone","title":"Pinecone","description":"Pinecone is a vector database with broad functionality.","sidebar":"integrations"},"integrations/vectorstores/qdrant":{"id":"integrations/vectorstores/qdrant","title":"Qdrant","description":"Qdrant (read: quadrant) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage vectors with additional payload and extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.","sidebar":"integrations"},"integrations/vectorstores/redis":{"id":"integrations/vectorstores/redis","title":"Redis Vector Store","description":"This notebook covers how to get started with the Redis vector store.","sidebar":"integrations"},"integrations/vectorstores/relyt":{"id":"integrations/vectorstores/relyt","title":"Relyt","description":"Relyt is a cloud native data warehousing service that is designed to analyze large volumes of data online.","sidebar":"integrations"},"integrations/vectorstores/rockset":{"id":"integrations/vectorstores/rockset","title":"Rockset","description":"Rockset is a real-time search and analytics database built for the cloud. Rockset uses a Converged Index\u2122 with an efficient store for vector embeddings to serve low latency, high concurrency search queries at scale. Rockset has full support for metadata filtering and  handles real-time ingestion for constantly updating, streaming data.","sidebar":"integrations"},"integrations/vectorstores/sap_hanavector":{"id":"integrations/vectorstores/sap_hanavector","title":"SAP HANA Cloud Vector Engine","description":"SAP HANA Cloud Vector Engine is a vector store fully integrated into the SAP HANA Cloud database.","sidebar":"integrations"},"integrations/vectorstores/scann":{"id":"integrations/vectorstores/scann","title":"ScaNN","description":"ScaNN (Scalable Nearest Neighbors) is a method for efficient vector similarity search at scale.","sidebar":"integrations"},"integrations/vectorstores/semadb":{"id":"integrations/vectorstores/semadb","title":"SemaDB","description":"SemaDB from SemaFind is a no fuss vector similarity database for building AI applications. The hosted SemaDB Cloud offers a no fuss developer experience to get started.","sidebar":"integrations"},"integrations/vectorstores/singlestoredb":{"id":"integrations/vectorstores/singlestoredb","title":"SingleStoreDB","description":"SingleStoreDB is a robust, high-performance distributed SQL database solution designed to excel in both cloud and on-premises environments. Boasting a versatile feature set, it offers seamless deployment options while delivering unparalleled performance.","sidebar":"integrations"},"integrations/vectorstores/sklearn":{"id":"integrations/vectorstores/sklearn","title":"scikit-learn","description":"scikit-learn is an open-source collection of machine learning algorithms, including some implementations of the k nearest neighbors. SKLearnVectorStore wraps this implementation and adds the possibility to persist the vector store in json, bson (binary json) or Apache Parquet format.","sidebar":"integrations"},"integrations/vectorstores/sqlitevec":{"id":"integrations/vectorstores/sqlitevec","title":"SQLite as a Vector Store with SQLiteVec","description":"This notebook covers how to get started with the SQLiteVec vector store.","sidebar":"integrations"},"integrations/vectorstores/sqlitevss":{"id":"integrations/vectorstores/sqlitevss","title":"SQLite-VSS","description":"SQLite-VSS is an SQLite extension designed for vector search, emphasizing local-first operations and easy integration into applications without external servers. Leveraging the Faiss library, it offers efficient similarity search and clustering capabilities.","sidebar":"integrations"},"integrations/vectorstores/sqlserver":{"id":"integrations/vectorstores/sqlserver","title":"SQLServer","description":"Azure SQL provides a dedicated\xa0Vector data type that simplifies the creation, storage, and querying of vector embeddings directly within a relational database. This eliminates the need for separate vector databases and related integrations, increasing the security of your solutions while reducing the overall complexity.","sidebar":"integrations"},"integrations/vectorstores/starrocks":{"id":"integrations/vectorstores/starrocks","title":"StarRocks","description":"StarRocks is a High-Performance Analytical Database.","sidebar":"integrations"},"integrations/vectorstores/supabase":{"id":"integrations/vectorstores/supabase","title":"Supabase (Postgres)","description":"Supabase is an open-source Firebase alternative. Supabase is built on top of PostgreSQL, which offers strong SQL querying capabilities and enables a simple interface with already-existing tools and frameworks.","sidebar":"integrations"},"integrations/vectorstores/surrealdb":{"id":"integrations/vectorstores/surrealdb","title":"SurrealDB","description":"SurrealDB is an end-to-end cloud-native database designed for modern applications, including web, mobile, serverless, Jamstack, backend, and traditional applications. With SurrealDB, you can simplify your database and API infrastructure, reduce development time, and build secure, performant apps quickly and cost-effectively.","sidebar":"integrations"},"integrations/vectorstores/tablestore":{"id":"integrations/vectorstores/tablestore","title":"Tablestore","description":"Tablestore is a fully managed NoSQL cloud database service.","sidebar":"integrations"},"integrations/vectorstores/tair":{"id":"integrations/vectorstores/tair","title":"Tair","description":"Tair is a cloud native in-memory database service developed by Alibaba Cloud.","sidebar":"integrations"},"integrations/vectorstores/tencentvectordb":{"id":"integrations/vectorstores/tencentvectordb","title":"Tencent Cloud VectorDB","description":"Tencent Cloud VectorDB is a fully managed, self-developed, enterprise-level distributed database service designed for storing, retrieving, and analyzing multi-dimensional vector data. The database supports multiple index types and similarity calculation methods. A single index can support a vector scale of up to 1 billion and can support millions of QPS and millisecond-level query latency. Tencent Cloud Vector Database can not only provide an external knowledge base for large models to improve the accuracy of large model responses but can also be widely used in AI fields such as recommendation systems, NLP services, computer vision, and intelligent customer service.","sidebar":"integrations"},"integrations/vectorstores/thirdai_neuraldb":{"id":"integrations/vectorstores/thirdai_neuraldb","title":"ThirdAI NeuralDB","description":"NeuralDB is a CPU-friendly and fine-tunable vector store developed by ThirdAI.","sidebar":"integrations"},"integrations/vectorstores/tidb_vector":{"id":"integrations/vectorstores/tidb_vector","title":"TiDB Vector","description":"TiDB Cloud, is a comprehensive Database-as-a-Service (DBaaS) solution, that provides dedicated and serverless options. TiDB Serverless is now integrating a built-in vector search into the MySQL landscape. With this enhancement, you can seamlessly develop AI applications using TiDB Serverless without the need for a new database or additional technical stacks. Create a free TiDB Serverless cluster and start using the vector search feature at https://pingcap.com/ai.","sidebar":"integrations"},"integrations/vectorstores/tigris":{"id":"integrations/vectorstores/tigris","title":"Tigris","description":"Tigris is an open-source Serverless NoSQL Database and Search Platform designed to simplify building high-performance vector search applications.","sidebar":"integrations"},"integrations/vectorstores/tiledb":{"id":"integrations/vectorstores/tiledb","title":"TileDB","description":"TileDB is a powerful engine for indexing and querying dense and sparse multi-dimensional arrays.","sidebar":"integrations"},"integrations/vectorstores/timescalevector":{"id":"integrations/vectorstores/timescalevector","title":"Timescale Vector (Postgres)","description":"Timescale Vector is PostgreSQL++ vector database for AI applications.","sidebar":"integrations"},"integrations/vectorstores/typesense":{"id":"integrations/vectorstores/typesense","title":"Typesense","description":"Typesense is an open-source, in-memory search engine, that you can either self-host or run on Typesense Cloud.","sidebar":"integrations"},"integrations/vectorstores/upstash":{"id":"integrations/vectorstores/upstash","title":"Upstash Vector","description":"Upstash Vector is a serverless vector database designed for working with vector embeddings.","sidebar":"integrations"},"integrations/vectorstores/usearch":{"id":"integrations/vectorstores/usearch","title":"USearch","description":"USearch is a Smaller & Faster Single-File Vector Search Engine","sidebar":"integrations"},"integrations/vectorstores/vald":{"id":"integrations/vectorstores/vald","title":"Vald","description":"Vald is a highly scalable distributed fast approximate nearest neighbor (ANN) dense vector search engine.","sidebar":"integrations"},"integrations/vectorstores/vdms":{"id":"integrations/vectorstores/vdms","title":"Intel\'s Visual Data Management System (VDMS)","description":"This notebook covers how to get started with VDMS as a vector store.","sidebar":"integrations"},"integrations/vectorstores/vearch":{"id":"integrations/vectorstores/vearch","title":"Vearch","description":"Vearch is the vector search infrastructure for deeping learning and AI applications.","sidebar":"integrations"},"integrations/vectorstores/vectara":{"id":"integrations/vectorstores/vectara","title":"Vectara","description":"Vectara is the trusted AI Assistant and Agent platform which focuses on enterprise readiness for mission-critical applications.","sidebar":"integrations"},"integrations/vectorstores/vespa":{"id":"integrations/vectorstores/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database. It supports vector search (ANN), lexical search, and search in structured data, all in the same query.","sidebar":"integrations"},"integrations/vectorstores/vikingdb":{"id":"integrations/vectorstores/vikingdb","title":"viking DB","description":"viking DB is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.","sidebar":"integrations"},"integrations/vectorstores/vlite":{"id":"integrations/vectorstores/vlite","title":"vlite","description":"VLite is a simple and blazing fast vector database that allows you to store and retrieve data semantically using embeddings. Made with numpy, vlite is a lightweight batteries-included database to implement RAG, similarity search, and embeddings into your projects.","sidebar":"integrations"},"integrations/vectorstores/weaviate":{"id":"integrations/vectorstores/weaviate","title":"Weaviate","description":"This notebook covers how to get started with the Weaviate vector store in LangChain, using the langchain-weaviate package.","sidebar":"integrations"},"integrations/vectorstores/xata":{"id":"integrations/vectorstores/xata","title":"Xata","description":"Xata is a serverless data platform, based on PostgreSQL. It provides a Python SDK for interacting with your database, and a UI for managing your data.","sidebar":"integrations"},"integrations/vectorstores/yellowbrick":{"id":"integrations/vectorstores/yellowbrick","title":"Yellowbrick","description":"Yellowbrick is an elastic, massively parallel processing (MPP) SQL database that runs in the cloud and on-premises, using kubernetes for scale, resilience and cloud portability. Yellowbrick is designed to address the largest and most complex business-critical data warehousing use cases. The efficiency at scale that Yellowbrick provides also enables it to be used as a high performance and scalable vector database to store and search vectors with SQL.","sidebar":"integrations"},"integrations/vectorstores/zep":{"id":"integrations/vectorstores/zep","title":"Zep","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences.","sidebar":"integrations"},"integrations/vectorstores/zep_cloud":{"id":"integrations/vectorstores/zep_cloud","title":"Zep Cloud","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences.","sidebar":"integrations"},"integrations/vectorstores/zilliz":{"id":"integrations/vectorstores/zilliz","title":"Zilliz","description":"Zilliz Cloud is a fully managed service on cloud for LF AI Milvus\xae,","sidebar":"integrations"},"introduction":{"id":"introduction","title":"Introduction","description":"LangChain is a framework for developing applications powered by large language models (LLMs).","sidebar":"docs"},"langserve":{"id":"langserve","title":"\ud83e\udd9c\ufe0f\ud83c\udfd3 LangServe","description":"Release Notes"},"people":{"id":"people","title":"People","description":"There are some incredible humans from all over the world who have been instrumental in helping the LangChain community flourish \ud83c\udf10!"},"security":{"id":"security","title":"Security Policy","description":"LangChain has a large ecosystem of integrations with various external resources like local and remote file systems, APIs and databases. These integrations allow developers to create versatile applications that combine the power of LLMs with the ability to access, interact with and manipulate external resources.","sidebar":"docs"},"troubleshooting/errors/index":{"id":"troubleshooting/errors/index","title":"Error reference","description":"This page contains guides around resolving common errors you may find while building with LangChain."},"troubleshooting/errors/INVALID_PROMPT_INPUT":{"id":"troubleshooting/errors/INVALID_PROMPT_INPUT","title":"INVALID_PROMPT_INPUT","description":"A prompt template received missing or invalid input variables."},"troubleshooting/errors/INVALID_TOOL_RESULTS":{"id":"troubleshooting/errors/INVALID_TOOL_RESULTS","title":"INVALID_TOOL_RESULTS","description":"You are passing too many, too few, or mismatched ToolMessages to a model."},"troubleshooting/errors/MESSAGE_COERCION_FAILURE":{"id":"troubleshooting/errors/MESSAGE_COERCION_FAILURE","title":"MESSAGE_COERCION_FAILURE","description":"Instead of always requiring instances of BaseMessage, several modules in LangChain take MessageLikeRepresentation, which is defined as:"},"troubleshooting/errors/MODEL_AUTHENTICATION":{"id":"troubleshooting/errors/MODEL_AUTHENTICATION","title":"MODEL_AUTHENTICATION","description":"Your model provider is denying you access to their service."},"troubleshooting/errors/MODEL_NOT_FOUND":{"id":"troubleshooting/errors/MODEL_NOT_FOUND","title":"MODEL_NOT_FOUND","description":"The model name you have specified is not acknowledged by your provider."},"troubleshooting/errors/MODEL_RATE_LIMIT":{"id":"troubleshooting/errors/MODEL_RATE_LIMIT","title":"MODEL_RATE_LIMIT","description":"You have hit the maximum number of requests that a model provider allows over a given time period and are being temporarily blocked."},"troubleshooting/errors/OUTPUT_PARSING_FAILURE":{"id":"troubleshooting/errors/OUTPUT_PARSING_FAILURE","title":"OUTPUT_PARSING_FAILURE","description":"An output parser was unable to handle model output as expected."},"tutorials/agents":{"id":"tutorials/agents","title":"Build an Agent","description":"By themselves, language models can\'t take actions - they just output text.","sidebar":"docs"},"tutorials/chatbot":{"id":"tutorials/chatbot","title":"Build a Chatbot","description":"This tutorial previously used the RunnableWithMessageHistory abstraction. You can access that version of the documentation in the v0.2 docs.","sidebar":"docs"},"tutorials/classification":{"id":"tutorials/classification","title":"Tagging","description":"Open In Colab","sidebar":"docs"},"tutorials/extraction":{"id":"tutorials/extraction","title":"Build an Extraction Chain","description":"In this tutorial, we will use tool-calling features of chat models to extract structured information from unstructured text. We will also demonstrate how to use few-shot prompting in this context to improve performance.","sidebar":"docs"},"tutorials/graph":{"id":"tutorials/graph","title":"Build a Question Answering application over a Graph Database","description":"In this guide we\'ll go over the basic ways to create a Q&A chain over a graph database. These systems will allow us to ask a question about the data in a graph database and get back a natural language answer. First, we will show a simple out-of-the-box option and then implement a more sophisticated version with LangGraph.","sidebar":"docs"},"tutorials/index":{"id":"tutorials/index","title":"Tutorials","description":"New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.","sidebar":"docs"},"tutorials/llm_chain":{"id":"tutorials/llm_chain","title":"Build a simple LLM application with chat models and prompt templates","description":"In this quickstart we\'ll show you how to build a simple LLM application with LangChain. This application will translate text from English into another language. This is a relatively simple LLM application - it\'s just a single LLM call plus some prompting. Still, this is a great way to get started with LangChain - a lot of features can be built with just some prompting and an LLM call!","sidebar":"docs"},"tutorials/qa_chat_history":{"id":"tutorials/qa_chat_history","title":"Build a Retrieval Augmented Generation (RAG) App: Part 2","description":"In many Q&A applications we want to allow the user to have a back-and-forth conversation, meaning the application needs some sort of \\"memory\\" of past questions and answers, and some logic for incorporating those into its current thinking.","sidebar":"docs"},"tutorials/rag":{"id":"tutorials/rag","title":"Build a Retrieval Augmented Generation (RAG) App: Part 1","description":"One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.","sidebar":"docs"},"tutorials/retrievers":{"id":"tutorials/retrievers","title":"Build a semantic search engine","description":"This tutorial will familiarize you with LangChain\'s document loader, embedding, and vector store abstractions. These abstractions are designed to support retrieval of data--  from (vector) databases and other sources--  for integration with LLM workflows. They are important for applications that fetch data to be reasoned over as part of model inference, as in the case of retrieval-augmented generation, or RAG (see our RAG tutorial here).","sidebar":"docs"},"tutorials/sql_qa":{"id":"tutorials/sql_qa","title":"Build a Question/Answering system over SQL data","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"tutorials/summarization":{"id":"tutorials/summarization","title":"Summarize Text","description":"This tutorial demonstrates text summarization using built-in chains and LangGraph.","sidebar":"docs"},"versions/migrating_chains/constitutional_chain":{"id":"versions/migrating_chains/constitutional_chain","title":"Migrating from ConstitutionalChain","description":"ConstitutionalChain allowed for a LLM to critique and revise generations based on principles, structured as combinations of critique and revision requests. For example, a principle might include a request to identify harmful content, and a request to rewrite the content.","sidebar":"docs"},"versions/migrating_chains/conversation_chain":{"id":"versions/migrating_chains/conversation_chain","title":"Migrating from ConversationalChain","description":"ConversationChain incorporated a memory of previous messages to sustain a stateful conversation.","sidebar":"docs"},"versions/migrating_chains/conversation_retrieval_chain":{"id":"versions/migrating_chains/conversation_retrieval_chain","title":"Migrating from ConversationalRetrievalChain","description":"The ConversationalRetrievalChain was an all-in one way that combined retrieval-augmented generation with chat history, allowing you to \\"chat with\\" your documents.","sidebar":"docs"},"versions/migrating_chains/index":{"id":"versions/migrating_chains/index","title":"How to migrate from v0.0 chains","description":"LangChain has evolved since its initial release, and many of the original \\"Chain\\" classes","sidebar":"docs"},"versions/migrating_chains/llm_chain":{"id":"versions/migrating_chains/llm_chain","title":"Migrating from LLMChain","description":"LLMChain combined a prompt template, LLM, and output parser into a class.","sidebar":"docs"},"versions/migrating_chains/llm_math_chain":{"id":"versions/migrating_chains/llm_math_chain","title":"Migrating from LLMMathChain","description":"LLMMathChain enabled the evaluation of mathematical expressions generated by a LLM. Instructions for generating the expressions were formatted into the prompt, and the expressions were parsed out of the string response before evaluation using the numexpr library.","sidebar":"docs"},"versions/migrating_chains/llm_router_chain":{"id":"versions/migrating_chains/llm_router_chain","title":"Migrating from LLMRouterChain","description":"The LLMRouterChain routed an input query to one of multiple destinations-- that is, given an input query, it used a LLM to select from a list of destination chains, and passed its inputs to the selected chain.","sidebar":"docs"},"versions/migrating_chains/map_reduce_chain":{"id":"versions/migrating_chains/map_reduce_chain","title":"Migrating from MapReduceDocumentsChain","description":"MapReduceDocumentsChain implements a map-reduce strategy over (potentially long) texts. The strategy is as follows:","sidebar":"docs"},"versions/migrating_chains/map_rerank_docs_chain":{"id":"versions/migrating_chains/map_rerank_docs_chain","title":"Migrating from MapRerankDocumentsChain","description":"MapRerankDocumentsChain implements a strategy for analyzing long texts. The strategy is as follows:","sidebar":"docs"},"versions/migrating_chains/multi_prompt_chain":{"id":"versions/migrating_chains/multi_prompt_chain","title":"Migrating from MultiPromptChain","description":"The MultiPromptChain routed an input query to one of multiple LLMChains-- that is, given an input query, it used a LLM to select from a list of prompts, formatted the query into the prompt, and generated a response.","sidebar":"docs"},"versions/migrating_chains/refine_docs_chain":{"id":"versions/migrating_chains/refine_docs_chain","title":"Migrating from RefineDocumentsChain","description":"RefineDocumentsChain implements a strategy for analyzing long texts. The strategy is as follows:","sidebar":"docs"},"versions/migrating_chains/retrieval_qa":{"id":"versions/migrating_chains/retrieval_qa","title":"Migrating from RetrievalQA","description":"The RetrievalQA chain performed natural-language question answering over a data source using retrieval-augmented generation.","sidebar":"docs"},"versions/migrating_chains/stuff_docs_chain":{"id":"versions/migrating_chains/stuff_docs_chain","title":"Migrating from StuffDocumentsChain","description":"StuffDocumentsChain combines documents by concatenating them into a single context window. It is a straightforward and effective strategy for combining documents for question-answering, summarization, and other purposes.","sidebar":"docs"},"versions/migrating_memory/chat_history":{"id":"versions/migrating_memory/chat_history","title":"How to use BaseChatMessageHistory with LangGraph","description":"This guide assumes familiarity with the following concepts:","sidebar":"docs"},"versions/migrating_memory/conversation_buffer_memory":{"id":"versions/migrating_memory/conversation_buffer_memory","title":"Migrating off ConversationBufferMemory or ConversationStringBufferMemory","description":"ConversationBufferMemory","sidebar":"docs"},"versions/migrating_memory/conversation_buffer_window_memory":{"id":"versions/migrating_memory/conversation_buffer_window_memory","title":"Migrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory","description":"Follow this guide if you\'re trying to migrate off one of the old memory classes listed below:","sidebar":"docs"},"versions/migrating_memory/conversation_summary_memory":{"id":"versions/migrating_memory/conversation_summary_memory","title":"Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory","description":"Follow this guide if you\'re trying to migrate off one of the old memory classes listed below:","sidebar":"docs"},"versions/migrating_memory/index":{"id":"versions/migrating_memory/index","title":"How to migrate to LangGraph memory","description":"As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of LangGraph persistence to incorporate memory into their LangChain application.","sidebar":"docs"},"versions/migrating_memory/long_term_memory_agent":{"id":"versions/migrating_memory/long_term_memory_agent","title":"A Long-Term Memory Agent","description":"This tutorial shows how to implement an agent with long-term memory capabilities using LangGraph. The agent can store, retrieve, and use memories to enhance its interactions with users.","sidebar":"docs"},"versions/release_policy":{"id":"versions/release_policy","title":"LangChain release policy","description":"The LangChain ecosystem is composed of different component packages (e.g., langchain-core, langchain, langchain-community, langgraph, langserve, partner packages etc.)","sidebar":"docs"},"versions/v0_2/deprecations":{"id":"versions/v0_2/deprecations","title":"Deprecations and Breaking Changes","description":"This code contains a list of deprecations and removals in the langchain and langchain-core packages.","sidebar":"docs"},"versions/v0_2/index":{"id":"versions/v0_2/index","title":"Migration","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x.","sidebar":"docs"},"versions/v0_2/migrating_astream_events":{"id":"versions/v0_2/migrating_astream_events","title":"Migrating to astream_events(..., version=\\"v2\\")","description":"We\'ve added a v2 of the astream_events API with the release of 0.2.x. You can see this PR for more details.","sidebar":"docs"},"versions/v0_2/overview":{"id":"versions/v0_2/overview","title":"Overview","description":"What\u2019s new in LangChain?","sidebar":"docs"},"versions/v0_3/index":{"id":"versions/v0_3/index","title":"LangChain v0.3","description":"Last updated: 09.16.24","sidebar":"docs"}}}}')}}]);